<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"GPT-3 论文","image":[""],"datePublished":"2025-06-26T00:00:00.000Z","dateModified":"2025-06-26T07:47:23.000Z","author":[{"@type":"Person","name":"BinaryOracle"}]}</script><meta property="og:url" content="https://mister-hope.github.io/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/GPT-3%E8%AE%BA%E6%96%87.html"><meta property="og:site_name" content="MetaMind"><meta property="og:title" content="GPT-3 论文"><meta property="og:description" content="GPT-3 论文"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-06-26T07:47:23.000Z"><meta property="article:author" content="BinaryOracle"><meta property="article:tag" content="已发布"><meta property="article:tag" content="预训练语言模型"><meta property="article:published_time" content="2025-06-26T00:00:00.000Z"><meta property="article:modified_time" content="2025-06-26T07:47:23.000Z"><title>GPT-3 论文 | MetaMind</title><meta name="description" content="GPT-3 论文">
    <link rel="preload" href="/assets/style-B9ka0LB5.css" as="style"><link rel="stylesheet" href="/assets/style-B9ka0LB5.css">
    <link rel="modulepreload" href="/assets/app-D88RxMvE.js"><link rel="modulepreload" href="/assets/GPT-3论文.html-DSuEOkac.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-BFWzr0JG.js" as="script"><link rel="prefetch" href="/assets/intro.html-QdwhLT68.js" as="script"><link rel="prefetch" href="/assets/GREAT.html-jOrZ2T_5.js" as="script"><link rel="prefetch" href="/assets/Grounding_3D_Object_Affordance.html-BH7mygbv.js" as="script"><link rel="prefetch" href="/assets/IAGNet.html-BKRghMwr.js" as="script"><link rel="prefetch" href="/assets/LASO.html-CaBPAUMZ.js" as="script"><link rel="prefetch" href="/assets/index.html-CqDZQ2U1.js" as="script"><link rel="prefetch" href="/assets/简析PointNet__.html-BA_oSs-Z.js" as="script"><link rel="prefetch" href="/assets/简析PointNet.html-SBC3rzjy.js" as="script"><link rel="prefetch" href="/assets/index.html-BlAUgj9m.js" as="script"><link rel="prefetch" href="/assets/ BLIP.html-Bw0UeMHw.js" as="script"><link rel="prefetch" href="/assets/ALBEF.html-B0jf52Tb.js" as="script"><link rel="prefetch" href="/assets/InternVL-1.0.html-4XcVMaAP.js" as="script"><link rel="prefetch" href="/assets/InternVl-1.5.html-Ch3zRal8.js" as="script"><link rel="prefetch" href="/assets/LLaVA_1.0.html-wUjWrA0K.js" as="script"><link rel="prefetch" href="/assets/MoCo.html-D0mtZ_w8.js" as="script"><link rel="prefetch" href="/assets/index.html-Coee1efM.js" as="script"><link rel="prefetch" href="/assets/VLMo.html-DjAigZB7.js" as="script"><link rel="prefetch" href="/assets/ViLT.html-BMEgapdF.js" as="script"><link rel="prefetch" href="/assets/多模态常用改编Bert实现.html-CtWkBdg8.js" as="script"><link rel="prefetch" href="/assets/多模态模型CLIP原理与图片分类，文字搜索图像实战演练.html-9qSOgoa8.js" as="script"><link rel="prefetch" href="/assets/庖丁解牛BLIP2.html-2RfuWFXp.js" as="script"><link rel="prefetch" href="/assets/庖丁解牛VIT.html-CDpFUyZo.js" as="script"><link rel="prefetch" href="/assets/index.html-0wXmhFoN.js" as="script"><link rel="prefetch" href="/assets/Attention运算过程中维度变换的理解.html-Dl_RR334.js" as="script"><link rel="prefetch" href="/assets/Pytorch张量存储与访问原理.html-Cb6OneZO.js" as="script"><link rel="prefetch" href="/assets/index.html-cEDvQVi-.js" as="script"><link rel="prefetch" href="/assets/conda虚拟环境管理.html-CN-VcFV6.js" as="script"><link rel="prefetch" href="/assets/常用评估指标.html-B9c0q2e8.js" as="script"><link rel="prefetch" href="/assets/数学知识点.html-DpFAqmEw.js" as="script"><link rel="prefetch" href="/assets/深度学习中常见API记录.html-qdYCtBPr.js" as="script"><link rel="prefetch" href="/assets/语义分割中常用的损失函数.html-wU7JdL6X.js" as="script"><link rel="prefetch" href="/assets/通俗易懂解读BPE分词算法实现.html-5Z5SOdtg.js" as="script"><link rel="prefetch" href="/assets/index.html-CYZTZYky.js" as="script"><link rel="prefetch" href="/assets/Fine_Tuning知识扫盲.html-DqrHJ6CC.js" as="script"><link rel="prefetch" href="/assets/LoRA微调系列.html-j7-pGp0l.js" as="script"><link rel="prefetch" href="/assets/Prompt_Engineering知识扫盲.html-CuPdziSD.js" as="script"><link rel="prefetch" href="/assets/index.html-DrpSpEdL.js" as="script"><link rel="prefetch" href="/assets/GPT-1论文.html-DJ8VJP63.js" as="script"><link rel="prefetch" href="/assets/GPT-2论文.html-BvubIqtL.js" as="script"><link rel="prefetch" href="/assets/InstructGPT论文.html-BvOyFevu.js" as="script"><link rel="prefetch" href="/assets/KV-Cache.html-yRfh2iSd.js" as="script"><link rel="prefetch" href="/assets/LLaMA-1论文.html-BU0p3qJD.js" as="script"><link rel="prefetch" href="/assets/LLaMA-2论文.html-CtZn_Ojv.js" as="script"><link rel="prefetch" href="/assets/index.html-QjSz7Ro5.js" as="script"><link rel="prefetch" href="/assets/RoBERTa论文.html-DpPS0Prj.js" as="script"><link rel="prefetch" href="/assets/从零实现Bert.html-DggMgmiU.js" as="script"><link rel="prefetch" href="/assets/图解BERT.html-CnvLyr7T.js" as="script"><link rel="prefetch" href="/assets/图解Transformer.html-Ch5LMXmR.js" as="script"><link rel="prefetch" href="/assets/1.自动微分.html-CX5J4p0K.js" as="script"><link rel="prefetch" href="/assets/2.用自然的代码表达.html-DmvASBAJ.js" as="script"><link rel="prefetch" href="/assets/3.高阶导数.html-Dww_n_Id.js" as="script"><link rel="prefetch" href="/assets/4.神经网络.html-D0V5Z5ZS.js" as="script"><link rel="prefetch" href="/assets/index.html-CqRRutug.js" as="script"><link rel="prefetch" href="/assets/1.前置知识.html-gLAZINf2.js" as="script"><link rel="prefetch" href="/assets/2.大模型API.html-Drx9ZnIU.js" as="script"><link rel="prefetch" href="/assets/index.html-BtE-kOix.js" as="script"><link rel="prefetch" href="/assets/index.html-Blsal4hU.js" as="script"><link rel="prefetch" href="/assets/index.html-sQLT9H4w.js" as="script"><link rel="prefetch" href="/assets/基础概念.html-DaPRev11.js" as="script"><link rel="prefetch" href="/assets/基础模型.html-DB6-fCgH.js" as="script"><link rel="prefetch" href="/assets/组合分析.html-NNFMZ6vA.js" as="script"><link rel="prefetch" href="/assets/BEiT.html-Ch12B1ts.js" as="script"><link rel="prefetch" href="/assets/BEiT模型代码解读.html-PX23OvLK.js" as="script"><link rel="prefetch" href="/assets/DALL·E.html-BjmKmHiK.js" as="script"><link rel="prefetch" href="/assets/PixelCNN.html-C6X6J6iP.js" as="script"><link rel="prefetch" href="/assets/Pytorch实现VAE和CVAE.html-YRjavV7e.js" as="script"><link rel="prefetch" href="/assets/index.html-CxDnNVha.js" as="script"><link rel="prefetch" href="/assets/Tutorial_VAE.html-BMAwdPY2.js" as="script"><link rel="prefetch" href="/assets/VQ-VAE.html-CGnbr8ZA.js" as="script"><link rel="prefetch" href="/assets/404.html-2Dp9l_SQ.js" as="script"><link rel="prefetch" href="/assets/index.html-DwKXsNFk.js" as="script"><link rel="prefetch" href="/assets/index.html-DCp-IDcv.js" as="script"><link rel="prefetch" href="/assets/index.html-Ckq22bG7.js" as="script"><link rel="prefetch" href="/assets/index.html-R17iFMuQ.js" as="script"><link rel="prefetch" href="/assets/index.html-Cmp-xi4Z.js" as="script"><link rel="prefetch" href="/assets/index.html-CQWOBqoM.js" as="script"><link rel="prefetch" href="/assets/index.html-DgZmfrZn.js" as="script"><link rel="prefetch" href="/assets/index.html-DC4UKc74.js" as="script"><link rel="prefetch" href="/assets/index.html-BOmdcOI8.js" as="script"><link rel="prefetch" href="/assets/index.html-CE6wnYVD.js" as="script"><link rel="prefetch" href="/assets/index.html-dDTM33Bn.js" as="script"><link rel="prefetch" href="/assets/index.html-BQr7oaD_.js" as="script"><link rel="prefetch" href="/assets/index.html-DZkkmU8_.js" as="script"><link rel="prefetch" href="/assets/index.html-BFeWW6xW.js" as="script"><link rel="prefetch" href="/assets/index.html-Beh7TSHs.js" as="script"><link rel="prefetch" href="/assets/index.html-D1uPpUGa.js" as="script"><link rel="prefetch" href="/assets/index.html-Bi2a6fUi.js" as="script"><link rel="prefetch" href="/assets/index.html-fJrNX5Va.js" as="script"><link rel="prefetch" href="/assets/index.html-wHyauzbN.js" as="script"><link rel="prefetch" href="/assets/index.html-CcLpGSu3.js" as="script"><link rel="prefetch" href="/assets/index.html-DH5e-ycz.js" as="script"><link rel="prefetch" href="/assets/index.html-Bp8_pty1.js" as="script"><link rel="prefetch" href="/assets/index.html-DpeFrFMn.js" as="script"><link rel="prefetch" href="/assets/index.html-tcdho5vC.js" as="script"><link rel="prefetch" href="/assets/index.html-DJYJBN-J.js" as="script"><link rel="prefetch" href="/assets/index.html-iEYH6YTY.js" as="script"><link rel="prefetch" href="/assets/index.html-Do1Ylxcv.js" as="script"><link rel="prefetch" href="/assets/index.html-D3rG8l5O.js" as="script"><link rel="prefetch" href="/assets/index.html-DbG5Coxm.js" as="script"><link rel="prefetch" href="/assets/index.html-C91DOoUi.js" as="script"><link rel="prefetch" href="/assets/index.html-Df7hOetF.js" as="script"><link rel="prefetch" href="/assets/index.html-DeiJiU0G.js" as="script"><link rel="prefetch" href="/assets/index.html-BTvefNMz.js" as="script"><link rel="prefetch" href="/assets/index.html--E7zxZ8s.js" as="script"><link rel="prefetch" href="/assets/index.html-Bz1Obp5U.js" as="script"><link rel="prefetch" href="/assets/index.html-Dm-etQ-F.js" as="script"><link rel="prefetch" href="/assets/index-BzBQJFYZ.js" as="script"><link rel="prefetch" href="/assets/flowchart-BKGBxuOE.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-Ow9_I7J5.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/SearchResult-E4f0Ryfq.js" as="script"><link rel="prefetch" href="/assets/waline-meta-l0sNRNKZ.js" as="script"><link rel="prefetch" href="/assets/component-CF-BVGzA.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><img class="vp-nav-logo" src="/assets/images/head.png" alt><!----><span class="vp-site-name hide-in-pad">MetaMind</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="主页"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:house" sizing="height" height="1em"></iconify-icon><!--]-->主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/LLM/" aria-label="大语言模型"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:book" sizing="height" height="1em"></iconify-icon><!--]-->大语言模型<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/MMLLM/" aria-label="多模态"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:laptop-code" sizing="height" height="1em"></iconify-icon><!--]-->多模态<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/3DVL/" aria-label="3D-Vision Language"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:eye" sizing="height" height="1em"></iconify-icon><!--]-->3D-Vision Language<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/other_direction/" aria-label="其他方向"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:computer" sizing="height" height="1em"></iconify-icon><!--]-->其他方向<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/open_projects/" aria-label="开源项目"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:star" sizing="height" height="1em"></iconify-icon><!--]-->开源项目<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/other/" aria-label="杂谈"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:sun" sizing="height" height="1em"></iconify-icon><!--]-->杂谈<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!----><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><button type="button" class="slimsearch-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="slimsearch-placeholder">搜索</div><div class="slimsearch-key-hints"><kbd class="slimsearch-key">Ctrl</kbd><kbd class="slimsearch-key">K</kbd></div></button><!--]--><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="主页"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:house" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->主页<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:book" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">大语言模型</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:robot" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">应用层</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:book" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">模型层</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/%E5%9B%BE%E8%A7%A3Transformer.html" aria-label="图解Transformer"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->图解Transformer<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/GPT-1%E8%AE%BA%E6%96%87.html" aria-label="GPT-1 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->GPT-1 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/GPT-2%E8%AE%BA%E6%96%87.html" aria-label="GPT-2 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->GPT-2 论文<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/GPT-3%E8%AE%BA%E6%96%87.html" aria-label="GPT-3 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->GPT-3 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/InstructGPT%E8%AE%BA%E6%96%87.html" aria-label="InstructGPT 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->InstructGPT 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/KV-Cache.html" aria-label="KV-Cache 详解"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->KV-Cache 详解<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/LLaMA-1%E8%AE%BA%E6%96%87.html" aria-label="LLaMA-1论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->LLaMA-1论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/LLaMA-2%E8%AE%BA%E6%96%87.html" aria-label="LLaMA-2论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->LLaMA-2论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/RoBERTa%E8%AE%BA%E6%96%87.html" aria-label="RoBERTa 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->RoBERTa 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0Bert.html" aria-label="从&quot;零&quot;实现 Bert"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->从&quot;零&quot;实现 Bert<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/%E5%9B%BE%E8%A7%A3BERT.html" aria-label="图解 Bert"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->图解 Bert<!----></a></li></ul></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:laptop-code" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">多模态</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:eye" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">3D-Vision Language</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:computer" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">其他方向</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:star" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">开源项目</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:sun" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">杂谈</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="关于我们"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:circle-info" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->关于我们<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="height" height="1em"></iconify-icon>GPT-3 论文</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">BinaryOracle</span></span><span property="author" content="BinaryOracle"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/6/26</span><meta property="datePublished" content="2025-06-26T00:00:00.000Z"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color2 clickable" role="navigation">NLP</span><!--]--><meta property="articleSection" content="NLP"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color6 clickable" role="navigation">预训练语言模型</span><span class="page-tag-item color4 clickable" role="navigation">已发布</span><!--]--><meta property="keywords" content="预训练语言模型,已发布"></span><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 17 分钟</span><meta property="timeRequired" content="PT17M"></span><span class="page-word-info" aria-label="字数🔠" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon word-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="word icon" name="word"><path d="M518.217 432.64V73.143A73.143 73.143 0 01603.43 1.097a512 512 0 01419.474 419.474 73.143 73.143 0 01-72.046 85.212H591.36a73.143 73.143 0 01-73.143-73.143z"></path><path d="M493.714 566.857h340.297a73.143 73.143 0 0173.143 85.577A457.143 457.143 0 11371.566 117.76a73.143 73.143 0 0185.577 73.143v339.383a36.571 36.571 0 0036.571 36.571z"></path></svg><span>约 4963 字</span><meta property="wordCount" content="4963"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><p><code>GPT-3 论文</code></p><!-- more --><blockquote><p>论文链接: <a href="https://arxiv.org/abs/2005.14165" target="_blank" rel="noopener noreferrer">Language Models are Few-Shot Learners</a></p></blockquote><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>这篇论文介绍了GPT-3，一个具有1750亿参数的自回归语言模型，通过大规模训练显著提升了少样本学习能力。GPT-3在多种自然语言处理任务中表现出色，包括翻译、问答和文本生成等，甚至在零样本和单样本设置下也能取得有竞争力的结果。研究还探讨了数据污染问题、模型局限性及其社会影响，如偏见和能源消耗。实验表明，模型规模的扩大带来了性能的持续提升，但某些任务仍存在挑战。论文强调了GPT-3在通用语言系统发展中的潜力及其可能带来的广泛社会影响。</p><h2 id="简介" tabindex="-1"><a class="header-anchor" href="#简介"><span>简介</span></a></h2><p><strong>1. 背景与动机</strong></p><p>近年来，自然语言处理（NLP）领域逐渐转向预训练语言模型，并采用更灵活的任务无关（task-agnostic）方法进行下游迁移学习。早期的模型（如词向量、RNN）依赖任务特定的架构，而现代模型（如Transformer）可直接微调，无需额外架构调整。然而，现有方法仍需要针对每个任务进行大规模监督数据微调，这限制了模型的广泛应用。相比之下，人类仅需少量示例或简单指令即可完成新任务，因此<strong>论文探索如何让语言模型具备类似的少样本学习能力</strong>。</p><hr><p><strong>2. 现有方法的局限性</strong></p><p>当前基于微调的方法存在三个主要问题：</p><ol><li><p><strong>数据需求高</strong>：每个任务需要数千至数十万标注样本，难以覆盖广泛的语言任务。</p></li><li><p><strong>泛化能力有限</strong>：模型容易过拟合训练数据的虚假相关性（spurious correlations），导致在分布外数据上表现不佳。</p></li><li><p><strong>与人类学习方式不匹配</strong>：人类可通过少量示例或自然语言指令快速适应新任务，而现有模型难以实现类似能力。</p></li></ol><hr><p><strong>3. 元学习与上下文学习的潜力</strong></p><p>论文提出通过<strong>元学习</strong> (meta-learning) 提升模型的少样本学习能力，即<strong>在预训练阶段让模型隐式学习多种技能，并在推理时通过上下文（in-context learning）快速适应新任务</strong>。此前的研究（如GPT-2）已初步验证了上下文学习的可行性，但性能远低于微调方法。论文假设，<strong>模型规模的扩大可能显著提升上下文学习能力</strong>，因为更大容量的模型能吸收更多任务相关的模式。</p><figure><img src="/assets/1-DfUyR6J5.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><br><h2 id="" tabindex="-1"><a class="header-anchor" href="#"><span><img src="/assets/2-DFE_4TXs.png" alt="" loading="lazy"></span></a></h2><p><strong>4. GPT-3 的目标与贡献</strong></p><p>论文训练了<strong>GPT-3</strong>（1750亿参数），比此前最大的非稀疏语言模型大10倍，并系统评估其在零样本（zero-shot）、单样本（one-shot）和少样本（few-shot）设置下的表现。实验覆盖了翻译、问答、常识推理等多样化任务，结果显示：</p><ul><li>在少样本设置下，GPT-3 接近或超越部分任务的微调模型性能。</li><li>模型规模与少样本学习能力呈正相关，表明缩放定律（scaling laws）在此类任务中依然适用。</li><li>同时，论文也分析了模型在自然语言推理（NLI）等任务上的局限性，并探讨了数据污染和社会影响等问题。</li></ul><br><figure><img src="/assets/3-B3JaiMwO.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><br><hr><p><strong>5. 研究意义</strong></p><p>GPT-3 的成果表明，<strong>超大规模语言模型可以显著减少对任务特定数据的需求</strong>，推动更通用、灵活的语言系统发展。然而，其局限性（如计算成本、偏见问题）也提示了未来改进方向，如结合双向架构或多模态训练。论文最终强调，这一研究为探索语言模型的元学习机制和实际应用奠定了基础。</p><h2 id="方法" tabindex="-1"><a class="header-anchor" href="#方法"><span>方法</span></a></h2><p><strong>1. 四种任务设定方法的比较</strong></p><p>作者首先定义了语言模型执行任务的四种方式：</p><ul><li><p><strong>Fine-tuning（微调）</strong>：在任务特定数据集上更新模型权重，通常需要数千到数十万个标注样本，性能最佳，但泛化能力弱，且每个任务都需新数据。</p></li><li><p><strong>Few-shot learning（少样本学习）</strong>：在推理时为模型提供10-100个任务示例作为上下文，无需参数更新，显著减少数据需求。</p></li><li><p><strong>One-shot learning（单样本学习）</strong>：提供一条示例和任务描述，有时更贴近人类学习习惯。</p></li><li><p><strong>Zero-shot learning（零样本学习）</strong>：仅提供任务描述，不给任何示例，是最具挑战也最通用的形式。</p></li></ul><p>如图 2.1 所示（Figure 2.1），这些方法在数据需求和任务适应能力之间形成一个光谱，GPT-3主要研究后三种方法，强调它们在无需微调的情况下就能取得良好效果，尤其是few-shot设定下的表现令人惊喜。</p><figure><img src="/assets/4-BgXCzVpX.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>2. 模型架构与规模设计</strong></p><p>GPT-3模型架构基本沿用GPT-2，包括预归一化、可逆tokenizer等设计，但采用稀疏注意力机制（Sparse Transformer）以提升效率。作者训练了从125M到175B参数的8个模型（见表 2.1），以研究性能与规模之间的关系。所有模型共享最大上下文窗口为2048 tokens。模型训练过程中采用混合并行策略以适应大规模参数训练。</p><figure><img src="/assets/5-BBn7XDLP.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>3. 数据集构成与过滤策略</strong></p><p>GPT-3的训练数据主要来自以下五个来源（见表 2.2）：</p><ul><li><p>Common Crawl（经过过滤，占比60%）</p></li><li><p>WebText2、Books1、Books2、Wikipedia（合计40%）</p></li></ul><p>为保证数据质量，作者对Common Crawl执行了质量过滤和模糊去重，并引入高质量参考语料。重要的是，数据在训练中并非按体量采样，而是按质量设权重采样，高质量数据被重复使用，而Common Crawl这类数据在整个训练中只被读取一次左右。</p><figure><img src="/assets/6-v55SKlhG.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>4. 训练过程与资源分配</strong></p><p>大模型使用较大的batch size和较小的学习率（详见表 2.1）。训练依赖微软提供的高带宽GPU集群，采用模型层间和矩阵级别的并行方式进行。所有模型都使用3000亿tokens进行训练，训练策略遵循了<a href="https://arxiv.org/abs/2001.08361" target="_blank" rel="noopener noreferrer">《Scaling Laws for Neural Language Models》</a>一文的建议。</p><p>如图 2.2 所示（Figure 2.2），GPT-3虽然模型更大，但实际训练所需的计算资源与较小模型相当，这得益于更高效的数据利用率。</p><figure><img src="/assets/7-Bt0swFoN.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>5. 评估方法与设定</strong></p><p>在few-shot设定下，模型的每个测试样本前会插入K条示例（K通常为10-100，取决于是否能容纳在2048 token窗口中）。对于没有训练集的数据集，示例从开发集提取；对于多选题，GPT-3比较不同答案的语言模型概率（归一化处理）；对于生成类任务，则使用beam search输出，并按F1、BLEU或精确匹配评估。最终结果在公开测试集或开发集上报告。</p><hr><p><strong>总结</strong></p><p>GPT-3的研究方法基于“任务不可知”的设定，通过大规模预训练和精心设计的上下文输入，在不进行梯度更新的前提下实现任务适应。这种“以上下文为接口”的元学习方法，加上参数规模的扩展，使得GPT-3在多个任务上展现出超越以往fine-tuned方法的能力，为未来通用语言智能系统奠定了基础。</p><h2 id="结果" tabindex="-1"><a class="header-anchor" href="#结果"><span>结果</span></a></h2><p><strong>1. 模型性能随规模扩展而持续提升</strong></p><p>作者首先展示了8个不同规模的模型在训练过程中的表现，发现无论是在训练损失还是实际任务中的表现，都随着模型参数的增长而呈现平滑的幂律提升趋势（见图 3.1 和图 3.3）。这表明大模型能够更好地吸收语言知识和上下文信息。</p><figure><img src="/assets/8-rG2dkxiy.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/assets/9-DeKVvVVX.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>2. GPT-3在语言建模和完形填空任务中的表现</strong></p><p>GPT-3在传统语言建模任务（如PTB）中零样本设定下创下新SOTA（PPL 20.5），远优于此前结果（PPL 35.8）。在LAMBADA数据集上，few-shot设置下准确率达到86.4%，比原SOTA高出18%（见图 3.2）。此外，在StoryCloze和HellaSwag等故事完形任务中，GPT-3也表现出明显的few-shot优势。</p><figure><img src="/assets/10-CJebFJ4K.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>3. 在封闭式问答任务中接近甚至超越SOTA</strong></p><p>GPT-3在TriviaQA、WebQuestions 和 Natural Questions这三个问答任务中，在没有使用外部检索信息（closed-book）或微调的前提下，仅通过few-shot设定就达到了与微调SOTA模型相当甚至更优的水平。尤其在TriviaQA中，few-shot得分达到71.2%，超越了一些基于检索系统的模型（如RAG）。</p><hr><p><strong>4. 多语言翻译能力显著提升</strong></p><p>尽管训练数据中非英语文本仅占7%，GPT-3在英法、英德、英罗等语言对的few-shot翻译任务中，已超越多项无监督NMT方法的表现（见表 3.4 和图 3.4）。尤其在<strong>翻译为英语</strong>的方向上，GPT-3展现出更强的语言建模优势。</p><figure><img src="/assets/11-B6soXUqp.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><br><figure><img src="/assets/12-SaytiX8v.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><br><hr><p><strong>5. 常识推理与Winograd类任务</strong></p><p>GPT-3在Winograd Schema Challenge中零样本即可取得88.3%的准确率，接近人类水平，且在更具挑战性的Winogrande数据集上few-shot得分达到77.7%，逼近fine-tuned大型模型表现（见图 3.5）。但对于如WiC（语义一致性）任务，GPT-3表现较差（仅为49.4%），显示在一些语义比较任务上仍存在明显短板。</p><figure><img src="/assets/13-CuLcXNz5.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>6. 阅读理解与逻辑推理任务表现不一</strong></p><p>在阅读理解任务中（如CoQA、DROP、QuAC、SQuADv2），GPT-3在few-shot设定下表现优异，尤其在CoQA中few-shot得分（85.0 F1）仅比人类低几分（见图 3.7）。但在结构化或需要多步推理的任务中（如DROP、RACE、QuAC），表现则不及微调模型，显示GPT-3对复杂语义结构的掌握仍有提升空间。</p><figure><img src="/assets/14-BMelAwkT.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>7. SuperGLUE整体表现良好，但有短板</strong></p><p>在SuperGLUE基准测试中，GPT-3在少样本（32个示例）设定下，在BoolQ、ReCoRD等任务上表现接近SOTA，在COPA任务中仅落后1-2分。但在如WiC、CB、MultiRC等任务上显著低于fine-tuned模型（见表 3.8 和图 3.8）。这说明GPT-3在识别细粒度语义差异上仍有明显不足。</p><figure><img src="/assets/15-C2niJ8JK.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="/assets/16-Ct-RER1-.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>8. NLI和Adversarial推理任务仍具挑战性</strong></p><p>在自然语言推理任务（如RTE和ANLI）中，即使是GPT-3 175B也只能在few-shot设定下稍高于随机水平（约33%），表现远不如fine-tuned模型（见图 3.9）。尤其在ANLI这种对抗性构建的数据集上，GPT-3展示了推理能力的不足。</p><figure><img src="/assets/17-DhnYO4dD.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>9. 在合成任务和灵活性测试中展现强大泛化能力</strong></p><p>GPT-3在设计的算术、字母重排、新词使用、语法纠错等任务中，只需提供极少量的示例就能成功完成，这表明其具有一定程度的推理和快速适应能力。这些任务测试了GPT-3的few-shot元学习能力，显示其对“任务模式”的提取并非依赖微调。</p><hr><p><strong>总结</strong></p><p>GPT-3在多数NLP任务中，在zero-, one-, few-shot设定下均展示了强大的任务适应能力，尤其在few-shot情境下，其表现多次逼近甚至超越传统fine-tuned模型。与此同时，一些任务（如对抗性推理、语义比较等）仍暴露出其推理深度与语言理解的局限，提示未来需在<strong>结构理解</strong>与<strong>逻辑泛化</strong>方面进一步改进。</p><h2 id="局限性" tabindex="-1"><a class="header-anchor" href="#局限性"><span>局限性</span></a></h2><p><strong>1. GPT-3 并非通用智能：能力分布不均</strong></p><p>尽管GPT-3在多个任务上取得了令人印象深刻的成绩，但作者明确指出，它并不是一个通用智能系统，其表现呈现出高度任务依赖性：<strong>在某些任务中可与SOTA模型媲美，但在其他任务（如自然语言推理、逻辑比较）中则表现平庸甚至接近随机</strong>。</p><p><mark><strong>这种“选择性优势”意味着GPT-3更像是一个巨大的“模式匹配引擎”，而非真正理解语言和任务的系统</strong>。</mark></p><hr><p><strong>2. 缺乏鲁棒的系统性泛化能力</strong></p><p>GPT-3的few-shot能力主要依赖于识别任务格式和输出模式，而不是进行真正意义上的概念抽象和泛化。作者指出，目前尚不清楚模型在推理任务中是否“学会”了新知识，还是只是记住了相似的训练样本。这种 <strong>泛化机制的模糊性</strong> 是目前元学习方法的一个重要限制。</p><hr><p><strong>3. Prompt依赖性强，输入微小变动影响大</strong></p><p>GPT-3对提示（prompt）形式和内容高度敏感。不同的措辞、问题格式甚至换行方式都可能造成性能大幅波动。</p><p>这意味着few-shot效果难以稳定复现，<strong>缺乏可控性与鲁棒性</strong>，在实际部署中可能导致意外错误。</p><hr><p><strong>4. 上下文窗口限制性能提升</strong></p><p>尽管GPT-3的上下文窗口扩大到2048 tokens，相比前代模型大幅提升，但这仍然限制了few-shot学习中可用的示例数量（尤其是在长文本任务中）。作者认为，<strong>有限上下文容量成为当前few-shot学习的“瓶颈”</strong>。</p><hr><p><strong>5. 无法利用结构化监督信号</strong></p><p>GPT-3完全不依赖梯度更新，因此无法像微调方法那样从结构化监督中持续优化。在特定任务上（如NER、结构化问答、程序生成等），GPT-3的表现明显弱于专门微调过的模型。这表明它在需要长期优化和知识整合的任务中仍有较大局限。</p><hr><p><strong>6. 推理与数学能力仍然有限</strong></p><p>GPT-3虽然能完成基础算术和简单逻辑题，但在 <strong>多步推理、抽象代数、数理一致性等方面</strong> 表现仍然较弱。这限制了其在金融、科研、工程等高精度领域的适用性。</p><hr><p><strong>7. 模型不可解释性问题严重</strong></p><p>GPT-3的推理过程完全由大量参数和非线性变换组成，目前尚无有效方式解释它为何会给出某一答案。这种不可解释性限制了其在高风险领域的应用，如医疗、法律、金融决策等。</p><hr><p><strong>总结</strong></p><p>虽然GPT-3在few-shot学习方面展现出极强的能力，但其本质仍是一个“超大规模、强记忆型的语言预测器”，而非具备深层理解与推理能力的系统。它面临的问题包括任务适应不均、prompt敏感性高、缺乏结构化监督利用能力、推理有限、以及缺乏透明性等。这些限制提示我们，在使用GPT-3及其衍生模型时，仍需谨慎评估其边界与适用性，并探索更强的系统性泛化能力和稳健性。</p><h2 id="相关工作" tabindex="-1"><a class="header-anchor" href="#相关工作"><span>相关工作</span></a></h2><p><strong>1. 从词向量到上下文表示的发展历程</strong></p><p>该部分首先回顾了自然语言处理（NLP）领域中语言表示学习的演进：</p><ul><li><p><strong>早期方法</strong>（如 word2vec、GloVe）关注学习固定词向量；</p></li><li><p><strong>后续方法</strong>（如 ELMo、ULMFiT）引入上下文，支持基于上下文的词表示；</p></li><li><p><strong>Transformer 时代</strong>：BERT、GPT 系列、XLNet 等模型将预训练语言模型推向主流，支持更广泛的下游任务，通过微调在多个任务上实现了SOTA。</p></li></ul><p>GPT-3继承了这一发展路线，并将参数规模推至前所未有的高度，强化了“无任务特定架构”的方法论。</p><hr><p><strong>2. 微调范式与任务适应能力的关系</strong></p><p>在GPT-3之前，大多数SOTA模型依赖于“预训练 + 微调”范式，即先在大语料上预训练，再在具体任务数据上进行监督微调（如BERT、T5）。这种方法虽然效果强大，但依赖大量任务标注数据，不利于迁移与泛化。</p><p>GPT-3的核心创新之一，是系统性地探索 <strong>无梯度更新的few-shot学习（in-context learning）</strong>，挑战了传统对“适应任务必须微调”的假设。</p><hr><p><strong>3. 元学习与few-shot学习的启发</strong></p><p>作者借鉴了 <strong>元学习（meta-learning）</strong> 的理念，即模型在“外循环”中获得广泛能力，在“内循环”中快速适应新任务。GPT-3通过扩展模型容量，在预训练阶段学习泛化模式，在推理阶段用文本输入指定任务，实质是一种“隐式元学习”机制。</p><p>这与Few-shot Learning领域中如MAML、Prototypical Networks、Matching Networks等方法异曲同工，但不同于它们使用结构明确的元任务，GPT-3完全通过文本学习并表达任务结构。</p><hr><p><strong>4. 模型规模扩展趋势与“Scaling Laws”</strong></p><p>文中引用了Kaplan等人提出的“<strong>神经语言模型的规模定律（Scaling Laws）</strong>”，即验证集损失随着模型规模、数据量和计算量按幂律缩放。在这一理论指导下，GPT-3以175B参数扩展至前代模型的10倍以上。</p><p>GPT-3验证了一个关键假设：<strong>few-shot能力会随着模型规模的增加而显著增强</strong>，补足了先前few-shot模型（如 GPT-2、CTRL、T5）表现不稳定的问题。</p><hr><p><strong>5. 多任务与多语言学习的基础</strong></p><p>GPT-3并未对每个任务建立单独的模型，而是通过单一语言建模目标，<strong>实现任务统一与跨任务迁移</strong>，呼应了T5等模型的“文本到文本”框架。同时，它在某种程度上也具备一定的多语言能力，尽管其非英语性能仍有限。</p><p>此外，文中提到了一些少量使用in-context设定的早期尝试（如 GPT-2 的zero-shot prompt），但GPT-3是首次系统性、大规模地在zero-, one-, few-shot条件下进行全面评估的工作。</p><hr><p><strong>总结</strong></p><p>GPT-3站在了词向量、上下文建模、transformer架构、微调范式、元学习和模型扩展趋势等多个重要研究方向的交汇点上。它在技术上并非从零出发，而是有机融合并推升了这些已有成果，<strong>将预训练语言模型从“参数调优”时代推向了“推理即编程”的新范式</strong>。</p><h2 id="结论" tabindex="-1"><a class="header-anchor" href="#结论"><span>结论</span></a></h2><p>作者指出，GPT-3 展示了强大的<strong>in-context learning（上下文学习）能力</strong>，在不进行任何梯度更新的前提下，仅通过自然语言提示和示例，即可在多种语言任务中实现从零样本到少样本的泛化，部分任务甚至达到或超越微调模型的水平。尽管仍存在局限，但结果表明：<strong>随着模型规模扩展，大规模语言模型在任务通用性与灵活性方面具有巨大潜力</strong>，为未来通用语言智能系统的发展提供了重要方向。</p></div><!----><!----><!----></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-06-26T07:47:23.000Z" data-allow-mismatch>2025/6/26 07:47</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 3076679680@qq.com">BinaryOracle</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/GPT-2%E8%AE%BA%E6%96%87.html" aria-label="GPT-2 论文"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="height" height="1em"></iconify-icon>GPT-2 论文</div></a><a class="route-link auto-link next" href="/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/InstructGPT%E8%AE%BA%E6%96%87.html" aria-label="InstructGPT 论文"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">InstructGPT 论文<iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="height" height="1em"></iconify-icon></div></a></nav><div id="comment" class="waline-wrapper vp-comment" vp-comment darkmode="false" style="display:block;"><!----></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">技术共建，知识共享</div><div class="vp-copyright">Copyright © 2025 BinaryOracle </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-D88RxMvE.js" defer></script>
  </body>
</html>
