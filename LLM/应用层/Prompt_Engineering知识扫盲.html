<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Prompt Engineering 知识扫盲","image":[""],"datePublished":"2025-06-17T00:00:00.000Z","dateModified":"2025-06-17T15:42:48.000Z","author":[{"@type":"Person","name":"BinaryOracle"}]}</script><meta property="og:url" content="https://mister-hope.github.io/LLM/%E5%BA%94%E7%94%A8%E5%B1%82/Prompt_Engineering%E7%9F%A5%E8%AF%86%E6%89%AB%E7%9B%B2.html"><meta property="og:site_name" content="MetaMind"><meta property="og:title" content="Prompt Engineering 知识扫盲"><meta property="og:description" content="Prompt Engineering 知识扫盲"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-06-17T15:42:48.000Z"><meta property="article:author" content="BinaryOracle"><meta property="article:tag" content="已发布"><meta property="article:tag" content="大模型应用层"><meta property="article:published_time" content="2025-06-17T00:00:00.000Z"><meta property="article:modified_time" content="2025-06-17T15:42:48.000Z"><title>Prompt Engineering 知识扫盲 | MetaMind</title><meta name="description" content="Prompt Engineering 知识扫盲">
    <link rel="preload" href="/assets/style-B9ka0LB5.css" as="style"><link rel="stylesheet" href="/assets/style-B9ka0LB5.css">
    <link rel="modulepreload" href="/assets/app-DROpRQtE.js"><link rel="modulepreload" href="/assets/Prompt_Engineering知识扫盲.html-DmJqY4Q1.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-DOKLXThH.js" as="script"><link rel="prefetch" href="/assets/intro.html-Cirjst2G.js" as="script"><link rel="prefetch" href="/assets/GREAT.html-DWJVf225.js" as="script"><link rel="prefetch" href="/assets/Grounding_3D_Object_Affordance.html-B1JOlsAO.js" as="script"><link rel="prefetch" href="/assets/IAGNet.html-CM-hZAkk.js" as="script"><link rel="prefetch" href="/assets/LASO.html-D227yDwD.js" as="script"><link rel="prefetch" href="/assets/index.html-DT5wziO9.js" as="script"><link rel="prefetch" href="/assets/简析PointNet__.html-Nj3VgSRX.js" as="script"><link rel="prefetch" href="/assets/简析PointNet.html-DnGx-9e7.js" as="script"><link rel="prefetch" href="/assets/index.html-C3cYRIma.js" as="script"><link rel="prefetch" href="/assets/ BLIP.html-BlxQrsaV.js" as="script"><link rel="prefetch" href="/assets/ALBEF.html-sXBqGiRx.js" as="script"><link rel="prefetch" href="/assets/InternVL-1.0.html-B9twDg3F.js" as="script"><link rel="prefetch" href="/assets/InternVl-1.5.html-DduKfXq7.js" as="script"><link rel="prefetch" href="/assets/LLaVA_1.0.html-CYdJEs_k.js" as="script"><link rel="prefetch" href="/assets/MoCo.html-D_NQsSLt.js" as="script"><link rel="prefetch" href="/assets/index.html-CULcMQ6U.js" as="script"><link rel="prefetch" href="/assets/VLMo.html-DnFbOa5y.js" as="script"><link rel="prefetch" href="/assets/VLMo代码解读.html-BZ59Oi55.js" as="script"><link rel="prefetch" href="/assets/ViLT.html-yQQYnSXT.js" as="script"><link rel="prefetch" href="/assets/多模态常用改编Bert实现.html-ByAYHN9_.js" as="script"><link rel="prefetch" href="/assets/多模态模型CLIP原理与图片分类，文字搜索图像实战演练.html-BFJfw0Ys.js" as="script"><link rel="prefetch" href="/assets/庖丁解牛BLIP2.html-BmG1rxLN.js" as="script"><link rel="prefetch" href="/assets/庖丁解牛VIT.html-ccozho9T.js" as="script"><link rel="prefetch" href="/assets/index.html-Czaft9zj.js" as="script"><link rel="prefetch" href="/assets/Attention运算过程中维度变换的理解.html-pY4jYkXg.js" as="script"><link rel="prefetch" href="/assets/Pytorch张量存储与访问原理.html-BaPuYVJA.js" as="script"><link rel="prefetch" href="/assets/index.html-DnBlgimZ.js" as="script"><link rel="prefetch" href="/assets/conda虚拟环境管理.html-DFhU_aN2.js" as="script"><link rel="prefetch" href="/assets/常用评估指标.html-EdnHr_64.js" as="script"><link rel="prefetch" href="/assets/数学知识点.html-CvprPgFt.js" as="script"><link rel="prefetch" href="/assets/深度学习中常见API记录(1).html-2QZ1Hj3L.js" as="script"><link rel="prefetch" href="/assets/深度学习中常见API记录(2).html-BvSI4GDH.js" as="script"><link rel="prefetch" href="/assets/语义分割中常用的损失函数.html-EBGhuUmv.js" as="script"><link rel="prefetch" href="/assets/通俗易懂解读BPE分词算法实现.html-CBClCbTc.js" as="script"><link rel="prefetch" href="/assets/index.html-AYa65fCr.js" as="script"><link rel="prefetch" href="/assets/Fine_Tuning知识扫盲.html-gqIq4V_b.js" as="script"><link rel="prefetch" href="/assets/LoRA微调系列.html-B437pObh.js" as="script"><link rel="prefetch" href="/assets/index.html-uawCfSVl.js" as="script"><link rel="prefetch" href="/assets/GPT-1论文.html-BDFU5uJx.js" as="script"><link rel="prefetch" href="/assets/GPT-2论文.html-BWQ1MOTV.js" as="script"><link rel="prefetch" href="/assets/GPT-3论文.html-CDNjBdN0.js" as="script"><link rel="prefetch" href="/assets/InstructGPT论文.html-BaUC7vpC.js" as="script"><link rel="prefetch" href="/assets/KV-Cache.html-BillLhQ3.js" as="script"><link rel="prefetch" href="/assets/LLaMA-1论文.html-CX1y2JjW.js" as="script"><link rel="prefetch" href="/assets/LLaMA-2论文.html-DWkxacMJ.js" as="script"><link rel="prefetch" href="/assets/index.html-tbX-aIqZ.js" as="script"><link rel="prefetch" href="/assets/RoBERTa论文.html-BfMdCdbc.js" as="script"><link rel="prefetch" href="/assets/从零实现Bert.html-InXPpoGq.js" as="script"><link rel="prefetch" href="/assets/位置编码.html-Bn9rLBkj.js" as="script"><link rel="prefetch" href="/assets/图解BERT.html-B-SjhzSb.js" as="script"><link rel="prefetch" href="/assets/图解Transformer.html-fxXnb-uJ.js" as="script"><link rel="prefetch" href="/assets/1.自动微分.html-j3kI4fiM.js" as="script"><link rel="prefetch" href="/assets/2.用自然的代码表达.html-CrdJWYST.js" as="script"><link rel="prefetch" href="/assets/3.高阶导数.html-DJfQpSK-.js" as="script"><link rel="prefetch" href="/assets/4.神经网络.html-C674Inef.js" as="script"><link rel="prefetch" href="/assets/index.html-BGHwSuOw.js" as="script"><link rel="prefetch" href="/assets/1.前置知识.html-C16A7nFu.js" as="script"><link rel="prefetch" href="/assets/2.大模型API.html-qvw8B1ZE.js" as="script"><link rel="prefetch" href="/assets/index.html-BgVRgv02.js" as="script"><link rel="prefetch" href="/assets/index.html-DPasxNks.js" as="script"><link rel="prefetch" href="/assets/index.html-BfDzlu1l.js" as="script"><link rel="prefetch" href="/assets/index.html-B5boTxfp.js" as="script"><link rel="prefetch" href="/assets/基础概念.html-B6hVwO5h.js" as="script"><link rel="prefetch" href="/assets/基础模型.html-lJ77UWLF.js" as="script"><link rel="prefetch" href="/assets/组合分析.html-BpgCU8Fj.js" as="script"><link rel="prefetch" href="/assets/BEiT.html-D9XeqbmK.js" as="script"><link rel="prefetch" href="/assets/BEiT模型代码解读.html-BQ2lQJ6K.js" as="script"><link rel="prefetch" href="/assets/DALL-E论文.html-Dyv9NmRK.js" as="script"><link rel="prefetch" href="/assets/DALL·E模型代码解读.html-_NCGT9tR.js" as="script"><link rel="prefetch" href="/assets/GAN学习笔记.html-lo1jcKSO.js" as="script"><link rel="prefetch" href="/assets/PixelCNN.html-BqYW1AQc.js" as="script"><link rel="prefetch" href="/assets/Pytorch实现VAE和CVAE.html-CYyGvQnc.js" as="script"><link rel="prefetch" href="/assets/index.html-c4j2duaE.js" as="script"><link rel="prefetch" href="/assets/Tutorial_VAE.html-DjDIfUXu.js" as="script"><link rel="prefetch" href="/assets/VQ-VAE.html-B-uE8e2J.js" as="script"><link rel="prefetch" href="/assets/404.html-B2MQJFRO.js" as="script"><link rel="prefetch" href="/assets/index.html-C53eJNug.js" as="script"><link rel="prefetch" href="/assets/index.html-fzmw1C1r.js" as="script"><link rel="prefetch" href="/assets/index.html-CHfQbney.js" as="script"><link rel="prefetch" href="/assets/index.html-CbQuxMHy.js" as="script"><link rel="prefetch" href="/assets/index.html-BJhUgvME.js" as="script"><link rel="prefetch" href="/assets/index.html-Uw6EbN8-.js" as="script"><link rel="prefetch" href="/assets/index.html-BYIZ2NHm.js" as="script"><link rel="prefetch" href="/assets/index.html-BUNpv-5v.js" as="script"><link rel="prefetch" href="/assets/index.html-DRY7iZ2U.js" as="script"><link rel="prefetch" href="/assets/index.html-CgcnIrPS.js" as="script"><link rel="prefetch" href="/assets/index.html-Pq9H4LV0.js" as="script"><link rel="prefetch" href="/assets/index.html-ClDtmUTK.js" as="script"><link rel="prefetch" href="/assets/index.html-Cpxv9Gg_.js" as="script"><link rel="prefetch" href="/assets/index.html-CoyyGWOD.js" as="script"><link rel="prefetch" href="/assets/index.html-9vIkQxBT.js" as="script"><link rel="prefetch" href="/assets/index.html-BsuVxXm6.js" as="script"><link rel="prefetch" href="/assets/index.html-C4kzVp21.js" as="script"><link rel="prefetch" href="/assets/index.html-HV1iZOjX.js" as="script"><link rel="prefetch" href="/assets/index.html-Cz4hAoCf.js" as="script"><link rel="prefetch" href="/assets/index.html-C2MTjJaT.js" as="script"><link rel="prefetch" href="/assets/index.html-oWr4crnh.js" as="script"><link rel="prefetch" href="/assets/index.html-wARsfW1k.js" as="script"><link rel="prefetch" href="/assets/index.html-j_b-rfVI.js" as="script"><link rel="prefetch" href="/assets/index.html-CrclDho4.js" as="script"><link rel="prefetch" href="/assets/index.html-BBi1h4fJ.js" as="script"><link rel="prefetch" href="/assets/index.html-9dD62maA.js" as="script"><link rel="prefetch" href="/assets/index.html-CX0LPNUK.js" as="script"><link rel="prefetch" href="/assets/index.html-7ry6aicY.js" as="script"><link rel="prefetch" href="/assets/index.html-0egf_IIG.js" as="script"><link rel="prefetch" href="/assets/index.html-557PvYu2.js" as="script"><link rel="prefetch" href="/assets/index.html-C9gCLw7b.js" as="script"><link rel="prefetch" href="/assets/index.html-DdJwoIEH.js" as="script"><link rel="prefetch" href="/assets/index.html-Boy0IOmW.js" as="script"><link rel="prefetch" href="/assets/index.html-BcYiDble.js" as="script"><link rel="prefetch" href="/assets/index.html-Dm8KG2gs.js" as="script"><link rel="prefetch" href="/assets/index.html-DVK5_Eew.js" as="script"><link rel="prefetch" href="/assets/index.html-CebSIJVE.js" as="script"><link rel="prefetch" href="/assets/index-BzBQJFYZ.js" as="script"><link rel="prefetch" href="/assets/flowchart-BKGBxuOE.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-HAlFmept.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/SearchResult-DPPwHnIO.js" as="script"><link rel="prefetch" href="/assets/waline-meta-l0sNRNKZ.js" as="script"><link rel="prefetch" href="/assets/component-9o_uPCr-.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><img class="vp-nav-logo" src="/assets/images/head.png" alt><!----><span class="vp-site-name hide-in-pad">MetaMind</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="主页"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:house" sizing="height" height="1em"></iconify-icon><!--]-->主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/LLM/" aria-label="大语言模型"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:book" sizing="height" height="1em"></iconify-icon><!--]-->大语言模型<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/MMLLM/" aria-label="多模态"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:laptop-code" sizing="height" height="1em"></iconify-icon><!--]-->多模态<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/3DVL/" aria-label="3D-Vision Language"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:eye" sizing="height" height="1em"></iconify-icon><!--]-->3D-Vision Language<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/other_direction/" aria-label="其他方向"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:computer" sizing="height" height="1em"></iconify-icon><!--]-->其他方向<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/open_projects/" aria-label="开源项目"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:star" sizing="height" height="1em"></iconify-icon><!--]-->开源项目<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/other/" aria-label="杂谈"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:sun" sizing="height" height="1em"></iconify-icon><!--]-->杂谈<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!----><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><button type="button" class="slimsearch-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="slimsearch-placeholder">搜索</div><div class="slimsearch-key-hints"><kbd class="slimsearch-key">Ctrl</kbd><kbd class="slimsearch-key">K</kbd></div></button><!--]--><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="主页"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:house" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->主页<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:book" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">大语言模型</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:robot" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">应用层</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/LLM/%E5%BA%94%E7%94%A8%E5%B1%82/Prompt_Engineering%E7%9F%A5%E8%AF%86%E6%89%AB%E7%9B%B2.html" aria-label="Prompt Engineering 知识扫盲"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Prompt Engineering 知识扫盲<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E5%BA%94%E7%94%A8%E5%B1%82/Fine_Tuning%E7%9F%A5%E8%AF%86%E6%89%AB%E7%9B%B2.html" aria-label="大模型微调(Fine Tuning)知识扫盲"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->大模型微调(Fine Tuning)知识扫盲<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/LLM/%E5%BA%94%E7%94%A8%E5%B1%82/LoRA%E5%BE%AE%E8%B0%83%E7%B3%BB%E5%88%97.html" aria-label="通俗易懂讲解LoRA微调"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->通俗易懂讲解LoRA微调<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:book" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">模型层</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:laptop-code" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">多模态</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:eye" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">3D-Vision Language</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:computer" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">其他方向</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:star" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">开源项目</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:sun" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">杂谈</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="关于我们"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:circle-info" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->关于我们<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="height" height="1em"></iconify-icon>Prompt Engineering 知识扫盲</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">BinaryOracle</span></span><span property="author" content="BinaryOracle"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/6/17</span><meta property="datePublished" content="2025-06-17T00:00:00.000Z"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color4 clickable" role="navigation">大模型应用层</span><!--]--><meta property="articleSection" content="大模型应用层"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color4 clickable" role="navigation">大模型应用层</span><span class="page-tag-item color4 clickable" role="navigation">已发布</span><!--]--><meta property="keywords" content="大模型应用层,已发布"></span><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 7 分钟</span><meta property="timeRequired" content="PT7M"></span><span class="page-word-info" aria-label="字数🔠" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon word-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="word icon" name="word"><path d="M518.217 432.64V73.143A73.143 73.143 0 01603.43 1.097a512 512 0 01419.474 419.474 73.143 73.143 0 01-72.046 85.212H591.36a73.143 73.143 0 01-73.143-73.143z"></path><path d="M493.714 566.857h340.297a73.143 73.143 0 0173.143 85.577A457.143 457.143 0 11371.566 117.76a73.143 73.143 0 0185.577 73.143v339.383a36.571 36.571 0 0036.571 36.571z"></path></svg><span>约 2023 字</span><meta property="wordCount" content="2023"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><p><code>Prompt Engineering 知识扫盲</code></p><!-- more --><h2 id="什么是prompt-engineering" tabindex="-1"><a class="header-anchor" href="#什么是prompt-engineering"><span>什么是Prompt Engineering?</span></a></h2><p>Prompt (提示词) 是人类发给各种人工智能模型、用以完成特定任务的指令。</p><p>Prompt Engineering (提示词工程) 是指我们为了让LLM能够更好地完成我们给它的任务，我们对Prompt进行优化、调整的过程。</p><p>可能会有人这么问，LLM已经这么强了，直接丢给它个指令，让他去执行就好了，为什么还需要Prompt Engineering呢？</p><p>确实像OpenAI的GPT4这样的LLM已经非常强了，很多简单的任务，我们直接用自然语言丢给他就去执行就好了。但是，对于一些复杂的问题，Prompt写得好不好，直接影响着大模型给出答案的正确与否。</p><p><strong>本质上，LLM是一个概率模型，它只是在给定的信息的前提下，给出概率最大的结果，它并不保证结果的合理性和正确性</strong>。</p><p>要让LLM给出的结果尽可能地合理、正确，这是我们使用LLM的人的职责。</p><p>这就是我们要去学习Prompt Engineering的原因。</p><h2 id="如何写好prompt" tabindex="-1"><a class="header-anchor" href="#如何写好prompt"><span>如何写好Prompt?</span></a></h2><h3 id="要明确-要具体" tabindex="-1"><a class="header-anchor" href="#要明确-要具体"><span>要明确,要具体</span></a></h3><p>我们发给LLM的批令，越明确、越具体，对于LLM越友好。</p><p>举个例子，我们让LLM对一段文字进行总结：</p><div class="vp-code-tabs"><div class="vp-code-tabs-nav" role="tablist"><button type="button" class="vp-code-tab-nav active" role="tab" aria-controls="v-0" aria-selected="true">Prompt 1</button><button type="button" class="vp-code-tab-nav" role="tab" aria-controls="v-1" aria-selected="false">Prompt 2</button></div><!--[--><div class="vp-code-tab active" id="v-0" role="tabpanel" aria-expanded="true"><div class="vp-code-tab-title">Prompt 1</div><!--[--><div class="language-json line-numbers-mode" data-highlighter="shiki" data-ext="json" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-json"><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">请给我总结一下这段文字的要点: 要总结的文字</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><!--]--></div><div class="vp-code-tab" id="v-1" role="tabpanel" aria-expanded="false"><div class="vp-code-tab-title">Prompt 2</div><!--[--><div class="language-json line-numbers-mode" data-highlighter="shiki" data-ext="json" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-json"><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">Prompt </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: 你的任务是帮我总结给定文字的要点，总结的要点请按下面的格式输出，这里&#39;###&#39;是分隔符：</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">###</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">- {{要点1}}</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">- {{要点2}}</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">- …</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">- {{要点n}}</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">###</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">，每个要点不要超出</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">个字。这是要你总结的文字：</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">###</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">要总结的文字</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">###</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><!--]--></div><!--]--></div><p>Prompt 2相比Prompt 1，对输出有了更加明确具体的要求，这样LLM输出的内容也会更加贴合我们的需求。另外，我们还用了&#39;###&#39;作为分隔符，进一步帮LLM明确要求。</p><p><strong>我们在给LLM发指令的时候，第一个关键点，就是我们要把给LLM做的任务尽可能细化，把要求尽可能明确、具体地描述出来</strong>。</p><h3 id="给llm更多的时间去思考" tabindex="-1"><a class="header-anchor" href="#给llm更多的时间去思考"><span>给LLM更多的时间去思考</span></a></h3><p>《思考快与慢》这本书里介绍了我们人类大脑的“系统1”和“ 系统2”。</p><p><strong>系统1是快思考系统，反应很快，但可能会出错。</strong></p><p><strong>系统2是慢思考系统，需要更长的反应时间，进行思考、推理，但结果会更加靠谱。</strong></p><p><strong>默认情况下，LLM就像是一个快思考的系统，他利用自己已掌握的知识，快速给出答案，但并不能保证结果的正确性。</strong></p><p><strong>为了让LLM给出的答案更加靠谱，我们需要通过Prompt Engineering 的方式，把LLM的慢思考调动起来。</strong></p><p>这就是“给LLM更多的时间去思考”背后的大致逻辑。</p><p>给LLM更多的时间去思考，一个简单的技巧是在你的Prompt后面，加上这样一句话“Let’s think step by step”。这句话会引导LLM，会去分步骤思考，效果会比不加这句话要好。</p><p>另一个技巧，在Prompt中加入一些例子，让LLM照着例子进行推理、思考。这一块的技巧性很强，我们在接下来的部分，介绍几种具体的技巧。</p><h4 id="思维链技术-chain-of-thought" tabindex="-1"><a class="header-anchor" href="#思维链技术-chain-of-thought"><span>思维链技术：Chain-of-Thought</span></a></h4><p>这是<a href="https://arxiv.org/abs/2201.11903" target="_blank" rel="noopener noreferrer">《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》</a>这篇论文里讲的一个Prompt Engineering的技巧。</p><p><strong>CoT(Chain-of-Thought) 的核心思想是，在Prompt中加入一些示例，来引导LLM展现出更好的推理能力。</strong></p><p>这里的关键是在Prompt中加入的示例，在这些示例中，我们会用自然语言描述一系列的推理过程，并最终引导出示例问题的正确结果。</p><p>这个过程有点像，我们教小孩做应用题，我们先给小孩子分析讲解一些示例。然后再把新的问题让小孩子来解决。小孩子根据从示例中学习到的推理、分析能力，最终解出了新的问题。</p><p>下面我们来看论文中给的CoT的例子：</p><figure><img src="/assets/1-Bk7HsVZM.png" alt="左侧是常规的Prompt，右侧是CoT Prompt" tabindex="0" loading="lazy"><figcaption>左侧是常规的Prompt，右侧是CoT Prompt</figcaption></figure><p>蓝色标记出的部分是提供给LLM的示例。绿色标记出的部分是LLM输出的推理过程。</p><p>在使用CoT这种Prompt Engineering技巧的时候，有几个注意点：</p><ol><li><p>CoT是LLM足够大（参数足够多，通常是在1000亿参数）时才涌现出来的能力。因此，在一些不够大的LLM上，CoT的效果并不明显。</p></li><li><p>通常，在Prompt中加入的示例不是1条，而是多条。具体要考虑解决的问题类型，以及Prompt的长度（因为LLM的Prompt长度通常都是有长度限制的）。</p></li></ol><h4 id="自一致性技术-self-consistency" tabindex="-1"><a class="header-anchor" href="#自一致性技术-self-consistency"><span>自一致性技术：Self-Consistency</span></a></h4><p>这是<a href="https://arxiv.org/abs/2203.11171" target="_blank" rel="noopener noreferrer">《Self-Consistency Improves Chain of Thought Reasoning in Language Models》</a> 这篇论文里讲的另一个Prompt Engineering的技巧。</p><p>Self-Consistency技术是在CoT技术的基础之上，进行的进一步优化，目的是为了让LLM的推理能力能够更进一步提升。</p><p>Self-Consistency的大致原理是这样：</p><ol><li><p>利用CoT Prompting技巧，写好Prompt；</p></li><li><p>不要让LLM只生成最合适的唯一一个结果，而是利用LLM结果的多样性，生成多种不同推理路径所得的结果的集合；</p></li><li><p>从结果集合中投票选择，选出投票最多的结果，做为最终的答案。</p></li></ol><p>这里有像我们人类解决问题的过程，如果我们用多种不同的方法去求解，大多数方法求解出来结果都一样的答案，那很有可能就是我们最终的答案。</p><p>下面我们来看论文中给的Self-Consistency的例子：</p><figure><img src="/assets/2-ByEsoDr6.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>在上面的例子中，虚线之上是标准的CoT的过程，它得到的结果是错的。虚线之下是Self-Consistency的过程，得到的三个答案中，有1个是错的，有2个是正确的。最终答案是大多数投票的结果，是正确的。</p><h4 id="从易至难技术-least-to-most" tabindex="-1"><a class="header-anchor" href="#从易至难技术-least-to-most"><span>从易至难技术：Least-to-Most</span></a></h4><p>这是<a href="https://arxiv.org/abs/2205.10625" target="_blank" rel="noopener noreferrer">《Least-to-Most Prompting Enables Complex Reasoning in Large Language Models》</a> 这篇论文中介绍的方法。</p><p><strong>CoT的特点是同类型问题的迁移思考，因此，如果给的例子是比较简单的问题，而给的问题却是难度大很多的问题，这时候CoT的效果就不尽如人意。</strong></p><p><strong>LtM(Least-to-Most)主是为了解决CoT这种从易到难的迁移能力不足而诞生的。</strong></p><p><strong>LtM的核心思想是：教LLM把复杂问题，拆解成一系列的简单问题，通过解决这一系列的简单问题，来最终得到复杂问题的结果。</strong></p><p>LtM的过程包含两个阶段：</p><ol><li><p>分解阶段：把复杂问题分解成一系列的简单子问题。这个阶段的Prompt中要包含分解问题的示例，要和分解的问题；</p></li><li><p>解决子问题阶段：这个阶段的Prompt中包含三部分内容：一是完整的LtM的例子；二是已解决的子问题及其答案列表；三是接下来要解答的子问题。</p></li></ol><p>这里也非常像我们人类学习解决复杂问题的过程，我们通过把复杂问题拆解成一个个的简单问题，通过把一个个的简单问题解决掉，最终把复杂问题也解决了。</p><p>下面我们来看看论文中LtM的例子：</p><figure><img src="/assets/3-Bg4k1rcB.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>从上图中，我们可以对LtM Prompting有一个直观的认知，通过引导LLM解决子问题，一步步引导LLM得出复杂问题的结果。</p></div><!----><!----><!----></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-06-17T15:42:48.000Z" data-allow-mismatch>2025/6/17 15:42</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 3076679680@qq.com">BinaryOracle</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><!----><a class="route-link auto-link next" href="/LLM/%E5%BA%94%E7%94%A8%E5%B1%82/Fine_Tuning%E7%9F%A5%E8%AF%86%E6%89%AB%E7%9B%B2.html" aria-label="大模型微调(Fine Tuning)知识扫盲"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">大模型微调(Fine Tuning)知识扫盲<iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="height" height="1em"></iconify-icon></div></a></nav><div id="comment" class="waline-wrapper vp-comment" vp-comment darkmode="false" style="display:block;"><!----></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">技术共建，知识共享</div><div class="vp-copyright">Copyright © 2025 BinaryOracle </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-DROpRQtE.js" defer></script>
  </body>
</html>
