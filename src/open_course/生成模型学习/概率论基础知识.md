---
title: 概率论基础知识
icon: file
category:
  - 生成模型
tag:
  - 编辑中
footer: 技术共建，知识共享
date: 2025-07-18
order: 1
author:
  - BinaryOracle
---

`概率论基础知识` 

<!-- more -->

> 随缘记录学习过程中所遇到的概率论相关知识点

# Bayes' rule

> Question One: What's the mean of Bayesian inference ?

“推理”（inference）是指“从样本数据出发，得出带有一定置信度的一般性结论的行为”。术语“贝叶斯”（Bayesian）则用来指代那些使用概率理论来表示“置信度”（即确定程度）并利用 贝叶斯公式(Bayes’ rule) 根据观察数据更新置信度的方法。

![](1/1.png)

贝叶斯公式本身非常简单：它是一个用于计算在给定观测数据 $Y = y$ 情况下，某个未知（或隐藏）变量 $H$ 可能取值的**概率分布**的公式：

$$
p(H = h \mid Y = y) = \frac{p(H = h)p(Y = y \mid H = h)}{p(Y = y)} \tag{2.51}
$$

这个公式可以由以下恒等式直接推出：

$$
p(h \mid y)p(y) = p(h)p(y \mid h) = p(h, y) \tag{2.52}
$$

而这个恒等式又来自于**概率的乘法法则**（product rule）。

在公式 (2.51) 中，术语 $p(H)$ 表示在我们看到任何数据之前，对 $H$ 的可能取值的了解；这被称为**先验分布**（prior distribution）。如果 $H$ 有 $K$ 个可能的取值，那么 $p(H)$ 就是一个包含 $K$ 个元素的向量，其中的概率和为 1。

术语 $p(Y \mid H = h)$ 表示在假设 $H = h$ 的前提下，我们对可能出现的结果 $Y$ 的分布，这被称为**观测分布**（observation distribution）。当我们将其评估于实际观测结果 $y$ 上时，就得到了函数 $p(Y = y \mid H = h)$，这被称为**似然函数**（likelihood）。<mark>需要注意的是，这其实是 $h$ 的函数，因为 $y$ 是已知的固定值，并且它不是一个概率分布，因为它的和不一定为 1 。</mark>

将先验概率 $p(H = h)$ 与似然函数 $p(Y = y \mid H = h)$ 相乘，可以得到**未归一化的联合分布** $p(H = h, Y = y)$。我们可以通过除以 $p(Y = y)$ 将其变为归一化分布，这个除数被称为**边际似然**（marginal likelihood），因为它是通过对未知量 $H$ 进行边际化（即求和）得到的：

$$
p(Y = y) = \sum_{h' \in H} p(H = h')p(Y = y \mid H = h') = \sum_{h' \in H} p(H = h', Y = y)
$$

通过对每个 $h$ 计算 $p(H = h, Y = y) / p(Y = y)$，我们就得到了**后验分布**（posterior distribution）$p(H = h \mid Y = y)$，它表示我们在看到数据 $y$ 之后，对 $H$ 可能取值的最新信念状态。

我们可以用一句话来总结贝叶斯公式：

$$
\text{posterior} \propto \text{prior} \times \text{likelihood} \tag{2.54}
$$

这里使用符号 $\propto$（“正比于”）表示我们省略了分母，因为它只是一个与 $H$ 无关的常数。

使用贝叶斯公式，根据观测数据对某一感兴趣的未知量的分布进行更新的过程，被称为**贝叶斯推理**（Bayesian inference）或**后验推理**（posterior inference），也可以简称为**概率推理**（probabilistic inference）。

> Bayes 公式人话版本:  “先有预期 + 接收信息 → 更新判断”

$$
P(H|Y) = \frac{P(Y|H) \cdot P(H)}{P(Y)}
$$

* $H$：隐藏的“真相”或假设

* $Y$：你观测到的信息

* $P(H)$：你在没有观察任何信息前对 H 的**先验信念**

* $P(Y|H)$：如果 H 是真的，你会看到这个信息的**可能性**

* $P(H|Y)$：你在看到 Y 后对 H 的**新判断（后验）**
