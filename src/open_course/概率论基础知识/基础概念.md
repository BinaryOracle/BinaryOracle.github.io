---
title: 概率论基础概念
icon: file
category:
  - 概率论
tag:
  - 已发布
footer: 技术共建，知识共享
date: 2025-07-22
order: 1
author:
  - BinaryOracle
---

`概率论基础概念(用到多少，学多少 =_=)` 

<!-- more -->

## 概率空间

我们将**概率空间**定义为三元组 $(\Omega, \mathcal{F}, P)$，其中：

* $\Omega$ 是**样本空间**，表示实验中所有可能的结果组成的集合；

* $\mathcal{F}$ 是**事件空间**，即 $\Omega$ 的所有子集的集合；

* $P$ 是**概率度量**，是一个从事件 $E \subseteq \Omega$ 到 $[0, 1]$ 区间数值的映射（即 $P: \mathcal{F} \rightarrow [0, 1]$），满足某些一致性要求。

## 离散随机变量

最简单的情况是实验的结果是**可数的**。例如，掷一个三面骰子，其三个面分别标记为 “A”、“B”、“C”（为了简洁，我们用3面而不是6面）。此时：

* 样本空间为 $\Omega = \{A, B, C\}$，表示所有可能的实验结果；

* 事件空间为 $\mathcal{F} = \{\emptyset, \{A\}, \{B\}, \{C\}, \{A,B\}, \{A,C\}, \{B,C\}, \{A,B,C\}\}$。

其中每一个**事件**就是事件空间中的一个元素。例如：

* 事件 $E_1 = \{A, B\}$ 表示骰子掷出面为 A 或 B；

* 事件 $E_2 = \{C\}$ 表示骰子掷出面为 C。

定义事件空间后，需要指定概率度量 $P$，即为事件空间中的每个集合赋予一个“权重”或“大小”。例如，设：

* $P[\{A\}] = \frac{2}{6}$，

* $P[\{B\}] = \frac{1}{6}$，

* $P[\{C\}] = \frac{3}{6}$。

则复合事件的概率可通过求和得到，例如：

* $P[\{A,B\}] = \frac{2}{6} + \frac{1}{6} = \frac{1}{2}$。

为简化记号，我们可以将每个样本空间中的结果映射为一个实数，这就定义了**随机变量**（random variable，记作 rv）：

> **随机变量 = 一个把“事件结果”映射为“数值”的函数，它本身不随机，随机的是它作用的输入（样本 $\omega$）。**

* $X : \Omega \rightarrow \mathbb{R}$，将每个结果 $\omega \in \Omega$ 映射为实数 $X(\omega)$。

例如，对三面骰子设：

* $X(A) = 1$，

* $X(B) = 2$，

* $X(C) = 3$。

再如，掷两次公平硬币，样本空间为：

* $\Omega = \{\omega_1 = (H,H), \omega_2 = (H,T), \omega_3 = (T,H), \omega_4 = (T,T)\}$。

设随机变量 $X$ 表示“正面出现次数”，则：

* $X(\omega_1) = 2$，

* $X(\omega_2) = 1$，

* $X(\omega_3) = 1$，

* $X(\omega_4) = 0$。

我们将随机变量可能的取值集合称为其**状态空间**，记作 $X(\Omega) = \mathcal{X}$。给定某个状态 $a$，定义：

$$
p_X(a) = P[X = a] = P[X^{-1}(a)]
$$

其中 $X^{-1}(a) = \{\omega \in \Omega | X(\omega) = a\}$，称为 $a$ 的原像。


> 你有一个随机变量 $X$，它是一个函数，从样本空间 $\Omega$ 映射到实数；给定某个输出值 $a$，我们关心的是：随机变量等于这个值的概率是多少，即 $P[X = a]$。
> </br>
> 但是：**随机变量是函数，它本身不“随机”，真正随机的是实验结果 $\omega \in \Omega$**。所以，要知道“$X = a$”的概率是多少，其实等价于问：
>  - **有多少个 $\omega$ 会导致 $X(\omega) = a$，而这些 $\omega$ 的总概率是多少？**

> 所以，我们这么定义：
> - $X^{-1}(a)$：是所有让 $X(\omega) = a$ 成立的样本点集合（这就是“原像”）；
> </br>
> - 然后，$\boxed{P[X = a] = P[X^{-1}(a)]}$：就是计算这些 $\omega$ 的总概率。

> **实验**：投两次硬币
> $$
> \Omega = \{(H, H), (H, T), (T, H), (T, T)\}
> $$
> 
> 定义随机变量 $X$：表示正面（H）的次数
>
> * $X(H, H) = 2$
> 
> * $X(H, T) = 1$
>
> * $X(T, H) = 1$
> 
> * $X(T, T) = 0$
> 
> 现在我们问：$\boxed{P[X = 1] = ?}$

> 这等价于找出：
> * 哪些 $\omega$ 会导致 $X(\omega) = 1$？
>
> * 答案是 $X^{-1}(1) = \{(H,T), (T,H)\}$
>
> 如果每个 $\omega$ 的概率都是 $1/4$，那么：
> $$
> P[X = 1] = P[X^{-1}(1)] = P[\{(H,T), (T,H)\}] = \frac{1}{4} + \frac{1}{4} = \frac{1}{2}
> $$

这里，$p_X$ 称为**概率质量函数**（pmf，probability mass function）。继续上述例子，掷两次硬币的 pmf 为：

* $p_X(0) = P[\{(T, T)\}] = \frac{1}{4}$，

* $p_X(1) = P[\{(T,H), (H,T)\}] = \frac{2}{4}$，

* $p_X(2) = P[\{(H,H)\}] = \frac{1}{4}$。

pmf 可用柱状图表示，也可用参数化函数表示。我们称 $p_X$ 为随机变量 $X$ 的**概率分布**。在上下文明确的情况下，常省略下标 $X$。

> **随机变量 $X$** 把**世界事件**映射成**数字**；
> </br>
> **pmf $p_X$** 把这些**数字**映射成它们发生的**概率**。
>$$
>\omega \xrightarrow{X} a \xrightarrow{p_X} P[X = a]
>$$

## 连续随机变量

我们也可以考虑结果为**连续值**的实验。这种情况下，假设样本空间是实数集合的子集：$\Omega \subseteq \mathbb{R}$，并定义随机变量为恒等函数 $X(\omega) = \omega$。

例如，测量某事件持续时间（单位：秒），设：

* $\Omega = \{t : 0 \le t \le T_{\text{max}}\}$。

由于该集合是不可数的，无法像离散情形那样枚举所有子集。因此，我们需要借助**Borel σ-代数**（Borel sigma-field）来定义事件空间。其定义如下：

集合 $\mathcal{F}$ 是一个 σ-代数（sigma-field）当且仅当：

1. $\emptyset \in \mathcal{F}$，且 $\Omega \in \mathcal{F}$；

2. 若 $E \in \mathcal{F}$，则其补集 $E^c \in \mathcal{F}$；

3. 若 $E_1, E_2, \ldots \in \mathcal{F}$，则 $\bigcup_{i=1}^\infty E_i$ 与 $\bigcap_{i=1}^\infty E_i$ 也属于 $\mathcal{F}$。

**Borel σ-代数**是由半开区间 $(-\infty, b]$ 生成的最小 σ-代数。通过这些区间的并、交和补运算，我们可以得到：

$$
(a, b),\ [a, b],\ (a, b],\ [a, b],\ \{b\},\quad -\infty \le a \le b \le \infty
$$

> 当我们讨论连续型随机变量（比如测量一个时间、距离或温度）时，它的**样本空间**是连续的，比如：
> 
> $$
> \Omega = [0, T_{\text{max}}]
> $$
> 
> 在这种连续的空间里，所有可能的“事件”不是像离散情况那样简单地枚举出来的（比如 $\{H,T\}$），而可能是“无限多种可能的区间组合”。
> </br>
> 比如我们可能想表示这些事件：
> 
> * “温度在 1 到 2 度之间” → 区间 (1, 2)
> 
> * “时间小于 5 秒” → 区间 $(0, 5]$
> 
> * “温度是 3 度或 7 度” → $\{3,7\}$
> 
> * “测量值是无理数” → 这也算是一类事件！
> 
> 但是问题是：**我们不能对“所有”这样的集合都定义概率！**
> </br>
> 因为某些集合太“奇怪”或太“复杂”，会导致概率的定义出现矛盾或不收敛。
> </br>
> 所以我们需要一个**规则体系**来规定“我们只对哪些集合定义概率” ——> 这个规则体系就是**σ-代数（sigma-field）**。

> σ-代数是一个集合的集合（简单理解：是**你允许讨论的事件的全集合**），它必须满足以下三条规则（你可以把它们理解成“合理事件空间”的要求）：
> 1. **包含整个样本空间和空集**
> 
>     -  你总得允许“什么都不发生”（空事件）
>     - 也得允许“一定会发生”（整个样本空间）
> 2. **如果你能谈某个事件，那它的补集你也得能谈**
>     - 比如：“温度小于 30 度” 这个事件存在，那“温度不小于 30 度”这个事件也应该存在
> 3. **如果你能谈一堆事件，那它们的并集和交集也得能谈**
>     -  比如你能谈“温度在 (0,1)”、“温度在 (1,2)”……，那“温度在 (0,2)”这种组合你也得能谈

> 换句话说：σ-代数就是一种**封闭的事件系统**，允许你用基本事件构造更复杂事件，但不会跑出系统之外。
> </br>
> Borel σ-代数是专门为实数空间（$\mathbb{R}$）设计的一种 σ-代数，用来处理**实数范围内的“正常”区间事件**。
> </br>
> 它的定义是：
> </br>
> **Borel σ-代数是由所有形如 $(-\infty, b]$ 的区间生成的最小 σ-代数。**
> </br>
> 也就是说，它从一些基本的“区间事件”出发，通过反复地做并集、交集、补集操作，构造出你所需要的所有“常见事件”。
> </br>
> 比如：
> 
> * $(a, b)$：开区间
> 
> * $[a, b]$：闭区间
> 
> * $[a, b)$、$(a, b]$：半开区间
> 
> * $\{c\}$：单点集
> 
> * 任意有限/可数个区间并集交集……
> 
> 这些都属于 Borel σ-代数。
> </br>
> 你可以把它理解成：**我们定义概率，只在这些“结构正常的区间组合”上做，不碰那些太反直觉或病态的集合。**
> </br>
> 总结: Borel σ-代数是一种你**可以安全地讨论概率**的“事件集合体系”，它由一些基本区间（比如 $(-\infty, b]$）出发，闭包得到所有“常规可测的集合”。

在持续时间的例子中，可进一步限制事件空间只包含区间 $[a, b]$，其中 $0 \le a \le b \le T_{\text{max}}$。

为定义概率度量，我们为每个 $x \in \Omega$ 赋一个非负权重 $p_X(x) \ge 0$，称为**概率密度函数**（pdf，probability density function）。

对于事件 $E = [a, b]$，概率由积分给出：

$$
P([a, b]) = \int_E dP = \int_a^b p(x) dx
$$

还可以定义**累积分布函数**（cdf）：

$$
P_X(x) \triangleq P[X \le x] = \int_{-\infty}^x p_X(x') dx'
$$

从中可以计算区间概率：

$$
P([a, b]) = P(a \le X \le b) = P_X(b) - P_X(a)
$$

“概率分布”一词既可以指 pdf $p_X$，也可以指 cdf $P_X$，甚至指概率度量 $P$ 本身。

上述定义也可推广到多维空间 $\Omega \subseteq \mathbb{R}^n$，以及函数等更复杂的样本空间。

## 概率公理

与事件空间相关联的概率规律，必须遵循**概率公理（Kolmogorov 公理）**，具体如下：

1. **非负性（Non-negativity）**：
   
   对任意事件 $E \subseteq \Omega$，有

   $$
   P[E] \ge 0
   $$

2. **规范性（Normalization）**：
   
   整个样本空间的概率为 1：

   $$
   P[\Omega] = 1
   $$

3. **可加性（Additivity）**：
   
   对于任意一列**两两互不相交**（即互斥）的事件 $\{E_1, E_2, \dots\}$，有

   $$
   P\left[\bigcup_{i=1}^{\infty} E_i\right] = \sum_{i=1}^{\infty} P[E_i] \tag{2.6}
   $$

   在有限的情况下，比如只有两个互斥事件 $E_1$ 和 $E_2$，上述公式简化为：

   $$
   P[E_1 \cup E_2] = P[E_1] + P[E_2] \tag{2.7}
   $$

   这个公式对应的是“事件 $E_1$ 或 $E_2$ 发生”的概率（前提是这两个事件是互斥的）。


从这些公理可以推导出一些常用结论：

> 补集规则（Complement Rule）：

$$
P[E^c] = 1 - P[E] \tag{2.8}
$$

其中，$E^c = \Omega \setminus E$ 表示事件 $E$ 的补集。

这个结论来自于：

$$
P[\Omega] = P[E \cup E^c] = P[E] + P[E^c] = 1
$$


> 其他可推出的结论：

* $P[E] \le 1$：可通过反证法证明

* $P[\emptyset] = 0$：可由补集规则推出，当 $E = \Omega$ 时，$E^c = \emptyset$，所以 $P[\emptyset] = 1 - P[\Omega] = 0$


> 加法规则（Addition Rule）：

对于任意两个事件（**不要求互斥**），有：

$$
P[E_1 \cup E_2] = P[E_1] + P[E_2] - P[E_1 \cap E_2] \tag{2.9}
$$

这个公式适用于任意两个事件，即使它们可能有重叠。

## 条件概率

考虑两个事件 $E_1$ 和 $E_2$。如果 $P[E_2] \ne 0$，则定义事件 $E_1$ 在 $E_2$ 已经发生的条件下的**条件概率**为：

$$
P[E_1 \mid E_2] \triangleq \frac{P[E_1 \cap E_2]}{P[E_2]} \tag{2.10}
$$

根据这个定义，可以得到**乘法法则（multiplication rule）**：

$$
P[E_1 \cap E_2] = P[E_1 \mid E_2] P[E_2] = P[E_2 \mid E_1] P[E_1] \tag{2.11}
$$

条件概率衡量的是：**在事件 $E_2$ 已经发生的前提下，事件 $E_1$ 发生的可能性有多大**。

然而，如果两个事件是**无关的**，那么一个事件的发生不会改变另一个事件的概率。更形式化地说，若满足以下条件，则称 $E_1$ 与 $E_2$ 是**独立事件（independent events）**：

$$
P[E_1 \cap E_2] = P[E_1] \cdot P[E_2] \tag{2.12}
$$

若 $P[E_1] > 0$ 且 $P[E_2] > 0$，上式等价于：

* $P[E_1 \mid E_2] = P[E_1]$，或

* $P[E_2 \mid E_1] = P[E_2]$

同理，若在某个事件 $E_3$ 已知的条件下，事件 $E_1$ 与 $E_2$ 满足下式：

$$
P[E_1 \cap E_2 \mid E_3] = P[E_1 \mid E_3] \cdot P[E_2 \mid E_3] \tag{2.13}
$$

则称 $E_1$ 和 $E_2$ **在给定 $E_3$ 的条件下是条件独立的（conditionally independent）**。

### 全概率公式（Law of total probability）

根据条件概率的定义，还可以推导出**全概率公式**：

若集合 $\{A_1, A_2, \dots, A_n\}$ 构成样本空间 $\Omega$ 的一个**划分（partition）**，那么对于任意事件 $B \subseteq \Omega$，有：

$$
P[B] = \sum_{i=1}^{n} P[B \mid A_i] \cdot P[A_i] \tag{2.14}
$$

