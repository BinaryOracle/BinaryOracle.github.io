---
icon: file
category:
  - 3D-VL
  - 3D Affordance
tag:
  - 3D-VL
  - 3D Affordance
  - ç¼–è¾‘ä¸­
footer: æŠ€æœ¯å…±å»ºï¼ŒçŸ¥è¯†å…±äº«
date: 2025-05-30
cover: assets/cover/LASO.png
author:
  - BinaryOracle
---

`LASO: Language-guided Affordance Segmentation on 3D Object è®ºæ–‡ä»£ç è§£è¯»ä¸å¤ç°` 

<!-- more -->

# LASO æ¨¡å‹ä»£ç è§£è¯»ä¸å¤ç°

> è®ºæ–‡: [https://openaccess.thecvf.com/content/CVPR2024/papers/Li_LASO_Language-guided_Affordance_Segmentation_on_3D_Object_CVPR_2024_paper.pdf](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_LASO_Language-guided_Affordance_Segmentation_on_3D_Object_CVPR_2024_paper.pdf)
> ä»£ç : [https://github.com/yl3800/LASO](https://github.com/yl3800/LASO)


è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€é¡¹æ–°çš„ä»»åŠ¡å’Œä¸€ä¸ªé…å¥—çš„æ•°æ®é›†ï¼Œæ—¨åœ¨æ¨åŠ¨ **è¯­è¨€å¼•å¯¼ä¸‹çš„** 3Då¯¹è±¡åŠŸèƒ½åŒºåŸŸåˆ†å‰²ï¼ˆLanguage-guided Affordance Segmentation on 3D Object, ç®€ç§° LASOï¼‰ã€‚

## æ•°æ®é›†

### 1. åŸºç¡€æ•°æ®æ¥æº

æ•°æ®é›†åŸºäº **3D-AffordanceNet** æä¾›çš„ç‚¹äº‘å’ŒåŠŸèƒ½åŒºåŸŸæ ‡æ³¨æ„å»ºï¼š

- æ¯ä¸ªç‰©ä½“éƒ½ä»¥ç‚¹äº‘å½¢å¼è¡¨ç¤ºï¼›
- ç‚¹äº‘ä¸­çš„æ¯ä¸ªç‚¹è¢«æ ‡æ³¨ä¸ºæ”¯æŒä¸€ä¸ªæˆ–å¤šä¸ªåŠŸèƒ½ç±»å‹ï¼ˆmulti-class affordance labelsï¼‰ï¼Œä¾‹å¦‚ graspã€openã€liftã€move ç­‰ï¼›
- è¿™äº›åŠŸèƒ½æ ‡æ³¨æ˜¯äººå·¥æ ‡æ³¨çš„ï¼Œå…·æœ‰è¯­ä¹‰æ„ä¹‰ï¼›

> **ä¸ºä»€ä¹ˆä½¿ç”¨ 3D-AffordanceNetï¼Ÿ** 
> - å› ä¸ºå®ƒæä¾›äº†é«˜è´¨é‡çš„ç‚¹äº‘å’ŒåŠŸèƒ½æ ‡æ³¨ï¼Œèƒ½å¤Ÿå¾ˆå¥½åœ°æ”¯æŒ LASO çš„ç›®æ ‡ï¼šæ ¹æ®è‡ªç„¶è¯­è¨€é—®é¢˜æ‰¾å‡ºä¸ä¹‹ç›¸å…³çš„åŠŸèƒ½åŒºåŸŸã€‚


### 2. æ„å»ºé—®é¢˜ï¼ˆQuestion Craftingï¼‰

1. **é€‰å–ç‰©ä½“-åŠŸèƒ½ç»„åˆ**ï¼š
   - ä» 3D-AffordanceNet ä¸­é€‰å–äº† **58 ç§ç‰©ä½“-åŠŸèƒ½ç»„åˆ**ï¼ˆå¦‚ mug-graspã€door-open ç­‰ï¼‰ï¼›
2. **æ‰‹å·¥è®¾è®¡é—®é¢˜**ï¼š
   - å¯¹æ¯ç§ç»„åˆæ‰‹å·¥ç¼–å†™ **5 ä¸ªä»£è¡¨æ€§é—®é¢˜**ï¼›
3. **ä½¿ç”¨ GPT-4 æ‰©å±•ç”Ÿæˆæ›´å¤šé—®é¢˜**ï¼š
   - ä½¿ç”¨ GPT-4 ä¸ºæ¯ä¸ªç»„åˆé¢å¤–ç”Ÿæˆ **10 ä¸ªé—®é¢˜**ï¼›
   - æ€»å…±å¾—åˆ° **870 ä¸ªä¸“å®¶è®¾è®¡çš„é—®é¢˜**ï¼ˆ58 Ã— 15 = 870ï¼‰ï¼›


![Affordance-Questionæ•°æ®å¯è§†åŒ–](LASO/1.png)   



åœ¨æ‰©å±•è¿‡ç¨‹ä¸­ï¼ŒGPT-4 ç”Ÿæˆçš„é—®é¢˜éµå¾ªä»¥ä¸‹ä¸‰ä¸ªå…³é”®åŸåˆ™ï¼Œä»¥ç¡®ä¿é—®é¢˜å¤šæ ·æ€§å’Œè¯­ä¹‰ä¸°å¯Œæ€§ï¼š

| åŸåˆ™ | æè¿° |
|------|------|
| **Contextual Enrichmentï¼ˆä¸Šä¸‹æ–‡ä¸°å¯ŒåŒ–ï¼‰** | æ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡ç»†èŠ‚ï¼Œä½¿é—®é¢˜æ›´å…·ä½“åœ°è¿æ¥ç›®æ ‡å¯¹è±¡çš„åŠŸèƒ½ï¼›<br>ä¾‹ï¼šå°† â€œGrasping scissors: top choice?â€ æ”¹ä¸º â€œIdentify the key points on the scissors that ensure successful grasping.â€ |
| **Concise Phrasingï¼ˆç®€æ´è¡¨è¾¾ï¼‰** | æç‚¼é—®é¢˜æœ¬è´¨ï¼Œä½¿å…¶ç®€çŸ­ä½†ä»æœ‰æ„ä¹‰ï¼› |
| **Structural Diversityï¼ˆç»“æ„å¤šæ ·æ€§ï¼‰** | ä½¿ç”¨ä¸åŒå¥å¼ç»“æ„ï¼ˆç–‘é—®å¥ã€é™ˆè¿°å¥ç­‰ï¼‰ï¼Œé˜²æ­¢æ¨¡å‹åå‘ç‰¹å®šå¥å¼æˆ–é•¿åº¦ï¼› |

### 3. æ ‡æ³¨ GT Maskï¼ˆGround Truth Maskï¼‰

å¯¹äºæ¯ä¸ªé—®é¢˜ï¼Œç»“åˆå…¶å¯¹åº”çš„åŠŸèƒ½ç±»å‹å’ŒåŸå§‹ç‚¹äº‘æ ‡æ³¨ä¿¡æ¯ï¼Œæ„é€ å‡ºå¯¹åº”çš„äºŒå€¼æ©ç  `gt_mask`ï¼š

- æ¯ä¸ªç‚¹æ˜¯å¦å±äºå½“å‰é—®é¢˜æè¿°çš„åŠŸèƒ½åŒºåŸŸï¼›
- `gt_mask` æ˜¯ `(N,)` å½¢çŠ¶çš„ä¸€ç»´æ•°ç»„ï¼Œå…¶ä¸­ N æ˜¯ç‚¹æ•°ï¼›
- æ•°å€¼å¯ä»¥æ˜¯ 0/1ï¼ˆbinary maskï¼‰ï¼Œä¹Ÿå¯ä»¥æ˜¯**è½¯æ ‡ç­¾ï¼ˆsoft labelï¼‰**ï¼Œè¡¨ç¤ºç‚¹å±äºè¯¥åŠŸèƒ½åŒºåŸŸçš„æ¦‚ç‡ï¼›
- è½¯æ ‡ç­¾é€šå¸¸ç”¨äºè¾¹ç•Œæ¨¡ç³ŠåŒºåŸŸï¼Œåæ˜ ç‚¹ä¸åŠŸèƒ½æ ¸å¿ƒåŒºåŸŸçš„è·ç¦»è¿œè¿‘ï¼›

> ğŸ’¡ æ³¨æ„ï¼šè¿™äº›åŠŸèƒ½æ ‡ç­¾ä»…ç”¨äºæ„é€ é—®é¢˜å’Œå®šä½æ­£ç¡®åŠŸèƒ½åŒºåŸŸï¼Œåœ¨è®­ç»ƒå’Œæµ‹è¯•ä¸­ä¸ä½œä¸ºæ˜¾å¼ç›‘ç£ä¿¡å·ã€‚

### 4. æ•°æ®é›†ç»„ç»‡æ–¹å¼

æ•°æ®æ€»é‡ï¼š

- **æ€»æ ·æœ¬æ•°**ï¼š19,751 ä¸ªç‚¹äº‘-é—®é¢˜é…å¯¹ï¼›
- **ç‰©ä½“ç±»åˆ«æ•°**ï¼š23 ç±»ï¼›
- **åŠŸèƒ½ç±»å‹æ•°**ï¼š17 ç±»ï¼›
- **é—®é¢˜æ€»æ•°**ï¼š870 ä¸ªä¸“å®¶è®¾è®¡çš„é—®é¢˜ï¼›
- **æ¯ä¸ªç‰©ä½“ç±»åˆ«å¯æœ‰å¤šä¸ªå½¢çŠ¶å®ä¾‹**ï¼›
- **ä¸€ä¸ªé—®é¢˜å¯ä»¥ä½œç”¨äºå¤šä¸ªç‰©ä½“ç±»åˆ«**ï¼ˆæ³›åŒ–èƒ½åŠ›ï¼‰ï¼›

æ•°æ®é›†è®¾ç½®ï¼ˆä¸¤ç§æ¨¡å¼ï¼‰ï¼š

ğŸ”¹ Seenï¼ˆè§è¿‡ï¼‰

- è®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µå…±äº«ç›¸ä¼¼çš„ç‰©ä½“ç±»åˆ«å’ŒåŠŸèƒ½ç±»å‹çš„åˆ†å¸ƒï¼›
- ç›®çš„æ˜¯è¯„ä¼°æ¨¡å‹åœ¨ç†Ÿæ‚‰åœºæ™¯ä¸‹çš„è¡¨ç°ï¼›

ğŸ”¹ Unseenï¼ˆæœªè§ï¼‰

- æŸäº›åŠŸèƒ½ç±»å‹åœ¨ç‰¹å®šç‰©ä½“ç±»åˆ«ä¸‹ä¼šä»è®­ç»ƒé›†ä¸­çœç•¥ï¼Œä½†åœ¨æµ‹è¯•é›†ä¸­ä¿ç•™ï¼›
- **ç›®çš„æ˜¯æµ‹è¯•æ¨¡å‹å¯¹æ–°ç»„åˆçš„æ³›åŒ–èƒ½åŠ›ï¼›**
- ä¾‹å¦‚ï¼šæ¨¡å‹åœ¨è®­ç»ƒæœŸé—´å­¦ä¼šäº†æŠ“å–åŒ…å’Œæ¯å­ï¼Œä½†æµ‹è¯•æ—¶è¦æ±‚â€œæŠ“å–è€³æœºâ€â€”â€”è¿™æ˜¯è®­ç»ƒä¸­æœªæ›¾é‡åˆ°è¿‡çš„åŠŸèƒ½-ç‰©ä½“ç»„åˆï¼›

æ•°æ®åˆ’åˆ†æ–¹å¼ï¼š

| åˆ†åŒº | ç‰©ä½“ç±»åˆ«æ•° | é—®é¢˜æ•° | æ ·æœ¬æ•° |
|------|-------------|--------|---------|
| Train | 6883 | 638 | 16,120 |
| Val | 516 | 58 | 1,215 |
| Test | 1035 | 174 | 2,416 |

### 5. æ•°æ®å¢å¼ºä¸é…å¯¹ç­–ç•¥

è®­ç»ƒé˜¶æ®µï¼š

- æ¯æ¬¡è¿­ä»£ä¸­ï¼Œæ¯ä¸ªå½¢çŠ¶å®ä¾‹éšæœºåŒ¹é…ä¸€ä¸ªä¸å…¶åŠŸèƒ½ç±»å‹ä¸€è‡´çš„é—®é¢˜ï¼›
- éšæœºé…å¯¹ä½¿æ¨¡å‹æš´éœ²äºå„ç§è¯­ä¹‰ä¸Šä¸‹æ–‡ä¸­ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ï¼›

æ¨ç†é˜¶æ®µï¼ˆéªŒè¯ & æµ‹è¯•ï¼‰ï¼š

- é—®é¢˜é…å¯¹æ˜¯å›ºå®šçš„ï¼›
- æ‰€æœ‰é—®é¢˜ä¸“å±äºè¯„ä¼°é˜¶æ®µï¼Œä¸åœ¨è®­ç»ƒä¸­é€éœ²ï¼›
- ç¡®ä¿æ¨ç†ä¸€è‡´æ€§ï¼Œä¿æŒè¯„ä¼°å®Œæ•´æ€§ï¼›


### 6. æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ¥è‡ªè®ºæ–‡å›¾3ï¼‰

| ç»´åº¦ | å†…å®¹ |
|------|------|
| åŠŸèƒ½ç±»å‹ | 17 ç±»ï¼Œå¦‚ graspã€openã€liftã€move ç­‰ |
| ç‰©ä½“ç±»åˆ« | 23 ç±»ï¼Œå¦‚ mugã€microwaveã€chairã€door ç­‰ |
| ç‰©ä½“-åŠŸèƒ½ç»„åˆ | 58 ç§å”¯ä¸€ç»„åˆï¼ˆobject-affordance pairsï¼‰ |
| é—®é¢˜æ€»æ•° | 870 ä¸ªå®šåˆ¶åŒ–é—®é¢˜ |
| ç‚¹äº‘-é—®é¢˜é…å¯¹ | 19,751 å¯¹ |
| ç‚¹äº‘æ¥æº | æ¥è‡ª 3D-AffordanceNetï¼Œæ¯ä¸ªç‚¹äº‘çº¦ 2048 ä¸ªç‚¹ |

### 7. ä»£ç å®ç°

**æ•°æ®é›†åˆå§‹åŒ–çš„æ ¸å¿ƒä»£ç å®ç°å¦‚ä¸‹:**

```python
class AffordQ(Dataset):

    def __init__(self,
                 split='train',
                 **kwargs
                 ):
        # æ•°æ®é›†å­˜æ”¾ç›®å½•         
        data_root='LASO_dataset'
        # æ•°æ®é›†ç±»å‹: è®­ç»ƒé›†ï¼Œè¯„ä¼°é›†ï¼Œæµ‹è¯•é›†
        self.split = split
        # æ‰€æ”¯æŒçš„23ç§ç‰©ä½“ç±»å‹å’Œ17ç§åŠŸèƒ½ç±»å‹ 
        classes = ["Bag", "Bed", "Bowl","Clock", "Dishwasher", "Display", "Door", "Earphone", "Faucet",
            "Hat", "StorageFurniture", "Keyboard", "Knife", "Laptop", "Microwave", "Mug",
            "Refrigerator", "Chair", "Scissors", "Table", "TrashCan", "Vase", "Bottle"]
        
        afford_cl = ['lay','sit','support','grasp','lift','contain','open','wrap_grasp','pour', 
                     'move','display','push','pull','listen','wear','press','cut','stab']
        # å»ºç«‹ç‰©ä½“ç±»å‹å’ŒåŠŸèƒ½ç±»å‹çš„ç´¢å¼•æ˜ å°„å…³ç³»ï¼Œç¥ç»ç½‘ç»œæ¨¡å‹åªè®¤è¯†æ•°å­— 
        self.cls2idx = {cls.lower():np.array(i).astype(np.int64) for i, cls in enumerate(classes)}
        self.aff2idx = {cls:np.array(i).astype(np.int64) for i, cls in enumerate(afford_cl)}
        # åŠ è½½æ ‡æ³¨æ•°æ®
        with open(os.path.join(data_root, f'anno_{split}.pkl'), 'rb') as f:
            self.anno = pickle.load(f)
        # åŠ è½½ç‚¹äº‘æ•°æ®
        with open(os.path.join(data_root, f'objects_{split}.pkl'), 'rb') as f:
            self.objects = pickle.load(f)

        # åŠ è½½58ç§ç‰©ä½“-åŠŸèƒ½ç»„åˆçš„æ ‡æ³¨æ•°æ® (æ•°æ®ç»„ç»‡å½¢å¼ï¼Œå‚è€ƒä¸Šæ–‡çš„ Affordance-Questionæ•°æ®å¯è§†åŒ–å›¾)
        self.question_df = pd.read_csv(os.path.join(data_root, 'Affordance-Question.csv'))

        # sort anno by object class and affordance type -- éå†æ ‡æ³¨æ•°æ®åˆ—è¡¨
        self.sort_anno ={}
        for item in sorted(self.anno, key=lambda x: x['class']):
            # è·å–å½“å‰æ ·æœ¬çš„ç‰©ä½“ç±»åˆ«å’Œç‰©ä½“ä¿¡æ¯å€¼: ç‚¹äº‘ID, åŠŸèƒ½åŒºåŸŸæ©ç , åŠŸèƒ½ç±»åˆ«
            key = item['class']
            value = {'shape_id': item['shape_id'], 'mask': item['mask'], 'affordance': item['affordance']}
            
            # æ¯ç§ç‰©ä½“å¯ä»¥å¯¹åº”å¤šç§å½¢çŠ¶å®ä¾‹å’ŒåŠŸèƒ½ç±»åˆ«
            if key not in self.sort_anno:
                # å¦‚æœå½“å‰ç‰©ä½“ç±»åˆ«ä¸åœ¨æ’åºåçš„å­—å…¸ä¸­ï¼Œç›´æ¥æ·»åŠ 
                self.sort_anno[key] = [value]
            else:
                # å¦‚æœå½“å‰ç‰©ä½“ç±»åˆ«åœ¨æ’åºåçš„å­—å…¸ä¸­ï¼Œå°†å½“å‰æ ·æœ¬çš„ç‰©ä½“ä¿¡æ¯å€¼è¿½åŠ åˆ°å¯¹åº”åˆ—è¡¨ä¸­
                self.sort_anno[key].append(value)
```
åŠ è½½çš„æ ‡æ³¨æ•°æ®ä¸­æ¯ä¸ªæ ·æœ¬çš„ç»„ç»‡å½¢å¼å¦‚ä¸‹:
- shape_id ï¼šç‚¹äº‘ID
- class ï¼šç‰©ä½“ç±»åˆ«ï¼ˆå¦‚bedï¼‰
- affordance ï¼šåŠŸèƒ½ç±»åˆ«ï¼ˆå¦‚layï¼‰
- mask ï¼šåŠŸèƒ½åŒºåŸŸæ©ç ï¼ˆç‚¹çº§åˆ«æ ‡æ³¨ï¼‰

![æ ‡æ³¨æ•°æ®ç»„ç»‡å½¢å¼](LASO/2.png)   

![ç‚¹äº‘æ•°æ®ç»„ç»‡å½¢å¼](LASO/3.png)   

![æ¯ç§ç‰©ä½“å¯ä»¥å¯¹åº”å¤šç§å½¢çŠ¶å®ä¾‹å’ŒåŠŸèƒ½ç±»åˆ«](LASO/4.png)   

**è·å–æ ·æœ¬çš„ä»£ç å®ç°:**

```python
    def __getitem__(self, index):
        # æ ¹æ®æ ·æœ¬ç´¢å¼•å–å‡ºæ ·æœ¬æ•°æ®
        data = self.anno[index]    
        # è·å–å½“å‰æ ·æœ¬å¯¹åº”çš„ç‚¹äº‘ID        
        shape_id = data['shape_id']
        # è·å–å½“å‰æ ·æœ¬å¯¹åº”çš„ç‰©ä½“ç±»åˆ«
        cls = data['class']
        #  è·å–å½“å‰æ ·æœ¬å¯¹åº”çš„åŠŸèƒ½ç±»å‹
        affordance = data['affordance']
        # è·å–å½“å‰æ ·æœ¬å¯¹åº”çš„åŠŸèƒ½åŒºåŸŸæ©ç 
        gt_mask = data['mask']
        # å–å‡ºå½“å‰æ ·æœ¬å¯¹åº”çš„ç‚¹äº‘æ•°æ® ï¼Œï¼ˆ2048,3)
        point_set = self.objects[str(shape_id)]
        # å¯¹ç‚¹äº‘æ•°æ®è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œæ¶ˆé™¤å°ºåº¦å·®å¼‚
        point_set,_,_ = pc_normalize(point_set)
        # å¯¹ç‚¹äº‘æ•°æ®è¿›è¡Œè½¬ç½®æ“ä½œ ï¼Œï¼ˆ3,2048)
        point_set = point_set.transpose()

        # è·å–å½“å‰æ ·æœ¬å¯¹åº”çš„é—®é¢˜æ–‡æœ¬(è®­ç»ƒ: éšæœºé€‰ï¼› éªŒè¯&æµ‹è¯•: å›ºå®šè¿”å›é—®é¢˜0)
        question = self.find_rephrase(self.question_df, cls, affordance)
        # è·å–å½“å‰åŠŸèƒ½ç±»å‹å¯¹åº”çš„ç´¢å¼•å€¼
        affordance = self.aff2idx[affordance]

        # è¿”å›: ç‚¹äº‘æ•°æ®ï¼Œ ç‰©ä½“ç±»åˆ«ç´¢å¼•ï¼Œ åŠŸèƒ½åŒºåŸŸæ©ç ï¼Œ é—®é¢˜æ–‡æœ¬ï¼Œ åŠŸèƒ½ç±»å‹ç´¢å¼•
        return point_set, self.cls2idx[cls], gt_mask, question, affordance

    def find_rephrase(self, df, object_name, affordance):
        # å¦‚æœå½“å‰æ˜¯è®­ç»ƒæ¨¡å¼ï¼Œåˆ™ä»é—®é¢˜1ï½15ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªé—®é¢˜ï¼Œå¦åˆ™å›ºå®šè¿”å›é—®é¢˜0
        qid = str(np.random.randint(1, 15)) if self.split == 'train' else '0'
        qid = 'Question'+qid
        # ä» DataFrame df ä¸­ç­›é€‰å‡ºåŒæ—¶æ»¡è¶³ ç‰©ä½“åç§°åŒ¹é… å’Œ åŠŸèƒ½å±æ€§åŒ¹é… çš„è¡Œï¼Œå¹¶ä»…ä¿ç•™ qid æŒ‡å®šçš„åˆ—ï¼Œä¹Ÿå°±æ˜¯å–å‡ºä¸Šé¢éšæœºé€‰æ‹©çš„é—®é¢˜æ–‡æœ¬
        result = df.loc[(df['Object'] == object_name) & (df['Affordance'] == affordance), [qid]]
        # é—®é¢˜æ–‡æœ¬ä¸ä¸ºç©ºï¼Œåˆ™è¿”å›è¯¥é—®é¢˜æ–‡æœ¬
        if not result.empty:
            # return result.index[0], result.iloc[0]['Rephrase']
            return result.iloc[0][qid]
        else:
            raise NotImplementedError
```

### 8. æ€»ç»“

LASO æ•°æ®é›†åŸºäº 3D-AffordanceNet çš„ç‚¹äº‘å’ŒåŠŸèƒ½æ ‡æ³¨ï¼Œç»“åˆäººå·¥+GPT-4 ç”Ÿæˆçš„å¤šæ ·åŒ–é—®é¢˜ï¼Œæ„é€ å‡º 19,751 ä¸ªç‚¹äº‘-é—®é¢˜é…å¯¹ï¼Œæ—¨åœ¨å®ç°è¯­è¨€å¼•å¯¼ä¸‹çš„ 3D åŠŸèƒ½åŒºåŸŸåˆ†å‰²ï¼Œæ¨åŠ¨ 3D è§†è§‰ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ·±åº¦èåˆã€‚

## æ¨¡å‹å®ç°

è®ºæ–‡æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„æ¨¡å‹ï¼š**PointRefer**ï¼Œç”¨äºè§£å†³ä¸€ä¸ªæ–°é¢–çš„ä»»åŠ¡ â€”â€” **è¯­è¨€å¼•å¯¼çš„ 3D å¯¹è±¡åŠŸèƒ½åŒºåŸŸåˆ†å‰²ï¼ˆLASOï¼‰**ã€‚

æ¨¡å‹ç›®æ ‡ï¼š ç»™å®šä¸€ä¸ª 3D ç‚¹äº‘å¯¹è±¡å’Œä¸€ä¸ªè‡ªç„¶è¯­è¨€é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šâ€œWhere would you grasp this mug?â€ï¼‰ï¼ŒPointRefer çš„ç›®æ ‡æ˜¯é¢„æµ‹å‡ºä¸è¯¥é—®é¢˜ç›¸å…³çš„ç‚¹äº‘åŒºåŸŸï¼Œå³ç”Ÿæˆä¸€ä¸ªäºŒå€¼æ©ç ï¼Œè¡¨ç¤ºå“ªäº›ç‚¹å±äºç›®æ ‡åŠŸèƒ½åŒºåŸŸã€‚

PointRefer åŒ…æ‹¬ä»¥ä¸‹æ ¸å¿ƒæ¨¡å—ï¼š

1. **3D éª¨å¹²ç½‘ç»œï¼ˆ3D Backboneï¼‰**
   - ä½¿ç”¨ PointNet++ ç¼–ç ç‚¹äº‘ç‰¹å¾ï¼›
   - å¤šé˜¶æ®µç¼–ç -è§£ç ç»“æ„æå–å¤šå°ºåº¦ç‚¹ç‰¹å¾ï¼›

2. **è‡ªé€‚åº”èåˆæ¨¡å—ï¼ˆAdaptive Fusion Module, AFMï¼‰**
   - åœ¨ä¸åŒè§£ç å±‚æ³¨å…¥è¯­è¨€ä¿¡æ¯ï¼›
   - å®ç°è¯­è¨€å¼•å¯¼ä¸‹çš„è·¨æ¨¡æ€èåˆï¼›
   - å¢å¼ºç‚¹ç‰¹å¾çš„è¯­ä¹‰åˆ¤åˆ«èƒ½åŠ›ï¼›

3. **å‚è€ƒç‚¹è§£ç å™¨ï¼ˆReferred Point Decoder, RPDï¼‰**
   - å¼•å…¥ä¸€ç»„å¯å­¦ä¹ çš„â€œé—®é¢˜æ¡ä»¶åŒ–æŸ¥è¯¢â€ï¼ˆaffordance queriesï¼‰ï¼›
   - åˆ©ç”¨ Transformer è§£ç å™¨å°†è¿™äº›æŸ¥è¯¢ä¸ç‚¹äº‘ç‰¹å¾è¿›è¡Œäº¤äº’ï¼›
   - ç”ŸæˆåŠ¨æ€å·ç§¯æ ¸ï¼ˆdynamic kernelsï¼‰ï¼›
   - æœ€ç»ˆé€šè¿‡å·ç§¯æ“ä½œç”Ÿæˆåˆ†å‰²æ©ç ï¼›

![PointReferæ¨¡å‹ç»“æ„å›¾](LASO/5.png)   

PointRefer å‰å‘ä¼ æ’­è¿‡ç¨‹å¦‚ä¸‹:

```python
class PointRefer(nn.Module):

    # ä¼ å…¥questionæ–‡æœ¬ å’Œ pointç‚¹äº‘æ•°æ® 
    def forward(self, text, xyz):

        '''
        text: [B, L, 768]
        xyz: [B, 3, 2048] -- (b,c,n)
        '''
         
        B, C, N = xyz.size()
        # 1. Encoding è¿‡ç¨‹
        # 1.1 Language Encoding ä½¿ç”¨RoBertç¼–ç æ–‡æœ¬
        t_feat, t_mask = self.forward_text(list(text), xyz.device)  # [batch, q_len, d_model]
        # 1.2 BackBone Encoding ä½¿ç”¨PointNet++ç¼–ç ç‚¹äº‘
        F_p_wise = self.point_encoder(xyz)     

        """ 
        Decoding
        """
        # 1.3 PointNet++ é€çº§åšç‚¹é›†æŠ½è±¡å¾—åˆ°çš„æ¯å±‚çš„ç‚¹é›†åæ ‡å’Œç‚¹é›†ç‰¹å¾é›†åˆ
        p_0, p_1, p_2, p_3 = F_p_wise

        # 2.Backbone Decodingè¿‡ç¨‹
        # 2.1 ç‚¹é›†é›†åˆä¸­æ¯ä¸ªç‚¹çš„ç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾ä¿¡æ¯è¿›è¡Œèåˆ,ä¼ å…¥çš„ç‚¹é›†ç‰¹å¾é›†åˆç»è¿‡è½¬ç½®å¤„ç†åçš„ç»´åº¦ä¸º: (b, n, c)
        p_3[1] = self.gpb(t_feat, p_3[1].transpose(-2, -1)).transpose(-2, -1)
        # 2.2 PointNet++ ç‰¹å¾ä¼ æ’­é˜¶æ®µ: ä¸Šé‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œä¸Šä¸€å±‚ç‚¹é›†ä¸­çš„ç‚¹ç‰¹å¾é‡å»ºè¿‡ç¨‹ä¸­ï¼Œå……åˆ†å¸æ”¶äº†é«˜çº§åŒºåŸŸæŠ½è±¡ç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾
        up_sample = self.fp3(p_2[0], p_3[0], p_2[1], p_3[1])   #[B, emb_dim, npoint_sa2]

        up_sample = self.gpb(t_feat, up_sample.transpose(-2, -1)).transpose(-2, -1)
        up_sample = self.fp2(p_1[0], p_2[0], p_1[1], up_sample)    #[B, emb_dim, npoint_sa1]   
        
        up_sample = self.gpb(t_feat, up_sample.transpose(-2, -1)).transpose(-2, -1) 
        # 2.3 ç‰¹å¾ä¼ æ’­é˜¶æ®µç»“æŸ: ä¸€æ­¥æ­¥é‡å»ºå›åŸå§‹ç‚¹æ•°é‡ 128->256->512->1024->2048        
        up_sample = self.fp1(p_0[0], p_1[0], torch.cat([p_0[0], p_0[1]],1), up_sample)  #[B, emb_dim, N]
        
        #  3. Referred Point Decodingè¿‡ç¨‹
        t_feat = self.decoder(t_feat, up_sample.transpose(-2, -1), tgt_key_padding_mask=t_mask, query_pos=self.pos1d) # b,l,c
        t_feat *= t_mask.unsqueeze(-1).float()
        _3daffordance = torch.einsum('blc,bcn->bln', t_feat, up_sample)
        _3daffordance = _3daffordance.sum(1)/(t_mask.float().sum(1).unsqueeze(-1))
        _3daffordance = torch.sigmoid(_3daffordance)
        # logits = self.cls_head(p_3[1].mean(-1))
        return _3daffordance.squeeze(-1)
```
> è®ºæ–‡ä¸­æ‰€ç»™çš„æ¨¡å‹æ¶æ„å›¾ä¸­çš„Encoder layeræŒ‡çš„æ˜¯PointNet++ä¸­æä¾›çš„PointNetSetAbstractionMsgå¤šå°ºåº¦åˆ†ç»„ç‚¹é›†ç‰¹å¾æŠ½å–ç±»

> è®ºæ–‡ä¸­æ‰€ç»™çš„æ¨¡å‹æ¶æ„å›¾ä¸­çš„Decoder layeræŒ‡çš„æ˜¯PointNet++ä¸­æä¾›çš„PointNetFeaturePropagationç‰¹å¾ä¼ æ’­ç±»

### AFM è‡ªé€‚åº”èåˆæ¨¡å—

```python
class GPBlock(nn.Module):
    # q: æ–‡æœ¬ç‰¹å¾ (b, l, c) ï¼Œ x: ç‚¹é›†ç‰¹å¾é›†åˆ (b, n, c)
    def forward(self, q, x, q_mask=None):
        # 1. æ³¨æ„åŠ›: æ–‡æœ¬ç‰¹å¾ä½œä¸ºqueryï¼Œä»ç‚¹é›†ç‰¹å¾é›†åˆä¸­æå–ç›¸å…³åŒºåŸŸç‰¹å¾
        gt = self.group_layer(query=q, key=x, value=x)
        if q_mask is not None:
            gt *= q_mask.unsqueeze(-1)
        # 2.  MLP: åštokenç»´åº¦å’Œchannelç»´åº¦çš„ä¿¡æ¯èåˆ
        gt = self.mixer(gt) + self.drop(gt)
        ungroup_tokens = self.un_group_layer(query=x, key=gt, value=gt, key_padding_mask=q_mask)
        return ungroup_tokens

# group_layer çš„å®ç°
class LightGroupAttnBlock(nn.Module):

    def forward(self, query, key, value, q_mask=None):
        def _inner_forward(query, key, value):
            q = self.norm_query(query)
            k = q if self.key_is_query else self.norm_key(key)
            v = k if self.value_is_key else self.norm_value(value)
            x = self.attn(q, k, v, q_mask) + self.drop(q) # æ®‹å·®è¿æ¥
            return x

        return _inner_forward(query, key, value)

# mixer çš„å®ç°
class MLPMixerLayer(nn.Module):
    def __init__(self,
                 num_patches,
                 embed_dims,
                 patch_expansion,
                 channel_expansion,
                 drop_out,
                 **kwargs):

        super().__init__()

        patch_mix_dims = int(patch_expansion * embed_dims) # 16
        channel_mix_dims = int(channel_expansion * embed_dims) # 128

        self.patch_mixer = nn.Sequential(
            nn.Linear(num_patches, patch_mix_dims, bias=False), # try here
            nn.GELU(),
            nn.Dropout(drop_out),
            nn.Linear(patch_mix_dims, num_patches, bias=False),
            nn.Dropout(drop_out)
        )

        self.channel_mixer = nn.Sequential(
            nn.Linear(embed_dims, channel_mix_dims),
            nn.GELU(),
            nn.Dropout(drop_out),
            nn.Linear(channel_mix_dims, embed_dims),
            nn.Dropout(drop_out)
        )

        self.norm1 = nn.LayerNorm(embed_dims)
        self.norm2 = nn.LayerNorm(embed_dims)

    def forward(self, x):
        # x_mask = (x.sum(-1)!=0).to(x.dtype)
        x = x + self.patch_mixer(self.norm1(x).transpose(1,2)).transpose(1,2)
        x = x + self.channel_mixer(self.norm2(x))
        # x *= x_mask
        return x
```


