---
title: Exploring and Exploiting Uncertainty for Incomplete Multi-View Classification 论文
icon: file
category:
  - 多模态
tag:
  - 多模态
  - 编辑中
footer: 技术共建，知识共享
date: 2025-09-30
author:
  - BinaryOracle
---

`Exploring and Exploiting Uncertainty for Incomplete Multi-View Classification 论文` 

<!-- more -->

> 论文链接: [https://arxiv.org/abs/2304.05165](https://arxiv.org/abs/2304.05165)

## 引言

**面临的问题:**   多视图学习相较于单视图能够利用互补性信息，在聚类、分类和表示学习上表现更佳。但由于视图缺失带来的 **高不确定性**，如何在缺失情况下实现稳定、可信的分类仍是难题。

---

**现存解决方法:** 现有的不完整多视图分类（IMVC）方法大体分为两类：

* 一类仅依赖可观测视图进行分类 [8, 9]，不进行插补。但当缺失率较高时，难以充分利用视图间相关性，效果欠佳。

* 另一类利用深度学习（如自编码器 [14, 15]、GAN [16]）对缺失视图进行插补，然后用完整数据分类 [10–13]。但其存在三个问题：

    1. 可解释性不足；
  
    2. 采用**确定性插补**，**无法刻画缺失视图的不确定性**，导致分类不稳定；
  
    3. 面对复杂缺失模式（尤其是多于两个视图的情况）时缺乏灵活性。

---

**提出的方法:**: 提出**不确定性驱动的不完整多视图分类模型（UIMC）** 来解决上述问题。核心思想是 **把缺失数据建模为分布而非单值**，并在此基础上进行采样和自适应融合：

* **分布建模**： 每个缺失视图通过条件分布进行建模，引入不确定性。

* **采样生成**： 从该分布中多次采样，将采样结果与观测视图组合，得到多个完整的多视图样本。

* **质量感知融合**： 由于采样结果本身的质量不确定，模型从两个层面自适应整合：

  * **单视图层面**：对低质量采样数据赋予更高不确定性，使其不干扰其他视图的学习；为此构建基于证据的分类器，输出 **主观概率 + 不确定性质量** 的观点。
  
  * **多视图层面**：通过 **Dempster-Shafer (DS) 规则** 融合多个视图观点，保证在不同质量视图下的可信整合。

---

**贡献总结**：

* 我们提出了一个“探索–利用”策略，通过刻画缺失数据的不确定性来进行不完整多视图分类，使得利用插补数据时既有效又可信。值得注意的是，UIMC 是首个在 IMVC 中显式引入不确定性的工作。

* 我们设计了从 **单视图与多视图融合** 两方面对插补数据进行加权的机制，以充分利用高质量数据并抑制低质量数据的负面影响；其中不确定性感知训练与融合显著提升了结果的稳定性与可靠性。

* 在多个包含不同特征类型或模态的数据集上进行实验，并采用多样化指标进行评估，结果表明 UIMC 在性能和可信度方面均超过现有方法，且能提供可靠的不确定性信息。

## 方法

![](1/1.png)

### 缺失视图补全

在不完整多视图分类中，现有方法大多采用 **单一插补（single imputation）**。形式上，它们会构建一个确定性映射 $f: X \to \hat{X}$，把不完整实例 $X$ 转换为完整实例 $\hat{X}$。 这种方法的问题在于：

* 它忽略了缺失视图的 **高不确定性**；

* 插补结果不够可信，容易对下游分类造成负面影响；

* 类似现象在单视图缺失属性的分类任务中也已被证实 [18, 42]。

因此，本文不再采用确定性插补，而是 **利用分布来刻画缺失视图的不确定性**，并基于 **非参数化的近邻策略** 来实现。

---

**邻居集合的构建**：

设有一个训练实例 $X$，其标签为 $y$，但缺失了第 $m$ 个视图 $x_m$。目标是基于其他训练样本的信息来补全 $x_m$。

* 方法受到 $k$-近邻（$k$NN）[43] 的启发，采用非参数化策略，借助邻居样本来估计缺失视图的分布。

* 对于一个可用视图 $x_v \in X$ （$v \neq m$），我们寻找它在训练集中 **同类别** 样本的 $k$ 个最近邻。

  1. **距离集合 $D_v$**：
     对所有标签相同、且 $x_v^n$ 与 $x_m^n$ 均可用的样本，计算欧式距离：

     $$
     D_v = { -|x_v - x_v^n|_2 \mid x_v^n, x_m^n \ \text{可用且 } y = y_n }
     $$

  2. **邻居指标集合 $I_v$**：
     根据 $D_v$ 选取 $k$ 个最近邻：

     $$
     I_v = { i \mid -|x_v - x_v^i|_2 \in \text{topk}(D_v) }
     $$

     其中 $\text{topk}(\cdot)$ 表示取前 $k$ 个最小距离对应的邻居。

* **测试阶段**：由于测试样本的标签未知，缺失视图 $x_m$ 的插补仅依赖特征的相似性，不再依赖标签信息（即 *being independent with labels*）。

---

**基于统计信息的插补**：

得到所有邻居集合 $I = {I_v}_{v \neq m}$ 后，我们将缺失视图 $x_m$ 建模为一个 **多元高斯分布**：

* 邻居集合为 ${x_m^i}_{i \in I}$；

* 分布为 $x_m \sim \mathcal{N}(\mu, \Sigma)$，其均值向量与协方差矩阵由邻居样本统计得到：

$$
\mu = \frac{\sum_{i \in I} x_m^i}{|I|}
$$

$$
\Sigma = \frac{1}{|I|-1} \sum_{i \in I} (x_m^i - \mu)(x_m^i - \mu)^T
$$

* 由此可以对 $x_m$ 进行 **多次采样**，生成多个插补版本。

---

**生成完整训练实例**：

对于一个不完整的训练样本 $X$，通过在 $\mathcal{N}(\mu, \Sigma)$ 上采样 $N_s$ 次，可以得到 $N_s$ 个完整样本：

$$
{\hat{X}^s}_{s=1}^{N_s}
$$

该过程如 **图1a** 所示，形成了一个可感知不确定性的插补框架。

### 对补全后的多视图样本进行分类

在获得填补后的多视图训练数据集 $(\hat{X}_{n,s})_{n=1}^N{}_{s=1}^{N_s}$ 之后，我们考虑通过利用填补样本的不确定性来减轻低质量填补带来的负面影响。由于填补过程中的固有噪声，填补后的多视图数据通常具有较高的不确定性。因此，我们首先基于一种证据化的多视图学习框架来估计不同视图的不确定性，然后进行基于不确定性的决策融合。整体框架如图 1b 所示。

与传统分类算法不同，**证据分类** [44,45] 定义了一个理论框架，用于获得主观意见

$$
S = \{b_k\}_{k=1}^K, u
$$

其中包含 **主观概率（置信质量）** $\{b_k\}_{k=1}^K \geq 0$ 和 **整体不确定性质量** $u \geq 0$，其中 $K$ 表示类别数，并且满足：

$$
\sum_{k=1}^K b_k + u = 1.
$$

该主观意见与参数为 $\alpha = [\alpha_1, \cdots, \alpha_K]$ 的 Dirichlet 分布相关联。具体来说，置信质量 $b_k$ 可以由对应 Dirichlet 分布的参数推导得到：

$$
b_k = \frac{\alpha_k - 1}{\alpha_0}, \quad \alpha_0 = \sum_{k=1}^K \alpha_k,
$$

其中 $\alpha_0$ 称为 **Dirichlet 强度**。

为了获得每个视图 $\hat{x}_v \in \hat{X}$ 的 Dirichlet 分布参数，我们构建了 **证据神经网络**，其方法是将传统神经网络分类器的 softmax 层替换为 softplus 等激活函数，从而使其正输出能够被视为证据向量


$$
e_v = [e_1^v, \cdots, e_K^v].
$$

随后，视图 $\hat{x}_v$ 的 Dirichlet 分布参数 $\text{Dir}(p_v \mid \alpha_v)$ 可通过如下方式获得：

$$
\alpha_k^v = e_k^v + 1.
$$

在变分框架下，证据分类的损失函数 $L_v$ 是分类损失 $L_c^v$ 与正则项 $L_r^v$ 的组合 [46]。更具体地说，分类目标函数可以看作是传统交叉熵损失在由 Dirichlet 分布 $\text{Dir}(p_v \mid \alpha_v)$ 决定的单纯形上的积分。其形式为：

$$
L_c^v(\alpha_v \mid x_v) = \sum_{k=1}^K y_k \big(\psi(\alpha_0^v) - \psi(\alpha_k^v)\big), \tag{4}
$$

其中 $y_k$ 是标签 $y$ 的第 $k$ 个元素（独热编码形式），$\psi(\cdot)$ 是 **digamma 函数**。

为了获得合理的 Dirichlet 分布，我们为其增加一个先验作为正则化项：

$$
L_r^v(\alpha_v \mid x_v) = D_{\text{KL}}\big[\text{Dir}(p_v \mid \tilde{\alpha}_v) ,|, \text{Dir}(p_v \mid [1,\cdots,1])\big], \tag{5}
$$

其中

$$
\tilde{\alpha}_v = y + (1-y) \odot \alpha_v
$$

表示将对应标签的 $\alpha_k$ 替换为 1 后得到的 Dirichlet 分布，$\text{Dir}(p_v \mid [1,\cdots,1])$ 是均匀 Dirichlet 分布。

因此，每个视图的总体损失函数可写为：

$$
L_v(\alpha_v \mid x_v) = L_c^v(\alpha_v \mid x_v) + \lambda L_r^v(\alpha_v \mid x_v), \tag{6}
$$

其中 $\lambda$ 是一个退火系数，在训练过程中逐渐从 0 变化到 1，用于控制约束强度。通过最小化 $L_v$，可以得到 Dirichlet 分布 $\text{Dir}(p_v \mid \alpha_v)$。随后，相应的主观意见可以由下式导出：

$$
b_k^v = \frac{\alpha_k^v - 1}{\alpha_0^v}, \quad u_v = 1 - \sum_{k=1}^K b_k^v.
$$

接下来我们考虑如何根据不确定性将来自不同视图的主观意见进行融合。**Dempster-Shafer 证据理论**允许将来自不同来源的主观意见进行整合，从而产生更全面的意见 [47]。具体来说，两个视图的 **Dempster 融合规则**定义在定义 3.2 中。相应地，集成后的多视图主观意见可表示为：

$$
S_m = S_1 \oplus S_2 \oplus \cdots \oplus S_V = \{b_k^m\}_{k=1}^K, u_m.
$$

集成后的多视图 Dirichlet 分布 $\text{Dir}(p_m \mid \alpha_m)$ 的参数由下式获得：

$$
\alpha_k^m = b_k^m \cdot \alpha_0^m + 1.
$$

---

**定义 3.2（Dempster 融合规则）**

两个主观意见

$$
S_1 = \{b_k^1\}_{k=1}^K, u_1, \quad S_2 = \{b_k^2\}_{k=1}^K, u_2
$$

融合后的主观意见

$$
S = S_1 \oplus S_2
$$

可写作：

$$
b_k = \frac{1}{1-C}\big(b_k^1 b_k^2 + b_k^1 u_2 + b_k^2 u_1\big), \quad
u = \frac{1}{1-C}u_1 u_2, \tag{7}
$$

其中

$$
C = \sum_{i \neq j} b_i^1 b_j^2.
$$

---

为了同时获得可靠的单视图和集成 Dirichlet 分布，我们采用多任务策略。具体来说，分类阶段的最终损失函数由单视图和多视图的损失共同组成：

$$
L = \sum_{n=1}^N \sum_{s=1}^{N_s} \Big( L_m(\alpha_m) + \sum_{v=1}^V L_v(\alpha_v \mid x_{n,s}^v) \Big), \tag{8}
$$

其中

$$
L_m(\alpha_m) = \sum_{k=1}^K y_k \big(\psi(\alpha_0^m) - \psi(\alpha_k^m)\big) + \lambda D_{\text{KL}}\big[\text{Dir}(p_m \mid \tilde{\alpha}_m),|, \text{Dir}(p_m \mid [1,\cdots,1])\big]. \tag{9}
$$

个人绘制的完整方法执行流程:

![](1/2.png)

### 预测

模型在测试时会为同一个缺失样本生成多个可能的补全版本，然后对这些补全样本分别进行分类预测，最终通过“多数投票”确定最终预测类别。



