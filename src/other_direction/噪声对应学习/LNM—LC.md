---
title: Unsupervised Label Noise Modeling and Loss Correction 论文
icon: file
category:
  - 噪声对比学习
tag:
  - 噪声对比学习
  - 编辑中
footer: 技术共建，知识共享
date: 2025-09-18
author:
  - BinaryOracle
---

`Unsupervised Label Noise Modeling and Loss Correction 论文` 

<!-- more -->

> 论文链接: [Unsupervised Label Noise Modeling and Loss Correction](https://arxiv.org/abs/1904.11238)
> 代码链接: [https://github.com/PaulAlbert31/LabelNoiseCorrection](https://github.com/PaulAlbert31/LabelNoiseCorrection)

## 引言

卷积神经网络（CNN）是计算机视觉任务中的主流方法，能够在有大量标注数据时建模复杂模式。但实际中获取大规模干净数据很困难，人工或自动标注往往会产生错误，形成噪声样本。

已有研究发现：

* CNN 虽然对少量噪声有一定鲁棒性，但在随机梯度下降训练下，容易 **拟合随机标签**。

* 当同时存在干净和错误标签时，网络会先拟合干净样本，再逐步拟合噪声样本。

* 过拟合噪声会严重损害模型的泛化能力，也会加剧训练中的偏差问题（如类别不平衡）。

因此，**如何在不丢弃噪声样本的前提下，避免网络过拟合错误标签，同时利用这些样本的潜在信息**，成为一个关键挑战。

---

**现有方法与不足**：

* **损失校正类方法**：

  * *Bootstrapping loss*（Reed 等, 2015）在目标函数中引入一致性约束，通过结合网络预测结果和原始标签，减少噪声的负面影响。
  
  * 类别概率修正（Patrini 等, 2017; Hendrycks 等, 2018）通过估计每类的噪声分布，对损失进行调整，引导网络更靠近真实类别。

* **课程学习类方法**：

  * 通过“由易到难”的顺序训练（Bengio 等, 2009），在噪声场景中，易样本≈干净样本，难样本≈噪声样本，因此可以降低噪声样本对损失的贡献。
  
  * 但简单丢弃噪声样本可能损失了关于数据分布的重要信息。

* **其他改进方法**：

  * 相似性学习（Wang 等, 2018b）：将噪声样本的表示与干净样本拉开。
  
  * *Mixup* 数据增强（Zhang 等, 2018）：无需显式建模噪声，却展现出对标签噪声的强鲁棒性。

然而，这些方法往往假设存在一部分干净数据，或者在利用噪声样本方面不够充分。

---

**本文的核心思想与贡献**：

本文提出一种新的训练流程，即使在高比例噪声下，也能避免过拟合错误标签，同时有效利用噪声样本：

* 通过对 **样本损失分布** 进行建模，提出 **双成分 Beta 混合模型 (BMM)**，分别对应“干净样本”和“噪声样本”。

* 使用 BMM 的后验概率来动态调整 **bootstrapping loss**，从而实现对每个样本的损失校正。

* 在不丢弃噪声样本的情况下，保持训练鲁棒性，并能学习到有利的表征。

* 将方法与 **mixup 数据增强** 结合，进一步提升性能，即便在极端噪声条件下依然能收敛。

**主要贡献**：

* 提出基于样本损失的无监督标签噪声建模方法。

* 提出结合该模型的损失校正策略，避免过拟合噪声标签。

* 将方法与 mixup 数据增强结合，推动了当前最优水平的提升。

* 在极端噪声水平下，依然能通过改进的 mixup 策略实现收敛。

## 相关工作

**标签噪声的两类场景**：

* **封闭集 (closed-set)**：所有样本（包括噪声样本）的真实标签都在已知集合 $S$ 内。

* **开放集 (open-set)**：某些噪声样本 $x_i$ 的真实标签可能在 $S$ 之外，即 $x_i$ 可能是分布外样本。

本文主要关注 **封闭集标签噪声**，并在此场景下开展研究。

---

**封闭集下的噪声类型**：

* **均匀随机噪声（对称噪声）**：真实标签以相同概率被随机翻转到其他类别。

* **非均匀随机噪声（类别条件噪声）**：不同类别有不同的翻转概率。

已有研究（Patrini 等, 2017）表明：**均匀噪声比非均匀噪声更难处理**。

---

**现有应对方法**：

* **丢弃噪声样本**

  简单但有风险：难样本可能被误判为噪声样本。
  
  尽管如此，研究（Ding 等, 2018）表明，丢弃高概率错误的样本并将它们用于半监督学习仍然有效。

* **重新标注样本**

  通过不同模型尝试恢复真实标签：

  * 有向图模型 (Xiao 等, 2015)

  * 条件随机场 (Vahdat, 2017)

  * CNN (Veit 等, 2017)

  但这些方法普遍假设存在一小部分干净数据。Tanaka 等（2018）则证明，可以利用网络预测在无监督下进行重新标注，生成软标签或硬标签。

* **损失校正方法**

  通过修改损失函数或计算损失所需的概率来抵消噪声：

  * Reed 等（2015）：在损失中加入感知一致性项，引入对模型预测的依赖，但噪声标签始终影响目标函数。

  * Patrini 等（2017）：提出两种方法：

    * **Backward 方法**：利用噪声转移矩阵 $T$ 的逆来加权损失。

    * **Forward 方法**：对预测概率进行修正，即用 $T$ 对预测分布做变换。

  * Hendrycks 等（2018）：基于在干净数据上训练的模型，计算腐蚀矩阵 (corruption matrix)，并用它来修正预测概率。

* **基于重加权的课程学习**

  * Jiang 等（2018b）：提出“导师-学生”框架，导师网络学习课程（即样本权重），指导学生网络在噪声下训练。

  * Guo 等（2018）：利用特征空间分布复杂度进行无监督估计，结合干净和噪声样本训练。

  * Ren 等（2018）：根据训练梯度与验证集梯度的方向一致性来为样本加权。

这些方法与重新标注方法一样，通常依赖于一部分干净数据，限制了实际应用。

---

**不依赖干净数据的方法**：

* Wang 等（2018b）：提出无监督的噪声检测方法，结合相似性学习，将噪声样本的表示与各类别的干净样本表示拉开，同时不丢弃噪声样本。

---

**本文的区别与方法**：

与现有方法不同，本文仅依赖 **每个样本的训练损失**，而无需任何干净数据。核心思路是：

* 对样本的损失分布拟合一个 **双成分 Beta 混合模型 (BMM)**，分别建模干净样本与噪声样本。

* 利用 BMM 的后验概率，实现 **损失校正**。

* 方法结合 **bootstrapping loss**（Reed 等, 2015）与 **mixup 数据增强**（Zhang 等, 2018），从而更好地应对封闭集标签噪声场景。

## 方法

### 1. 标签噪声建模

图像分类被定义为从训练集

$D = \{(x_i, y_i)\}_{i=1}^N$

学习一个模型 $h_\theta(x)$，其中 $y_i$ 是 one-hot 标签。本文中 $h_\theta$ 是 CNN，$\theta$ 是权重和偏置。训练通过最小化交叉熵损失：

$$
\mathcal{L}(\theta) = - \sum_{i=1}^N y_i^T \log(h_\theta(x_i)) .
$$

当标签含有噪声时，样本 $x_i$ 可能带有错误标签，因此需要扩展损失函数来抵抗噪声。

---

![](LNM-LC/2.png)

**核心观察**（见图1与图2）：

* 随机错误标签比正确标签更难学，因此在训练早期，噪声样本的损失值更高。

* CNN 在拟合干净样本后才逐渐拟合噪声样本。

* 因此，仅通过损失分布就能区分干净与噪声样本。

![](LNM-LC/1.png)

这启发了本文提出的：通过 **混合模型** 对损失分布建模，进而判别样本是否为噪声。

---

**混合模型的选择**：

* 一般混合模型定义为：

  $$
  p(\mathcal{L}) = \sum_{k=1}^K \lambda_k p(\mathcal{L} \mid k) ,
  $$

  其中 $\lambda_k$ 是混合系数。

* 直观做法是使用 **高斯混合模型(GMM)** 来区分干净与噪声（$K=2$）。

* 但高斯分布不能很好刻画干净样本的分布，因为其损失高度偏向零。

* **Beta 分布** 更灵活，能拟合 $[0,1]$ 区间的对称或偏态分布，因此 **Beta 混合模型(BMM)** 更适合。

* 实验表明：在 CIFAR-10 上 80% 标签噪声条件下，BMM 相比 GMM 在 **ROC-AUC 提升约 5 个点**（见附录A）。

---

**Beta 分布定义**：

$$
p(\mathcal{L} \mid \alpha, \beta) = 
\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} 
\mathcal{L}^{\alpha - 1} (1 - \mathcal{L})^{\beta - 1}, \quad \alpha, \beta > 0
$$

将其代入公式(2)，即可得到 BMM 的概率密度函数。

---

**参数估计：EM 算法流程**

* **E 步**（公式(4)）：固定参数，计算后验概率 $\gamma_k(\mathcal{L})$，即样本损失来自分量 $k$ 的概率。

* **M 步**（公式(5)(6)(7)）：根据加权矩方法更新 $\alpha_k, \beta_k$，并计算加权均值 $\bar{\mathcal{L}}_k$ 与方差 $s_k^2$。

* **更新混合系数**（公式(8)）：

  $$
  \lambda_k = \frac{1}{N} \sum_{i=1}^N \gamma_k(\mathcal{L}_i)
  $$

* 交替进行 E/M 步，直至收敛或迭代 10 次（本文实验设置）。

* **数值稳定性处理**：为避免 $\mathcal{L} \approx 0$ 或 $\mathcal{L} \approx 1$ 导致的不稳定，作者将观测值限制在区间 $[\epsilon, 1-\epsilon]$，其中 $\epsilon = 10^{-4}$。

---

**最终判别结果**（公式(9)）：

* 得到样本为干净或噪声的概率：

  $$
  p(k \mid \mathcal{L}_i) = \frac{p(k) p(\mathcal{L}_i \mid k)}{p(\mathcal{L}_i)}, \quad k=0,1
  $$

* $k=0$ 表示干净样本，$k=1$ 表示噪声样本。

* 用于估计分布的损失始终是 **标准交叉熵损失**，在每个 epoch 后对所有样本重新计算。这与训练损失可能不同，因为训练时会引入噪声修正项。


## 代码实现

### 期望最大化（Expectation-Maximization, EM）算法

EM 是一种**处理“隐藏变量”或不完全数据”的参数估计方法**。

* 问题：你有观测数据 $X = \{x_1, x_2, ..., x_N\}$，但模型中存在隐藏变量 $Z = \{z_1, ..., z_N\}$（比如样本属于哪个分量）

* 目标：估计模型参数 $\theta$（例如 Beta 分布的 $\alpha, \beta$ 和混合权重 $\pi$）

* 难点：直接最大化似然函数很困难，因为隐藏变量未知

**EM 的核心思想：**

> 交替做两件事：
>
> 1. **E-step**：根据当前参数估计隐藏变量的分布（“猜测每个样本属于哪个分量”）
> 
> 2. **M-step**：在隐藏变量已知的假设下，更新参数，使似然最大（用“责任”加权更新参数）
>
> EM 算法就是解决“**已知数据分布形式，但部分信息（隐藏变量）未知**”的参数估计问题。它通过 **交替猜测隐藏变量 → 根据猜测更新参数** 的方式逼近最大似然估计。

论文中所提供的 `EM` 算法整体流程框架如下:

```python
def fit(self, x):
    # 拷贝输入数据，避免修改原始数组 (输入的是每个样本的损失值)
    x = np.copy(x)

    # ----------------------------
    # 对数据做数值修正，保证 Beta 分布计算稳定
    # Beta 分布定义在开区间 (0, 1)，x=0 或 x=1 会导致 pdf 或矩估计出现数值不稳定
    # eps 用来把 0/1 附近的值略微拉开
    # ----------------------------
    eps = 1e-4
    x[x >= 1 - eps] = 1 - eps  # 将大于等于 1-eps 的值置为 1-eps
    x[x <= eps] = eps          # 将小于等于 eps 的值置为 eps

    # ----------------------------
    # 开始 EM 迭代
    # ----------------------------
    for i in range(self.max_iters):
        # ------------------------
        # E-step（期望步）
        # 计算每个样本属于每个 Beta 分量的责任
        # r.shape = (2, N)，r[k, i] 表示第 i 个样本属于分量 k 的概率
        # ------------------------
        r = self.responsibilities(x)

        # ------------------------
        # M-step（最大化步）
        # 使用责任 r 对每个分量的 Beta 分布参数进行加权拟合
        # fit_beta_weighted 使用加权矩估计得到 alpha 和 beta
        # ------------------------
        self.alphas[0], self.betas[0] = fit_beta_weighted(x, r[0])  # 更新第 0 个分量
        self.alphas[1], self.betas[1] = fit_beta_weighted(x, r[1])  # 更新第 1 个分量

        # ------------------------
        # 更新混合权重 pi_k
        # 根据责任求每个分量的总权重，然后归一化
        # ------------------------
        self.weight = r.sum(axis=1)       # 每个分量的总责任
        self.weight /= self.weight.sum()  # 归一化，使 sum(weight)=1

    # 返回训练好的模型实例
    return self
```
**1. E-step（期望步）: 作者使用两个混合 Beta 分布分别建模干净样本和噪声样本的损失分布。在 E 步中，首先根据当前模型参数，计算每个样本属于 Beta1（干净样本损失分布）和 Beta2（噪声样本损失分布）的后验概率（responsibility），即每个样本属于各分量的概率，这两个概率经过归一化保证和为 1。**

```python
def likelihood(self, x, y):
    """
    计算样本 x 在第 y 个 Beta 分量下的似然（概率密度函数值）
    
    参数:
        x : array-like
            样本数据，可以是单个值或向量
        y : int
            分量索引，0 表示 Beta1，1 表示 Beta2
    
    返回:
        array-like
            样本 x 在 Beta 分布 y 下的概率密度
    """
    return stats.beta.pdf(x, self.alphas[y], self.betas[y])


def weighted_likelihood(self, x, y):
    """
    计算样本 x 在第 y 个 Beta 分量下的加权似然
    
    参数:
        x : array-like
            样本数据
        y : int
            分量索引
    
    返回:
        array-like
            样本 x 在 Beta 分量 y 下的加权概率密度，即 pdf * 分量权重
    """
    # self.weight[y] 是当前 Beta 分量的混合权重 π_y
    return self.weight[y] * self.likelihood(x, y)


def responsibilities(self, x):
    """
    E-step 的核心：计算每个样本属于各个 Beta 分量的后验概率（responsibility）
    
    参数:
        x : array-like
            样本数据
    
    返回:
        r : ndarray, shape=(2, N)
            r[k, i] 表示样本 i 属于分量 k 的概率
    """
    # 先计算每个样本在各个分量下的加权似然
    # r.shape = (2, N)，每行对应一个分量，每列对应一个样本
    r = np.array([self.weighted_likelihood(x, i) for i in range(2)])
    
    # 防止数值过小导致除零或 NaN
    # 将小于 eps_nan 的概率置为 eps_nan
    r[r <= self.eps_nan] = self.eps_nan
    
    # 对每个样本归一化，使两行（两个分量）概率和为 1
    # 对应公式: r_{ik} = π_k * pdf(x_i | θ_k) / sum_j(π_j * pdf(x_i | θ_j))
    r /= r.sum(axis=0)
    
    return r
```

**2. M-step（最大化步）: 利用 E 步得到的责任（作为权重），对每个分量重新估计参数。**

```python
def weighted_mean(x, w):
    """
    计算加权平均值
    
    参数:
        x : array-like
            样本数据
        w : array-like
            权重向量，对应每个样本的权重（例如 EM 算法中的责任 r）
    
    返回:
        float
            加权平均值
    """
    # 加权平均值公式：sum(w_i * x_i) / sum(w_i)
    return np.sum(w * x) / np.sum(w)


def fit_beta_weighted(x, w):
    """
    根据加权样本估计 Beta 分布的参数 alpha 和 beta
    
    参数:
        x : array-like
            样本数据，取值范围应在 (0, 1)
        w : array-like
            权重向量，用于加权估计（例如来自 E-step 的责任）
    
    返回:
        (alpha, beta) : tuple of floats
            拟合得到的 Beta 分布参数
    """
    # Step 1: 计算加权均值
    x_bar = weighted_mean(x, w)  
    
    # Step 2: 计算加权方差
    s2 = weighted_mean((x - x_bar)**2, w)
    
    # Step 3: 根据矩估计公式推导 alpha
    # Beta 分布的均值 mu = alpha / (alpha + beta)
    # 方差 sigma^2 = alpha*beta / ((alpha+beta)^2 * (alpha+beta+1))
    # 通过加权均值和方差反解得到 alpha
    alpha = x_bar * ((x_bar * (1 - x_bar)) / s2 - 1)
    
    # Step 4: 根据均值公式反解 beta
    beta = alpha * (1 - x_bar) / x_bar
    
    # 返回估计的参数
    return alpha, beta
```
> **加权平均值公式**: 在计算平均时考虑“重要性”，权重越大，样本对结果的影响越大; 对比普通求平均值，所有样本的权重都是 $1/N$。

> **加权方差公式**: 加权方差考虑了样本的“重要性”，权重越大的样本，其“离均值的偏差”对整体方差的贡献更大。

完整的EM算法执行过程如下图所示:

![](LNM-LC/3.png)
