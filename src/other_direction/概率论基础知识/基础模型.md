---
title: 概率论基础模型
icon: file
category:
  - 概率论
tag:
  - 已发布
footer: 技术共建，知识共享
date: 2025-07-18
order: 2
author:
  - BinaryOracle
---

`概率论基础模型(用到多少，学多少 =_=)` 

<!-- more -->

## Bayes' rule

> Question One: What's the mean of Bayesian inference ?

“推理”（inference）是指“从样本数据出发，得出带有一定置信度的一般性结论的行为”。术语“贝叶斯”（Bayesian）则用来指代那些使用概率理论来表示“置信度”（即确定程度）并利用 贝叶斯公式(Bayes’ rule) 根据观察数据更新置信度的方法。

![](2/1.png)

贝叶斯公式本身非常简单：它是一个用于计算在给定观测数据 $Y = y$ 情况下，某个未知（或隐藏）变量 $H$ 可能取值的**概率分布**的公式：

$$
p(H = h \mid Y = y) = \frac{p(H = h)p(Y = y \mid H = h)}{p(Y = y)} \tag{2.51}
$$

这个公式可以由以下恒等式直接推出：

$$
p(h \mid y)p(y) = p(h)p(y \mid h) = p(h, y) \tag{2.52}
$$

而这个恒等式又来自于**概率的乘法法则**（product rule）。

在公式 (2.51) 中，术语 $p(H)$ 表示在我们看到任何数据之前，对 $H$ 的可能取值的了解；这被称为**先验分布**（prior distribution）。如果 $H$ 有 $K$ 个可能的取值，那么 $p(H)$ 就是一个包含 $K$ 个元素的向量，其中的概率和为 1。

术语 $p(Y \mid H = h)$ 表示在假设 $H = h$ 的前提下，我们对可能出现的结果 $Y$ 的分布，这被称为**观测分布**（observation distribution）。当我们将其评估于实际观测结果 $y$ 上时，就得到了函数 $p(Y = y \mid H = h)$，这被称为**似然函数**（likelihood）。<mark>需要注意的是，这其实是 $h$ 的函数，因为 $y$ 是已知的固定值，并且它不是一个概率分布，因为它的和不一定为 1 。</mark>

将先验概率 $p(H = h)$ 与似然函数 $p(Y = y \mid H = h)$ 相乘，可以得到**未归一化的联合分布** $p(H = h, Y = y)$。我们可以通过除以 $p(Y = y)$ 将其变为归一化分布，这个除数被称为**边际似然**（marginal likelihood），因为它是通过对未知量 $H$ 进行边际化（即求和）得到的：

$$
p(Y = y) = \sum_{h' \in H} p(H = h')p(Y = y \mid H = h') = \sum_{h' \in H} p(H = h', Y = y)
$$

通过对每个 $h$ 计算 $p(H = h, Y = y) / p(Y = y)$，我们就得到了**后验分布**（posterior distribution）$p(H = h \mid Y = y)$，它表示我们在看到数据 $y$ 之后，对 $H$ 可能取值的最新信念状态。

我们可以用一句话来总结贝叶斯公式：

$$
\text{posterior} \propto \text{prior} \times \text{likelihood} \tag{2.54}
$$

这里使用符号 $\propto$（“正比于”）表示我们省略了分母，因为它只是一个与 $H$ 无关的常数。

使用贝叶斯公式，根据观测数据对某一感兴趣的未知量的分布进行更新的过程，被称为**贝叶斯推理**（Bayesian inference）或**后验推理**（posterior inference），也可以简称为**概率推理**（probabilistic inference）。

> Bayes 公式人话版本:  “先有预期 + 接收信息 → 更新判断”

$$
P(H|Y) = \frac{P(Y|H) \cdot P(H)}{P(Y)}
$$

* $H$：隐藏的“真相”或假设

* $Y$：你观测到的信息

* $P(H)$：你在没有观察任何信息前对 H 的**先验信念**

* $P(Y|H)$：如果 H 是真的，你会看到这个信息的**可能性**

* $P(H|Y)$：你在看到 Y 后对 H 的**新判断（后验）**

## Inverse problems

概率论的核心是：在已知世界状态 $h$ 的前提下，预测某个结果 $y$ 的分布。而**逆概率问题**关注的则是：通过观察结果 $y$，去**推断世界的状态** $h$。我们可以把这看作是对 $h \rightarrow y$ 映射关系的反向求解。

![](2/2.png)

举个例子，设想我们要从一张二维图像 $y$ 中推断出一个三维形状 $h$。这是视觉场景理解中的一个经典问题。不幸的是，这是一个**根本上的病态问题（ill-posed problem）**，如图 2.8 所示：**同一个观测结果 $y$**，可能对应**多个潜在的隐藏状态 $h$**。同样地，我们也可以将自然语言理解看作是一个病态问题：听者必须从说话者表达出的（通常是模糊的）语言中，去推测其真正的意图 $h$。

为了解决这类反向问题，我们可以使用**贝叶斯公式**来计算**后验概率** $p(h|y)$，它描述了在观测到 $y$ 的情况下，对各种可能世界状态 $h$ 的概率分布。

要实现这一点，需要给出：

* **前向模型** $p(y|h)$：描述在给定 $h$ 的前提下，结果 $y$ 是如何产生的；

* **先验分布** $p(h)$：用于排除或降低某些不太可能的世界状态。

## 混合分布概率模型

混合模型的假设是：**观测数据 $x$ 来自多个潜在分布的组合**。

公式：

$$
p(x) = \sum_{k=1}^{K} \lambda_k \, p(x \mid \theta_k)
$$

其中：

* $K$ ：混合成分（components）的数量

* $\lambda_k$ ：混合系数，满足 $\lambda_k \geq 0$ 且 $\sum_{k=1}^K \lambda_k = 1$

* $p(x \mid \theta_k)$ ：第 $k$ 个成分的概率分布，参数为 $\theta_k$

* 整体 $p(x)$ 就是加权平均。

![](2/3.png)

这里列举一个**混合高斯分布**的例子，我们设定了两个高斯分布：

  * **成分1**：均值 $0$、方差 $1$、权重 $0.4$
  
  * **成分2**：均值 $5$、方差 $1.5$、权重 $0.6$

* 最终的混合分布由这两个分布加权得到：$p(x) = 0.4 \cdot \mathcal{N}(x|0,1) + 0.6 \cdot \mathcal{N}(x|5,1.5)$

图中蓝色虚线是第一个高斯，绿色虚线是第二个高斯，红色实线就是它们的**混合分布**。

> 这相当于我们有两种“人群”——比如说一部分人身高在 170cm 左右（成分1），另一部分人身高在 180cm 左右（成分2），总人口分布就是这两类人混在一起的结果。这就是**混合分布**的意义。

在混合分布（Mixture Distribution）里，权重 $\lambda_k$ 表示 **一个样本来自第 $k$ 个分布的概率**。

* 比如在我举的例子里：

  * $\lambda_1 = 0.4$ → 有 40% 的概率样本来自第一个高斯分布 $\mathcal{N}(0,1)$
  
  * $\lambda_2 = 0.6$ → 有 60% 的概率样本来自第二个高斯分布 $\mathcal{N}(5,1.5)$

权重必须满足：

$$
\sum_{k=1}^K \lambda_k = 1, \quad \lambda_k \geq 0
$$

权重不是随便定的，它们一般通过 **模型假设 + 数据估计** 得到：

* **先验假设**：有时我们事先知道（比如男女比例是 50/50），就可以直接设定。

* **参数学习**：如果我们不知道比例，就用算法（通常是 **EM算法**）在数据上估计。

  * 在 E 步：计算每个样本属于各个分布的“责任值”

  * 在 M 步：根据这些责任值重新估计权重 $\lambda_k$（就是每个分布解释数据的比例）

一旦有了权重 $\lambda_k$ 和各个子分布 $p(x|k)$，混合分布就写成：

$$
p(x) = \sum_{k=1}^K \lambda_k \, p(x|k)
$$

这就是一个新的合法概率分布，可以直接用来：

* **绘图**（像我画的红色曲线）

* **采样**（先按权重选一个分布，再从那个分布里抽样）

* **计算概率**（比如某个损失值出现的概率是多少）

---

为了更清晰地建模，通常引入一个 **隐变量 $z$**，表示样本属于哪个成分。

* $z \in {1,2,\dots,K}$

* $p(z=k) = \lambda_k$

* 条件分布 $p(x|z=k) = p(x|\theta_k)$

于是：

$$
p(x) = \sum_{k=1}^{K} p(x, z=k) = \sum_{k=1}^K p(z=k) \, p(x|z=k)
$$

这就是混合分布的“生成过程”描述。

---

给定观测 $x$，我们可以计算“它属于哪个成分的概率”：

$$
p(z=k\mid x)
= \frac{p(x,z=k)}{p(x)}
= \frac{\lambda_k\,p(x\mid\theta_k)}{\sum_{j=1}^K \lambda_j\,p(x\mid\theta_j)}.
$$


这就是 **贝叶斯公式**。在标签噪声建模里，这个概率就对应 “一个样本是干净/噪声的可能性”。

## 期望最大化（Expectation-Maximization, EM）算法
 
在统计建模里，我们有一组观测数据 $\{x_1,\dots,x_N\}$，想找到参数 $(\lambda,\theta)$，使得在这个模型下生成这些数据的概率最大。

这就是 **极大似然估计**：

$$
(\hat\lambda, \hat\theta) = \arg\max_{\lambda,\theta} p(x_1,\dots,x_N \mid \lambda,\theta).
$$

通常我们假设数据是 **独立同分布（i.i.d.）** 的，也就是说：

$$
p(x_1,\dots,x_N \mid \lambda,\theta) = \prod_{i=1}^N p(x_i \mid \lambda,\theta).
$$

于是得到：

$$
\mathcal{L}(\lambda,\theta) = \prod_{i=1}^N p(x_i).
$$

在混合分布模型中，单个样本的边缘概率是

$$
p(x_i) = \sum_{k=1}^K \lambda_k \, p(x_i|\theta_k),
$$

所以完整似然就是：

$$
\mathcal{L}(\lambda, \theta) = \prod_{i=1}^N \sum_{k=1}^K \lambda_k \, p(x_i|\theta_k).
$$


混合模型的训练目标是 **最大化似然**：

$$
\mathcal{L}(\lambda, \theta) = \prod_{i=1}^N p(x_i) = \prod_{i=1}^N \sum_{k=1}^K \lambda_k \, p(x_i|\theta_k)
$$

直接优化很难，因为里面有求和。常见方法是 **期望最大化（Expectation-Maximization, EM）算法**：

1. **E步（Expectation）**：计算后验概率

   $$
   \gamma_{ik} = p(z_i=k \mid x_i) = \frac{\lambda_k \, p(x_i|\theta_k)}{\sum_{j=1}^K \lambda_j \, p(x_i|\theta_j)}
   $$

   $\gamma_{ik}$ 表示样本 $x_i$ 来自成分 $k$ 的责任值（responsibility）。

2. **M步（Maximization）**：更新参数

   * 更新混合系数：

     $$
     \lambda_k = \frac{1}{N} \sum_{i=1}^N \gamma_{ik}
     $$

   * 更新成分参数 $\theta_k$ ：根据具体分布形式（高斯、Beta等）来更新，一般用加权最大似然。
    
     $$
     \theta_k^{\text{new}} = \arg\max_{\theta_k} \sum_{i=1}^N \gamma_{ik} \, \log p(x_i \mid \theta_k)
    $$

3. 不断迭代 E-M，直到收敛。

## 高斯混合分布模型

高斯混合模型是一种 **概率模型**，用于对数据进行建模和聚类。它假设数据由 **多个高斯分布（正态分布）混合**而成，每个高斯分布代表一个潜在的子群体（cluster）。

数学上，GMM 可以写作：

$$
p(x) = \sum_{k=1}^{K} \pi_k \mathcal{N}(x|\mu_k, \Sigma_k)
$$

其中：

* $K$ ：高斯分布的个数，也就是潜在群体数

* $\pi_k$ ：第 $k$ 个高斯分布的混合权重，满足 $\sum_{k=1}^{K} \pi_k = 1$

* $\mathcal{N}(x|\mu_k, \Sigma_k)$ ：第 $k$ 个高斯分布的概率密度函数

* $\mu_k, \Sigma_k$ ：第 $k$ 个高斯分布的均值向量和协方差矩阵

> 核心思想：每个样本点 $x$ 都有一定概率属于每个高斯分布（软聚类），而不是像 K-Means 那样直接划入某个簇（硬聚类）。

## Beta 分布

Beta 分布是一类定义在 **区间 $[0,1]$ 上** 的连续概率分布，由两个正参数 $\alpha, \beta > 0$ 控制形状。

其概率密度函数（PDF）为：

$$
f(x; \alpha, \beta) = \frac{x^{\alpha-1}(1-x)^{\beta-1}}{B(\alpha,\beta)}, \quad 0<x<1
$$

其中 $B(\alpha, \beta)$ 是 Beta 函数：

$$
B(\alpha,\beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}
$$

$\Gamma(\cdot)$ 是 Gamma 函数，是阶乘的推广：$\Gamma(n) = (n-1)!$ （当 $n$ 为正整数时）。

> 参数含义

* $\alpha$ 决定分布在 **接近 1** 的形状

* $\beta$ 决定分布在 **接近 0** 的形状

> 均值和方差为

$$
\mathbb{E}[X] = \frac{\alpha}{\alpha+\beta}
$$

$$
Var[X] = \frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}
$$

> 特殊情况

![$\alpha=\beta=1$](2/4.png)

* 当 $\alpha=\beta=1$：退化为 **均匀分布 U(0,1)**

![$\alpha=\beta=0.5$](2/5.png)

* 当 $\alpha=\beta<1$：分布在两端更集中（接近 0 或 1）

![$\alpha=\beta=32$](2/6.png)

* 当 $\alpha=\beta>1$：分布在中间更集中（接近 0.5）

![$\alpha=32 , \beta=1$](2/7.png)

* 当 $\alpha>1, \beta=1$：分布偏向 1

![$\alpha=1 , \beta=32$](2/8.png)

* 当 $\alpha=1, \beta>1$：分布偏向 0

> 与二项分布/贝叶斯的关系

Beta 分布常被称为 **二项分布的共轭先验**。

* 如果我们有 $n$ 次伯努利试验，成功次数为 $k$

* 假设成功概率 $p$ 的先验分布为 $Beta(\alpha,\beta)$

* 那么后验分布也是一个 Beta 分布：

$$
p \mid \text{data} \sim Beta(\alpha + k, \beta + (n-k))
$$

这就是 Beta 分布在贝叶斯学习中的重要性。

> Beta 分布的一个超能力是：用它作为二项分布的先验，看到数据之后，它的形式不变（还是 Beta 分布），只需要把参数加上观测次数就行，非常方便。

> 在机器学习中的应用

**(1) 标签噪声建模**

* 用 Beta 分布拟合样本损失的分布，可以区分「干净样本」和「噪声样本」。

**(2) Mixup 数据增强**

* 从 $Beta(\alpha,\alpha)$ 中采样 $\lambda$，作为两张图片的混合系数： $x_{mix} = \lambda x_i + (1-\lambda)x_j$

**(3) 探索-利用问题（Bandit 问题）**

* 在强化学习/多臂老虎机问题中，Beta 分布经常作为成功率的后验。

**(4) 概率建模**

* 因为 Beta 分布限制在 $[0,1]$，适合建模概率本身。

> 直观理解

可以把 Beta 分布看作是 **“在 0 到 1 之间对概率值的信心”**：

* $\alpha$ 越大，表示我们对「成功概率接近 1」越有信心

* $\beta$ 越大，表示我们对「失败概率接近 0」越有信心

例如：

* $Beta(1,1)$：我们完全没有先验知识（均匀分布）

* $Beta(100,1)$：我们很相信概率接近 1

* $Beta(1,100)$：我们很相信概率接近 0

Beta 分布是定义在 $[0,1]$ 上的连续分布，形状由 $\alpha,\beta$ 控制。它是二项分布的共轭先验，常用于贝叶斯建模、噪声处理和数据增强。在机器学习里，它的直观含义就是「在 $[0,1]$ 之间对某个概率的信心程度」。
