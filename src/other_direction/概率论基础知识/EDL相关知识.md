---
title: 证据深度学习相关知识整理
icon: file
category:
  - 概率论
tag:
  - 已发布
footer: 技术共建，知识共享
date: 2025-09-29
order: 3
author:
  - BinaryOracle
---

`证据深度学习相关知识整理` 

<!-- more -->

## 主观逻辑 (Subjective Logic)

**主观逻辑 (Subjective Logic)** 是一种**概率逻辑**，它明确地将**认知不确定性**和**信息源信任度**纳入考量。简单来说，它是一种用于在**不确定、信息不完整或信息源不可靠**的情况下进行推理和决策的数学框架。

> **主观意见**（Subjective Opinion）

主观逻辑的核心是**主观意见**（Subjective Opinion），它取代了传统概率论中的单一概率值。一个主观意见 $\omega$ 不仅表达了对某个命题（例如：“命题 $x$ 为真”）的**信念程度**，还表达了关于这个信念本身的**不确定程度**。

对于一个二元命题（如：是/否），一个主观意见 $\omega_x$ 通常由四个分量组成：

1.  **信念值 (Belief Mass, $b_x$)**：相信命题 $x$ 为真的程度。

2.  **不信值 (Disbelief Mass, $d_x$)**：相信命题 $x$ 为假的程度。

3.  **不确定性 (Uncertainty Mass, $u_x$)**：由于缺乏证据或证据不完整而导致的不确定程度。

4.  **先验概率/基准率 (Base Rate, $a_x$)**：在没有任何证据的情况下，命题 $x$ 预期的概率。

这三个信念分量之和必须满足：

$$b_x + d_x + u_x = 1$$

> **主观意见与概率的关系**

主观意见可以看作是对传统概率的推广。通过将不确定性 $u_x$ 明确地表示出来，主观逻辑能够区分“**确定的概率**”（$u_x=0$）和“**不确定的概率**”（$u_x>0$）。

可以根据主观意见计算出对应的**期望概率 (Expectation Probability)** $P(x)$：

$$P(x) = b_x + a_x u_x$$

这个期望概率是在考虑了信念、不信和不确定性后，对命题 $x$ 为真的最佳点估计。

> 主要特点与优势

1. 明确建模不确定性 (Explicitly Models Uncertainty)

主观逻辑的核心优势在于它能够**量化和保留不确定性**。在传统的概率论中，如果不确定性很高，我们可能仍然被迫给出一个 $P(x)=0.5$ 的概率值，这看起来和掷硬币的确定概率一样。而在主观逻辑中，一个完全不确定的情况会表示为 $b_x=0, d_x=0, u_x=1$，这与 $b_x=0.5, d_x=0.5, u_x=0$（掷硬币）明显不同，从而避免了“**无知与均等信念**”之间的混淆。

2. 与二元逻辑和概率论兼容 (Compatibility)

主观逻辑的运算符（如合取、析取、条件演绎等）是对传统**布尔逻辑**（当 $u_x=0$ 且 $b_x, d_x$ 只有 0 或 1 时）和**概率演算**（当 $u_x=0$ 时）的**泛化**。

3. 处理信任和信息来源 (Source Trust and Evidence)

主观逻辑特别适用于建模**信任网络**。它允许在聚合来自不同来源的信息时，考虑每个信息来源的**信任度**，通过“**折算 (Discounting)**”等操作来调整意见。

## Dempster-Shafer 证据理论 (DST)

**Dempster-Shafer 证据理论 (DST, Dempster-Shafer Theory of Evidence)**，又称 **信度理论 (Theory of Belief Functions)**，是一种用于 **不确定性推理** 的数学框架。

它最早由 **Arthur P. Dempster** 在1967年提出，后由 **Glenn Shafer** 在1976年的著作《A Mathematical Theory of Evidence》中系统化。

DST 的核心思想是：

* 在处理 **不完整、模糊或冲突性证据** 时，直接用 **概率论** 往往过于严格或困难。

* DST 提供了一种更宽松的表示方式，它不要求为所有事件精确给出概率，而是允许以 **信度 (belief)** 和 **似然度 (plausibility)** 的区间来描述。

DST 的关键组成部分包括：

* **识别框架 (Frame of Discernment, Θ)**：所有可能结果的集合。

* **基本概率分配 (Basic Probability Assignment, BPA 或 Mass function, m)**：把一定的置信度分配给 Θ 的子集，而不是单个事件。

* **信度函数 (Belief, Bel)**：表示对某个命题的最小可信度。

* **似然度函数 (Plausibility, Pl)**：表示对某个命题的最大可能可信度。

关系：

$$
Bel(A) \leq P(A) \leq Pl(A), \quad \forall A \subseteq \Theta
$$

这意味着，概率 $P(A)$ 必然落在信度和似然度之间。

> DST 的机制可以分为三部分：

1. 基本概率分配 (BPA)

- 给定识别框架 Θ（比如 Θ = {猫, 狗, 兔子}），我们把置信度分配到子集上：
   
    - m({猫}) = 0.3
   
    - m({狗}) = 0.2
   
    - m({猫,狗}) = 0.4 （表示“可能是猫也可能是狗”）
   
    - m(Θ) = 0.1 （表示“完全不确定”）

- 要求：
    
    $$
    m(\emptyset) = 0, \quad \sum_{A \subseteq \Theta} m(A) = 1
    $$
    
2. 信度与似然度

- 信度 Bel(A)：所有 **完全支持 A 的子集** 的 BPA 之和。

- 似然度 Pl(A)：所有 **不与 A 矛盾的子集** 的 BPA 之和。

    $$ 
    Bel(A) = \sum_{B \subseteq A} m(B), \quad Pl(A) = \sum_{B \cap A \neq \emptyset} m(B)
    $$

3. Dempster 合成规则

- 用于将来自 **不同信息源** 的 BPA 进行合并：
    
    $$
    m_{12}(C) = \frac{1}{1-K} \sum_{A \cap B = C} m_1(A) \cdot m_2(B)
    $$
    
    其中 $K = \sum_{A \cap B = \emptyset} m_1(A) \cdot m_2(B)$ 表示冲突度。
    
- 意义：如果两个证据源冲突较大（K接近1），合成后的结果会受到显著影响。

### Dempster 合成规则

我们想判断一个目标是不是 **猫(Cat)** 还是 **狗(Dog)**。识别框架：$\Theta = {\text{Cat}, \text{Dog}}$。

现在有两个证据源：

* **证据源1（传感器1）**：比较确信是猫

  * $m_1({Cat}) = 0.6$

  * $m_1({Dog}) = 0.3$
  
  * $m_1(\Theta) = 0.1$（表示不确定，是猫还是狗）

* **证据源2（传感器2）**：更偏向狗

  * $m_2({Cat}) = 0.2$
  
  * $m_2({Dog}) = 0.7$
  
  * $m_2(\Theta) = 0.1$

> 合成步骤

1. 两两相乘，分类到“交集”

我们把每个集合 (A)（来自证据1）和 (B)（来自证据2）组合，看它们交集是什么：

| 来自证据1 | 来自证据2 | 交集    | 乘积                   |
| ----- | ----- | ----- | -------------------- |
| `{Cat}` | `{Cat}` | `{Cat}` | 0.6 × 0.2 = **0.12** |
| `{Cat}` | `{Dog}` | ∅（冲突） | 0.6 × 0.7 = **0.42** |
| `{Cat}` | Θ     | `{Cat}` | 0.6 × 0.1 = **0.06** |
| `{Dog}` | `{Cat}` | ∅（冲突） | 0.3 × 0.2 = **0.06** |
| `{Dog}` | `{Dog}` | `{Dog}` | 0.3 × 0.7 = **0.21** |
| `{Dog}` | Θ     | `{Dog}` | 0.3 × 0.1 = **0.03** |
| Θ     | `{Cat}` | `{Cat}` | 0.1 × 0.2 = **0.02** |
| Θ     | `{Dog}` | `{Dog}` | 0.1 × 0.7 = **0.07** |
| Θ     | Θ     | Θ     | 0.1 × 0.1 = **0.01** |

--- 

2. 整理结果

* 分给 **{Cat}** 的：0.12 + 0.06 + 0.02 = **0.20**

* 分给 **{Dog}** 的：0.21 + 0.03 + 0.07 = **0.31**

* 分给 **Θ** 的：0.01

* **冲突 K** = 0.42 + 0.06 = **0.48**

--- 

3. 归一化（去掉冲突部分）

冲突比例 $K = 0.48$，所以归一化因子 $(1 - K) = 0.52$。

把前面非冲突部分都除以 0.52：

* $m_{12}({Cat}) = 0.20 / 0.52 ≈ 0.385$

* $m_{12}({Dog}) = 0.31 / 0.52 ≈ 0.596$

* $m_{12}(\Theta) = 0.01 / 0.52 ≈ 0.019$

---

4. 最终结果

* 猫的支持度 ≈ 38.5%

* 狗的支持度 ≈ 59.6%

* 仍然有一点点不确定 ≈ 1.9%

> 理解

* 虽然第一个传感器更偏向猫（0.6），但第二个传感器更强烈支持狗（0.7），合成后系统整体更倾向于“狗”。

* 中间的大冲突（0.48）被“抹掉”，剩余证据按比例分给了相容的结果。

#### 为什么抹除冲突部分 ？

在合成两个证据时，如果一个证据支持集合 (A)，另一个证据支持集合 (B)，而 **(A \cap B = \varnothing)**，就出现了冲突。

例子：

* 证据1：90% 认为是 **猫**

* 证据2：90% 认为是 **狗**

因为“猫”和“狗”不可能同时为真，所以这部分乘积就是**冲突度 K**；Dempster–Shafer 理论想要的是 **“一致证据的合力”**。它假设：

* 证据源是 **相互独立** 的，冲突是由于“偶然噪声、有限性信息”等原因产生的，因此，冲突不代表“第三种情况”，而应该**被忽略**。

所以：

* 他把所有相容证据累加，把冲突度 (K) “丢掉”，然后把剩下的相容质量归一化到 1。

数学上，就是：

$$
m_{12}(C) = \frac{\sum_{A\cap B=C} m_1(A)m_2(B)}{1-K}
$$

可以这样理解：

* 只保留“有可能共存的证据”。

* 把冲突部分看成“垃圾数据”，不允许它稀释相容证据。

* 最后归一化，是为了保持 **总和 = 1** 的概率质量框架。

所以，**“抹除冲突部分”其实是 DST 的设计选择**：认为冲突只是无效信息，不必在结果里占比。这种做法在冲突较小时是合理的，但如果冲突很大（(K) → 1）：

* 归一化会把很少的一点相容证据“放大”，导致结果可能严重偏向某一方，出现“反直觉”现象。

* 因此学界提出了替代方法：

  * **Yager 规则**：不抹掉冲突，而是把冲突质量分配到全集 $\Theta$，表示“完全不确定”。

  * **Dubois–Prade 规则**：把冲突分配到交集为空的“并集”。

  * **PCR（Proportional Conflict Redistribution）**：把冲突按比例分配回原始冲突的集合。

## Dirichlet 分布

Dirichlet 分布是 **概率向量的分布**，常用作多项式分布参数的 **共轭先验**。

* 假设有 $K$ 个类别，每个类别出现的概率为 $\theta_i$，满足：
  
  $$
  \theta_i \ge 0, \quad \sum_{i=1}^{K} \theta_i = 1
  $$

* 如果向量 $\boldsymbol{\theta} = (\theta_1,...,\theta_K)$ 服从 Dirichlet 分布，参数为 $\boldsymbol{\alpha} = (\alpha_1,...,\alpha_K)$，记作：
  
  $$
  \boldsymbol{\theta} \sim \text{Dir}(\alpha_1,...,\alpha_K)
  $$

* **概率密度函数（PDF）**：

  $$
  p(\theta_1,...,\theta_K) = \frac{1}{B(\boldsymbol{\alpha})} \prod_{i=1}^{K} \theta_i^{\alpha_i-1}, \quad \theta_i \ge 0, \sum \theta_i = 1
  $$

* **归一化常数**：

  $$
  B(\boldsymbol{\alpha}) = \frac{\prod_{i=1}^K \Gamma(\alpha_i)}{\Gamma(\sum_{i=1}^K \alpha_i)}
  $$

  其中 $\Gamma(\cdot)$ 是 Gamma 函数（阶乘的连续推广）。

> 直观理解

1. **概率向量**

   * Dirichlet 分布生成的是一个满足 $\sum \theta_i = 1$ 的向量。
   
   * 适合描述 K 类概率的不确定性。

2. **参数 $\alpha_i$ 的作用**：

   * $\alpha_i > 1$：$\theta_i$ 倾向于大
   
   * $\alpha_i < 1$：$\theta_i$ 倾向于接近 0
   
   * $\alpha_i = 1$：均匀分布

3. **K=2 时退化成 Beta 分布**：
   
   $$
   \text{Dir}(\alpha_1, \alpha_2) = \text{Beta}(\alpha_1, \alpha_2)
   $$

> 期望与方差

设 $\alpha_0 = \sum_{i=1}^K \alpha_i$，则：

$$
\mathbb{E}[\theta_i] = \frac{\alpha_i}{\alpha_0}
$$

$$
\text{Var}[\theta_i] = \frac{\alpha_i (\alpha_0 - \alpha_i)}{\alpha_0^2 (\alpha_0+1)}
$$

$$
\text{Cov}[\theta_i, \theta_j] = - \frac{\alpha_i \alpha_j}{\alpha_0^2 (\alpha_0+1)}, \quad i \neq j
$$

* 解释：向量分量之间是负相关的，因为 $\sum \theta_i = 1$。

> 与其他分布的关系

| 分布          | 维度 | 关系                    |
| ----------- | -- | --------------------- |
| Beta        | 1  | K=2 的 Dirichlet       |
| Bernoulli   | 1  | 单次二分类，Beta 是共轭先验      |
| Binomial    | 1  | 多次二分类，Beta 是共轭先验      |
| Categorical | K  | 单次多分类，Dirichlet 是共轭先验 |
| Multinomial | K  | 多次多分类，Dirichlet 是共轭先验 |

## DS理论与证据深度学习的关系

Dempster-Shafer 理论（DS theory）是一种 **不确定性推理框架**，又叫 **证据理论**。它不像概率论必须对所有事件分配精确概率，DS theory 允许对“集合”分配 **置信质量 (basic belief assignment, BBA)**。结果有三类：

* **信任度 (belief)**：保守下界（多大程度可以肯定事件成立）。

* **似然度 (plausibility)**：乐观上界（多大程度可能事件成立）。

* **未分配证据**：代表模糊、不确定性。

这比单一概率分布更能表达 **不确定性和模糊性**。

---

Evidential Deep Learning (EDL) 的核心目标：让神经网络 **输出不仅仅是概率分布 (softmax)**，而是 **概率分布 + 不确定性度量**。实现思路：

* EDL 把分类问题建模为 **Dirichlet 分布**，其参数由网络输出的“证据 (evidence)”决定。

* 每个类别的证据量类似“观察到多少支持它的证据”，和 DS theory 的“基本信任分配 (BBA)”对应。

* 从证据中可以计算出：

    * **期望概率 (expected probability)** → 相当于传统 softmax 概率。
  
    * **不确定性 (uncertainty mass)** → 对应 DS theory 中的“未分配证据”。

换句话说，EDL 实际上是 **把 DS theory 与贝叶斯框架嫁接到深度学习上**。

两者关系总结:

* **理论基础**：EDL 的不确定性建模思想来源于 Dempster-Shafer theory。

* **映射关系**：

  * DS theory 中的 **BBA (基本信任分配)** → EDL 中的 **证据 (evidence)**。

  * DS theory 中的 **未分配信任质量** → EDL 中的 **不确定性分量**。

  * DS theory 中的 **belief/plausibility 区间** → EDL 中的 **Dirichlet 分布参数范围**。

* **改进点**：DS theory 是符号级推理，而 EDL 通过神经网络 **自动学习证据分配**，可扩展到图像识别、NLP 等任务。

**Evidential Deep Learning (EDL) = 深度学习框架下的 Dempster-Shafer 证据理论应用与扩展**。它让网络不仅输出类别概率，还能输出“不确定性”，从而在 **小样本、分布外 (OOD) 检测、风险决策**等场景表现更好。

## DS融合规则并没有在EDL中使用

**Dempster’s Rule of Combination**: 用于将来自不同来源的 **独立证据** 融合成新的信任分配 (BBA)。

- 公式思想：如果两条证据都支持某个事件，就增强其置信；若冲突，则按比例削弱，并把冲突质量重新分配。

- 应用场景：多传感器融合、专家意见整合等。

**EDL 并没有直接使用 Dempster’s combination rule**。它的核心是：

- 神经网络输出“证据” → 转化为 **Dirichlet 分布参数**。

- Dirichlet 分布提供了 **类别概率期望** 和 **不确定性质量**。

- 训练时，EDL 使用的是一种 **损失函数**（基于 **期望交叉熵 + KL 正则**），来约束证据学习，而不是对多来源证据做融合。

---

**DS theory 的 spirit（精神）** 在 EDL 中体现了： “部分证据 + 未分配证据” → “分类概率 + 不确定性”。

**DS theory 的 combination rule** 在 EDL 中 **没有被直接使用**，因为：

  * EDL 假设证据是由同一个神经网络单源生成的，而不是多源传感器/多专家场景。

  * 如果需要多模型/多传感器证据融合，可以在 EDL 的输出层（Dirichlet 参数）或 BBA 表达形式上，再套用 DS 融合规则，但这不是 EDL 标准做法，而是后续研究方向。

---

结论：

**EDL 借鉴了 DS 理论的“信任质量 + 未分配证据”思想，但没有用到 Dempster 的融合规则**。 不过，如果做 **多模型集成、联邦学习、传感器融合**，完全可以把 EDL 学到的证据结果再用 DS 规则做二次融合，这其实是个很有潜力的研究方向。

