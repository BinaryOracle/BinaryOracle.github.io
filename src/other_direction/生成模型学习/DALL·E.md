---
title: DALLÂ·E è®ºæ–‡
icon: file
category:
  - å¤šæ¨¡æ€
tag:
  - å¤šæ¨¡æ€
  - ç¼–è¾‘ä¸­
footer: æŠ€æœ¯å…±å»ºï¼ŒçŸ¥è¯†å…±äº«
date: 2025-08-04
author:
  - BinaryOracle
---

`DALLÂ·E è®ºæ–‡` 

<!-- more -->

> è®ºæ–‡é“¾æ¥: [Zero-Shot Text-to-Image Generation](https://arxiv.org/abs/2102.12092)
> ç¬¬ä¸‰æ–¹ä»£ç å®ç°: [DALL-E](https://github.com/lucidrains/DALLE-pytorch/tree/main)

## ä»£ç å®ç°

`DALLÂ·E` å°† **æ–‡æœ¬-å›¾åƒç”Ÿæˆ** é—®é¢˜å»ºæ¨¡ä¸ºä¸€ä¸ª**è‡ªå›å½’è¯­è¨€å»ºæ¨¡ä»»åŠ¡**ï¼Œå³å°†**æ–‡æœ¬ token å’Œå›¾åƒ token æ‹¼æ¥**èµ·æ¥ï¼Œä½œä¸ºä¸€ä¸ª**ç»Ÿä¸€çš„åºåˆ—**è¿›è¡Œè®­ç»ƒï¼Œä»è€Œå­¦ä¼šç”Ÿæˆå›¾åƒçš„ç¦»æ•£è¡¨ç¤ºã€‚ å…·ä½“çš„æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤º:

![DALL-E æ¨¡å‹å‰å‘ä¼ æ’­æ•´ä½“æµç¨‹](DALL-E/3.png)

### æ¨¡å‹åˆå§‹åŒ–

æˆ‘ä»¬éœ€è¦é€šè¿‡ `DALL-E` æ¨¡å‹çš„åˆå§‹åŒ–æµç¨‹ï¼Œæ¥ç†Ÿæ‚‰æ¨¡å‹ä¸­ä½¿ç”¨åˆ°çš„ä¸€äº›å‚æ•°åŠå…¶å«ä¹‰:

```python
def __init__(
    self,
    *,
    dim,                              # Transformer çš„éšè—ç»´åº¦
    vae,                              # ç¼–ç å›¾åƒçš„ VAE æ¨¡å‹ï¼ˆç”¨äº image token çš„æå–ï¼‰
    num_text_tokens = 10000,         # æ–‡æœ¬è¯è¡¨å¤§å°ï¼ˆä¸å« position padding tokenï¼‰
    text_seq_len = 256,              # æ–‡æœ¬åºåˆ—æœ€å¤§é•¿åº¦
    depth,                           # Transformer block å±‚æ•°
    heads = 8,                       # Attention å¤´æ•°
    dim_head = 64,                   # æ¯ä¸ª attention head çš„ç»´åº¦
    reversible = False,              # æ˜¯å¦ä½¿ç”¨ reversible transformer
    attn_dropout = 0.,               # attention dropout æ¦‚ç‡
    ff_dropout = 0,                  # feedforward dropout æ¦‚ç‡
    sparse_attn = False,             # æ˜¯å¦ä½¿ç”¨ç¨€ç– attention
    attn_types = None,               # å¤šç§ attention ç±»å‹ï¼ˆå¯é€‰ï¼‰
    loss_img_weight = 7,            # å›¾åƒæŸå¤±åœ¨æœ€ç»ˆ loss ä¸­çš„æƒé‡
    stable = False,                  # æ˜¯å¦ä½¿ç”¨ numerically stable çš„ norm
    sandwich_norm = False,          # æ˜¯å¦é‡‡ç”¨ sandwich norm ç­–ç•¥ï¼ˆå‰ä¸­åéƒ½åŠ  layernormï¼‰
    shift_tokens = True,            # æ˜¯å¦å¯¹è¾“å…¥ token åš right shiftï¼ˆè®­ç»ƒï¼‰
    rotary_emb = True,              # æ˜¯å¦ä½¿ç”¨ rotary embeddingï¼ˆç›¸å¯¹ä½ç½®ç¼–ç ï¼‰
    shared_attn_ids = None,         # ç”¨äºæ¨¡å—å…±äº«çš„ attention å±‚ IDï¼ˆå¯é€‰ï¼‰
    shared_ff_ids = None,           # ç”¨äºæ¨¡å—å…±äº«çš„ feedforward å±‚ IDï¼ˆå¯é€‰ï¼‰
    share_input_output_emb = False, # æ˜¯å¦è¾“å…¥è¾“å‡º embedding æƒé‡å…±äº«
    optimize_for_inference = False, # æ˜¯å¦ä¸ºæ¨ç†æ¨¡å¼ä¼˜åŒ–ç»“æ„
):
```

è¿™é‡Œå…³äº `text_seq_len` å‚æ•°å’Œæ–‡æœ¬è¯ç©ºé—´çš„æ„æˆéœ€è¦ç®€å•è¯´æ˜ä¸€ä¸‹:

![](DALL-E/4.png)

å›¾åƒ Token ç›¸å…³è®¡ç®—:

```python
    image_size = vae.image_size                     # è¾“å…¥å›¾åƒå¤§å°ï¼ˆä¾‹å¦‚ 256x256ï¼‰
    num_image_tokens = vae.num_tokens               # å›¾åƒ token çš„è¯è¡¨å¤§å°
    image_fmap_size = (image_size // (2 ** vae.num_layers))  # ç¼–ç å feature map çš„å¤§å°
    image_seq_len = image_fmap_size ** 2            # å›¾åƒ token åºåˆ—é•¿åº¦ï¼ˆflatten ä¹‹åï¼‰
```
> vae.num_layers æ˜¯ VAE ç¼–ç å™¨ä¸­çš„å·ç§¯å±‚ä¸ªæ•°ï¼Œæ¯å±‚ä¸‹é‡‡æ ·ä¸€æ¬¡ï¼ˆä¸€èˆ¬æ˜¯ stride=2ï¼‰ã€‚ å›¾åƒç»è¿‡ VAE ç¼–ç å™¨ä¸‹é‡‡æ ·åï¼Œç‰¹å¾å›¾çš„è¾¹é•¿ = åŸå›¾è¾¹é•¿ / 2^å±‚æ•°

> å›¾åƒè¾“å…¥ç»è¿‡ VAE ç¼–ç åï¼Œå˜æˆäº† image_fmap_size Ã— image_fmap_size çš„äºŒç»´ token mapï¼Œå±•å¹³åæ˜¯ image_seq_len é•¿åº¦çš„ä¸€ç»´åºåˆ—ï¼Œä¾› Transformer ä½¿ç”¨ã€‚
> ![](DALL-E/5.png)


æ–‡æœ¬ token æ€»æ•°è°ƒæ•´ï¼ˆæ·»åŠ  padding tokenï¼‰:

```python
    num_text_tokens = num_text_tokens + text_seq_len  # æ¯ä¸ªä½ç½®é¢„ç•™ä¸€ä¸ªç‰¹æ®Š padding token
```

ä½ç½®ç¼–ç è®¾ç½® :

```python
    self.text_pos_emb = nn.Embedding(text_seq_len + 1, dim) if not rotary_emb else always(0)
    # æ–‡æœ¬ä½ç½®ç¼–ç ï¼ˆ+1 æ˜¯ä¸ºäº† <BOS> tokenï¼‰ï¼Œå¦‚æœç”¨ rotary å°±è¿”å› 0

    self.image_pos_emb = AxialPositionalEmbedding(dim, axial_shape=(image_fmap_size, image_fmap_size)) if not rotary_emb else always(0)
    # å›¾åƒä½¿ç”¨äºŒç»´ axial ä½ç½®ç¼–ç ï¼ˆé»˜è®¤ï¼‰
```
ä¿å­˜é…ç½®å‚æ•° :

```python
    self.num_text_tokens = num_text_tokens
    self.num_image_tokens = num_image_tokens
    self.text_seq_len = text_seq_len
    self.image_seq_len = image_seq_len

    seq_len = text_seq_len + image_seq_len               # æ€»åºåˆ—é•¿åº¦
    total_tokens = num_text_tokens + num_image_tokens    # æ€»è¯è¡¨å¤§å°
    self.total_tokens = total_tokens
    self.total_seq_len = seq_len
```

å†»ç»“ VAE æƒé‡ï¼ˆä¸å‚ä¸è®­ç»ƒï¼‰:

```python
    self.vae = vae
    set_requires_grad(self.vae, False)
```

æ„é€  Transformer ä¸»ä½“ :

```python
    self.transformer = Transformer(
        dim = dim,
        causal = True,                  # è‡ªå›å½’æ¨¡å‹
        seq_len = seq_len,
        depth = depth,
        heads = heads,
        dim_head = dim_head,
        reversible = reversible,
        attn_dropout = attn_dropout,
        ff_dropout = ff_dropout,
        attn_types = attn_types,
        image_fmap_size = image_fmap_size,
        sparse_attn = sparse_attn,
        stable = stable,
        sandwich_norm = sandwich_norm,
        shift_tokens = shift_tokens,
        rotary_emb = rotary_emb,
        shared_attn_ids = shared_attn_ids,
        shared_ff_ids = shared_ff_ids,
        optimize_for_inference = optimize_for_inference,
    )
```
> å› ä¸ºä¸ºæ¯ä¸ª padding ä½ç½®ä¿ç•™äº†å”¯ä¸€ token idï¼ŒTransformer ä¸å†éœ€è¦å¤–éƒ¨çš„ pad maskã€‚

è¾“å‡º projection å±‚ï¼ˆLogitsï¼‰:

```python
    self.to_logits = nn.Sequential(
        nn.LayerNorm(dim),
        nn.Linear(dim, self.total_tokens),  # è¾“å‡ºç»´åº¦ä¸ºæ•´ä¸ª text + image çš„ token vocab
    )
```

æ„é€  token embedding å±‚ï¼ˆè¾“å…¥ï¼‰:

```python
    if share_input_output_emb:
        # å¦‚æœå¯ç”¨æƒé‡å…±äº«ï¼Œå°† to_logits çš„ Linear æ‹†åˆ†ä½œä¸ºå…±äº«çŸ©é˜µ
        self.text_emb = SharedEmbedding(self.to_logits[1], 0, num_text_tokens)
        self.image_emb = SharedEmbedding(self.to_logits[1], num_text_tokens, total_tokens)
    else:
        self.text_emb = nn.Embedding(num_text_tokens, dim)
        self.image_emb = nn.Embedding(num_image_tokens, dim)
```

æ„é€  Logits Mask:

```python
    seq_range = torch.arange(seq_len)        # åºåˆ—ä¸­æ¯ä¸ª token çš„ä½ç½®ç¼–å·ï¼ˆ0~seq_len-1ï¼‰
    logits_range = torch.arange(total_tokens) # æ€»è¯è¡¨ä¸­çš„æ¯ä¸ª token idï¼ˆ0~total_tokens-1ï¼‰

    seq_range = rearrange(seq_range, 'n -> () n ()')     # å˜æˆ shape (1, seq_len, 1)
    logits_range = rearrange(logits_range, 'd -> () () d') # å˜æˆ shape (1, 1, total_tokens)

    logits_mask = (
        ((seq_range >= text_seq_len) & (logits_range < num_text_tokens)) |
        ((seq_range < text_seq_len) & (logits_range >= num_text_tokens))
    )
    # å¦‚æœä½ç½®åœ¨å›¾åƒæ®µï¼ˆtext_seq_lenä¹‹åï¼‰ï¼Œå´è¾“å‡º text token â†’ å±è”½
    # å¦‚æœä½ç½®åœ¨æ–‡æœ¬æ®µï¼ˆtext_seq_lenä¹‹å‰ï¼‰ï¼Œå´è¾“å‡º image token â†’ å±è”½

    self.register_buffer('logits_mask', logits_mask, persistent=False) # ä¿å­˜ mask åˆ° bufferï¼ˆä¸ä¼šè¢«æ¨¡å‹è®­ç»ƒä¿®æ”¹ï¼‰
```
ç”±äºæ–‡æœ¬tokenå’Œå›¾åƒtokenè¢«æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œä½œä¸ºç»Ÿä¸€çš„åºåˆ—è¾“å…¥Transformerè¿›è¡Œç¼–ç ï¼Œ

![](DALL-E/6.png)

ä¸”æ–‡æœ¬è¯ç©ºé—´å’Œå›¾åƒç¦»æ•£è§†è§‰è¯ç©ºé—´ä¹Ÿé€šè¿‡è§†è§‰è¯ç´¢å¼•åç§»çš„æ–¹å¼å®Œæˆäº†ç»Ÿä¸€ï¼Œ

![](DALL-E/7.png)

å› æ­¤æ‰æœ‰äº†Transformerå¯ä»¥ä¸€æ¬¡æ€§é¢„æµ‹å‡ºæ¯ä¸ªä½ç½®å¯¹åº”çš„Next Tokenèƒ½åŠ›ï¼Œ

![](DALL-E/8.png)

ä½†é—®é¢˜å°±åœ¨äºå±äºæŸä¸ªæ–‡æœ¬Tokenä½ç½®å¤„çš„é¢„æµ‹ç»“æœå‘é‡ä¸­ï¼Œå…¶åæ˜ çš„å®é™…æ˜¯æ•´ä¸ªç»Ÿä¸€è¯ç©ºé—´ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒï¼Œå¦‚æœæ¦‚ç‡æœ€é«˜çš„é‚£ä¸ªTokenæ˜¯å›¾åƒTokenï¼Œé‚£ä¹ˆå°±ä¼šå¯¼è‡´æ¨¡æ€æ··ä¹±äº†ï¼Œ

![](DALL-E/9.png)

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…å¼•å…¥äº† `Logits Mask`  , å¦‚æœå½“å‰å¾…é¢„æµ‹Tokenä½ç½®å±äºæ–‡æœ¬è¯ï¼Œåˆ™å°†å…¶æ¦‚ç‡åˆ†å¸ƒä¸­çš„ç¦»æ•£è§†è§‰è¯ç´¢å¼•ç©ºé—´å¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒè®¾ç½®ä¸º0ï¼Œ

![](DALL-E/10.png)

åä¹‹ï¼Œå¦‚æœå½“å‰å¾…é¢„æµ‹Tokenä½ç½®å±äºç¦»æ•£è§†è§‰è¯ï¼Œåˆ™å°†å…¶æ¦‚ç‡åˆ†å¸ƒä¸­çš„æ–‡æœ¬è¯ç´¢å¼•ç©ºé—´å¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒè®¾ç½®ä¸º0ï¼Œ

![](DALL-E/11.png)

å…·ä½“æ¥è¯´:

```python
import torch

# å‡è®¾é…ç½®
text_seq_len = 4   # è¾“å…¥æ–‡æœ¬åºåˆ—é•¿åº¦
image_seq_len = 2  # æ¯ä¸ªå›¾åƒç”±ä¸¤ä¸ªç¦»æ•£è§†è§‰tokenè¿›è¡Œè¡¨ç¤º
total_seq_len = text_seq_len + image_seq_len # æ€»è¾“å…¥åºåˆ—é•¿åº¦
num_text_tokens = 4 # æ–‡æœ¬è¯è¡¨å¤§å°
num_image_tokens = 5 # ç¦»æ•£è§†è§‰è¯è¡¨å¤§å°
total_tokens = num_text_tokens + num_image_tokens # æ€»è¯è¡¨å¤§å°

# æ„é€  logits_mask
seq_range = torch.arange(total_seq_len).view(1, total_seq_len, 1)
logits_range = torch.arange(total_tokens).view(1, 1, total_tokens)

logits_mask = ((seq_range >= text_seq_len) & (logits_range < num_text_tokens)) | \
              ((seq_range < text_seq_len) & (logits_range >= num_text_tokens))

# å°† logits_mask è½¬ä¸º int å±•ç¤ºï¼ˆTrue->1, False->0ï¼‰
logits_mask_int = logits_mask.int()[0]  # åªå±•ç¤ºç¬¬ä¸€ä¸ª batch ç»´åº¦

print(logits_mask_int)
```

è¾“å‡ºç»“æœ:

```python
# å‰4ä¸ªä½ç½®ä¸ºæ–‡æœ¬tokenï¼Œå2ä¸ªä½ç½®ä¸ºå›¾åƒtoken
tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1], # å¯¹äºæ¯ä¸ªtokenæ¥è¯´ï¼Œç»Ÿä¸€è¯ç©ºé—´å¤§å°ä¸º9ï¼Œå…¶ä¸­å‰4ç»´ä¸ºè¯ç©ºé—´ç´¢å¼•ï¼Œå5ç»´ä¸ºç¦»æ•£è§†è§‰è¯ç©ºé—´ç´¢å¼•
        [0, 0, 0, 0, 1, 1, 1, 1, 1], # å¯¹äºæ–‡æœ¬tokenï¼Œå°†ç¦»æ•£è§†è§‰è¯ç©ºé—´ç´¢å¼•å¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒè®¾ç½®ä¸º0 (è¿™é‡Œè®¾ç½®ä¸º1ï¼Œæ˜¯ä¸ºäº†åç»­ä¹˜ä¸Šä¸€ä¸ªæœ€å°å€¼)
        [0, 0, 0, 0, 1, 1, 1, 1, 1],
        [0, 0, 0, 0, 1, 1, 1, 1, 1],

        [1, 1, 1, 1, 0, 0, 0, 0, 0], # å¯¹äºå›¾åƒtokenï¼Œå°†æ–‡æœ¬è¯ç´¢å¼•ç©ºé—´å¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒè®¾ç½®ä¸º0 (è¿™é‡Œè®¾ç½®ä¸º1ï¼Œæ˜¯ä¸ºäº†åç»­ä¹˜ä¸Šä¸€ä¸ªæœ€å°å€¼)
        [1, 1, 1, 1, 0, 0, 0, 0, 0]], dtype=torch.int32)
```

 
### å‰å‘ä¼ æ’­æµç¨‹

æœ¬èŠ‚æœ€å¼€å§‹ç»™å‡ºçš„å‰å‘ä¼ æ’­æµç¨‹å›¾å·²ç»æ¸…æ™°å±•ç¤ºäº† `DALLÂ·E` æ¨¡å‹çš„å‰å‘ä¼ æ’­æµç¨‹ï¼Œä¸‹é¢æˆ‘ä»¬é€šè¿‡ä»£ç è¯¦ç»†æ¥çœ‹ä¸€ä¸‹å…·ä½“å®ç°ç»†èŠ‚:

1. éšæœºå¯¹è¾“å…¥çš„æ–‡æœ¬æ¡ä»¶è¿›è¡Œ Dropout

```python
def forward(
    self,
    text,
    image=None,
    return_loss=False,
    null_cond_prob=0.,
    cache=None,
):
    # è·å– batch sizeã€device å’Œ transformer çš„æœ€å¤§åºåˆ—é•¿åº¦
    batch, device, total_seq_len = text.shape[0], text.device, self.total_seq_len

    # ä»¥ä¸€å®šæ¦‚ç‡éšæœºåˆ é™¤æ–‡æœ¬æ¡ä»¶ï¼ˆç”¨äºè®­ç»ƒæ—¶çš„æ¡ä»¶ dropoutï¼‰
    if null_cond_prob > 0:
        null_mask = prob_mask_like((batch,), null_cond_prob, device=device)
        text *= rearrange(~null_mask, 'b -> b 1')  # å¦‚æœ null_mask=Trueï¼Œåˆ™æ•´æ¡ text è®¾ä¸º 0ï¼ˆå³æ— æ¡ä»¶ï¼‰
```
> ```python
>   def prob_mask_like(shape, prob, device):
>       return torch.zeros(shape, device = device).float().uniform_(0, 1) < prob
> ```   

DALLÂ·E çš„ç›®æ ‡ä¸æ˜¯åªä¼šâ€œæ ¹æ®æ–‡æœ¬ç”Ÿæˆå›¾åƒâ€ï¼Œè¿˜å¸Œæœ›å®ƒèƒ½ï¼š

1. æœ‰æ¡ä»¶ç”Ÿæˆï¼ˆtext â†’ imageï¼‰

2. æ— æ¡ä»¶ç”Ÿæˆï¼ˆéšæœº â†’ imageï¼‰

é€šè¿‡è®©ä¸€éƒ¨åˆ†æ ·æœ¬åœ¨è®­ç»ƒæ—¶ä¸ç»™æ–‡æœ¬è¾“å…¥ï¼Œè®©æ¨¡å‹ä¹Ÿèƒ½å­¦åˆ°â€œå¦‚ä½•ä»…é å›¾åƒç”Ÿæˆå›¾åƒâ€ã€‚

--- 

2. ä¸ºæ¯ä¸€ä¸ªpadding tokenåˆ†é…ä¸€ä¸ªå”¯ä¸€çš„è¯ç´¢å¼•

```python
    # self.num_text_tokens - self.text_seq_len æ˜¯è®¡ç®— padding token åœ¨æ–‡æœ¬è¯ç´¢å¼•ç©ºé—´ä¸­çš„èµ·å§‹ç´¢å¼•
    text_range = torch.arange(self.text_seq_len, device=device) + (self.num_text_tokens - self.text_seq_len)
    text = torch.where(text == 0, text_range, text) # å°† padding token æ›¿æ¢ä¸ºå”¯ä¸€çš„ token ID
```

---

3. æ–‡æœ¬åºåˆ—å¼€å¤´åŠ ä¸Š `<bos> token` , ä½œä¸ºè‡ªå›å½’é¢„æµ‹çš„å¼€å§‹æ ‡å¿—

```python
    # åœ¨æ–‡æœ¬åºåˆ—å¼€å¤´åŠ ä¸Š <bos> tokenï¼ˆå€¼ä¸º0ï¼‰
    text = F.pad(text, (1, 0), value=0)
```
---

4. æ–‡æœ¬ token embedding ä¸ ä½ç½®ç¼–ç 

```python
    # æ–‡æœ¬ token embedding ä¸ä½ç½®ç¼–ç 
    tokens = self.text_emb(text)
    tokens += self.text_pos_emb(torch.arange(text.shape[1], device=device))
    seq_len = tokens.shape[1]  # å½“å‰ token åºåˆ—é•¿åº¦ï¼ˆä»…åŒ…å«æ–‡æœ¬éƒ¨åˆ†ï¼‰
```
--- 

5. è¾“å…¥å›¾åƒç¼–ç ä¸ºç¦»æ•£çš„è§†è§‰Tokenï¼Œè§†è§‰Token embedding ä¸ ä½ç½®ç¼–ç  ï¼Œæœ€åä¸æ–‡æœ¬Token embedding æ‹¼æ¥ï¼Œä½œä¸ºé€å…¥ Transformer çš„è¾“å…¥

```python
    # å¦‚æœè¾“å…¥äº†å›¾åƒï¼ˆä¸”éç©ºï¼‰ï¼Œå¤„ç†å›¾åƒ embedding
    if exists(image) and not is_empty(image):
        is_raw_image = len(image.shape) == 4  # å¦‚æœæ˜¯åŸå§‹å›¾åƒï¼ˆB, C, H, Wï¼‰

        if is_raw_image:
            image_size = self.vae.image_size
            channels = self.vae.channels
            # ç¡®ä¿å›¾åƒå°ºå¯¸æ­£ç¡®
            assert tuple(image.shape[1:]) == (channels, image_size, image_size), \
                f'invalid image of dimensions {image.shape} passed in during training'

            # ä½¿ç”¨ VAE å°†åŸå§‹å›¾åƒç¼–ç ä¸ºç¦»æ•£ codebook indices (after flatten)
            image = self.vae.get_codebook_indices(image)

        image_len = image.shape[1]
        image_emb = self.image_emb(image)  # å›¾åƒ token embedding
        image_emb += self.image_pos_emb(image_emb)  # å›¾åƒä½ç½®ç¼–ç 

        # å°†æ–‡æœ¬å’Œå›¾åƒçš„ embedding æ‹¼æ¥
        tokens = torch.cat((tokens, image_emb), dim=1)
        seq_len += image_len  # æ›´æ–°æ€»é•¿åº¦
```
---

6.  "å³ç§»": åˆ é™¤åºåˆ—æœ€åä¸€ä¸ªtokenï¼Œå› ä¸ºå…¶ä¸å‚ä¸Next Token Predictionï¼›(è®­ç»ƒä¼˜åŒ–Trickä¸è¿›è¡Œè®²è§£)

```python
    # å¦‚æœ token æ€»é•¿åº¦è¶…è¿‡æ¨¡å‹æœ€å¤§é•¿åº¦ï¼Œåˆ™è£å‰ªæ‰æœ€åä¸€ä¸ª tokenï¼ˆè®­ç»ƒæ—¶æœ«å°¾ token ä¸éœ€è¦é¢„æµ‹ï¼‰
    if tokens.shape[1] > total_seq_len:
        seq_len -= 1
        tokens = tokens[:, :-1]

    # å¦‚æœå¯ç”¨äº†ç¨³å®šè®­ç»ƒç­–ç•¥ï¼ˆstabilization trickï¼‰
    if self.stable:
        alpha = 0.1
        tokens = tokens * alpha + tokens.detach() * (1 - alpha)

    # å¦‚æœä½¿ç”¨äº† KV Cacheï¼ˆç”¨äºæ¨ç†é˜¶æ®µï¼‰ï¼Œåªä¿ç•™æœ€åä¸€ä¸ª token
    if exists(cache) and cache.get('offset'):
        tokens = tokens[:, -1:]

    # é€å…¥ transformer ä¸»ä½“
    out = self.transformer(tokens, cache=cache)
```
---

7. æŠ•å½±åˆ°ç»Ÿä¸€è¯ç©ºé—´ï¼Œåº”ç”¨ logits mask ï¼Œé˜²æ­¢è·¨æ¨¡æ€é¢„æµ‹

```python
    # å¦‚æœå¯ç”¨äº†ç¨³å®šç­–ç•¥ï¼Œå¯¹è¾“å‡ºåšå½’ä¸€åŒ–
    if self.stable:
        out = self.norm_by_max(out)

    # å¾—åˆ°æ¯ä¸ªä½ç½®ä¸Šçš„åˆ†ç±» logitsï¼ˆé¢„æµ‹ tokenï¼‰
    logits = self.to_logits(out)

    # æ„é€  logits maskï¼šé™åˆ¶å“ªäº›ä½ç½®å¯ä»¥é¢„æµ‹å“ªäº› tokenï¼ˆé˜²æ­¢è·¨æ¨¡æ€é¢„æµ‹ï¼‰
    logits_mask = self.logits_mask[:, :seq_len]
    if exists(cache) and cache.get('offset'):
        logits_mask = logits_mask[:, -1:]
    max_neg_value = -torch.finfo(logits.dtype).max  # -inf æ›¿ä»£å€¼
    logits.masked_fill_(logits_mask, max_neg_value)  # ç”¨ -inf å±è”½ä¸åˆæ³•é¢„æµ‹
```
---

8. æ˜¯å¦æå‰ä¸­æ–­è¿”å› logits

```python
    # æ›´æ–° KV Cache çš„åç§»é‡ï¼ˆç”¨äºå¢é‡æ¨ç†ï¼‰
    if exists(cache):
        cache['offset'] = cache.get('offset', 0) + logits.shape[1]

    # å¦‚æœä¸è¦æ±‚è®¡ç®—æŸå¤±ï¼Œç›´æ¥è¿”å› logits
    if not return_loss:
        return logits
```

--- 

9. è®¡ç®—æ–‡æœ¬tokenå’Œè§†è§‰tokené¢„æµ‹ç»“æœä¸åŸLabelçš„äº¤å‰ç†µæŸå¤±

```python
    # è®­ç»ƒæ—¶å¿…é¡»æä¾›å›¾åƒï¼ˆå¦åˆ™æ— æ³•è®¡ç®—å›¾åƒ token çš„é¢„æµ‹æŸå¤±ï¼‰
    assert exists(image), 'when training, image must be supplied'

    # å°†å›¾åƒ token çš„ç´¢å¼•æ•´ä½“åŠ åç§»ï¼ˆè®©å›¾åƒ token ID ä¸æ–‡æœ¬ token ä¸é‡å ï¼‰
    offsetted_image = image + self.num_text_tokens

    # æ„é€ é¢„æµ‹æ ‡ç­¾ï¼šæ–‡æœ¬å»æ‰ <bos>ï¼ˆtext[:, 1:]ï¼‰ï¼Œæ¥ä¸Šå›¾åƒ token
    labels = torch.cat((text[:, 1:], offsetted_image), dim=1)

    # logits ç»´åº¦ä» [B, N, C] å˜æˆ [B, C, N]ï¼Œä»¥åŒ¹é… cross_entropy çš„è¾“å…¥æ ¼å¼
    logits = rearrange(logits, 'b n c -> b c n')

    # è®¡ç®—æ–‡æœ¬éƒ¨åˆ†çš„ cross-entropy lossï¼ˆå‰ self.text_seq_len ä¸ª tokenï¼‰
    loss_text = F.cross_entropy(logits[:, :, :self.text_seq_len], labels[:, :self.text_seq_len])

    # è®¡ç®—å›¾åƒéƒ¨åˆ†çš„ cross-entropy loss
    loss_img = F.cross_entropy(logits[:, :, self.text_seq_len:], labels[:, self.text_seq_len:])

    # æŒ‰ç…§æƒé‡åŠ æƒèåˆ lossï¼ˆå›¾åƒæŸå¤±é€šå¸¸å æ›´å¤§æ¯”ä¾‹ï¼‰
    loss = (loss_text + self.loss_img_weight * loss_img) / (self.loss_img_weight + 1)

    return loss
```

![](DALL-E/12.png)

åœ¨ DALLÂ·E çš„è®­ç»ƒä¸­ï¼Œæ–‡æœ¬ token å’Œå›¾åƒ token çš„æ•°é‡å·®åˆ«å¾ˆå¤§ï¼ˆé€šå¸¸å›¾åƒ token è¿œå¤šäºæ–‡æœ¬ tokenï¼‰ï¼Œå¦‚æœç›´æ¥æŠŠå®ƒä»¬çš„äº¤å‰ç†µæŸå¤±ç®€å•ç›¸åŠ ï¼Œå›¾åƒéƒ¨åˆ†çš„ loss ä¼šâ€œæ·¹æ²¡â€æ–‡æœ¬éƒ¨åˆ†ï¼Œå¯¼è‡´æ¨¡å‹è¿‡åº¦å…³æ³¨å›¾åƒè€Œå¿½è§†æ–‡æœ¬ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªä¸å¹³è¡¡é—®é¢˜ï¼ŒDALLÂ·E åœ¨åˆå¹¶ä¸¤éƒ¨åˆ†æŸå¤±æ—¶å¼•å…¥äº†ä¸€ä¸ª **å›¾åƒæŸå¤±æƒé‡** `self.loss_img_weight`ï¼ˆé€šå¸¸è®¾ç½®ä¸º 7ï¼‰ï¼Œå…·ä½“åšæ³•å¦‚ä¸‹ï¼š

```python
loss = (loss_text + self.loss_img_weight * loss_img) / (self.loss_img_weight + 1)
```

* `loss_text`ï¼šæ–‡æœ¬éƒ¨åˆ†çš„å¹³å‡äº¤å‰ç†µæŸå¤±

* `loss_img` ï¼šå›¾åƒéƒ¨åˆ†çš„å¹³å‡äº¤å‰ç†µæŸå¤±

* `self.loss_img_weight`ï¼šå›¾åƒæŸå¤±åœ¨æ€»æŸå¤±ä¸­çš„ç›¸å¯¹é‡è¦æ€§ç³»æ•°ï¼ˆ>1 æ—¶æ”¾å¤§å›¾åƒ lossï¼‰

å½“ `loss_img_weight = 7` æ—¶ï¼Œå…¬å¼ç›¸å½“äºï¼š

$$
\text{loss} = \frac{1 \times \text{loss\_text} + 7 \times \text{loss\_img}}{7 + 1}
$$

ä¹Ÿå°±æ˜¯æŠŠæ–‡æœ¬æŸå¤±å’Œå›¾åƒæŸå¤±å½“ä½œ 1:7 çš„æ¯”ä¾‹æ¥èåˆã€‚é™¤ä»¥ `(self.loss_img_weight + 1)` å¯ä»¥ **ä¿æŒæ€»æŸå¤±çš„æ•°å€¼ scale** å¤§è‡´ä¸å•ä¸€éƒ¨åˆ†æŸå¤±ç›¸åŒï¼Œå¦åˆ™ä¼šç›´æ¥æŠŠ loss æ”¾å¤§ 8 å€ï¼Œä¸åˆ©äºå­¦ä¹ ç‡ç­‰è¶…å‚æ•°è®¾ç½®ã€‚ä¾‹å¦‚ï¼š

* è‹¥ä¸é™¤ä»¥ï¼Œåˆå¹¶å loss è§„æ¨¡ â‰ˆ $\text{loss\_text} + 7 \times \text{loss\_img}$

* é™¤ä»¥å loss è§„æ¨¡ â‰ˆ $\frac{1}{8}\text{loss\_text} + \frac{7}{8}\text{loss\_img}$ï¼Œæ•´ä½“ä»åœ¨åˆç†åŒºé—´

> **é€šè¿‡ç»™å›¾åƒæŸå¤±è®¾ç½®æ›´é«˜çš„æƒé‡ï¼Œå¹³è¡¡æ–‡æœ¬å’Œå›¾åƒä¸¤éƒ¨åˆ†çš„è®­ç»ƒç›®æ ‡ï¼ŒåŒæ—¶ä¿æŒæ€»æŸå¤±æ•°å€¼ç¨³å®šã€‚**

### Classifier-Free Guidanceï¼ˆæ— æ¡ä»¶å¼•å¯¼æŠ€æœ¯ï¼‰

Classifier-Free Guidanceï¼ˆCFGï¼‰æœ¬è´¨ä¸Šæ˜¯ä¸€ç§â€œåœ¨åŒä¸€ä¸ªæ¨¡å‹å†…éƒ¨åšæœ‰æ¡ä»¶ä¸æ— æ¡ä»¶ä¸¤ç§é¢„æµ‹ï¼Œç„¶åæŒ‰æ¯”ä¾‹æ··åˆâ€ä»¥å¼ºåŒ–æ¡ä»¶ä¿¡å·çš„æ–¹æ³•ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼š

1. **æ— æ¡ä»¶é¢„æµ‹**

   ä»¤æ¨¡å‹å¿½ç•¥è¾“å…¥çš„æ¡ä»¶ï¼ˆä¾‹å¦‚å°† `null_cond_prob=1.0`ï¼‰ï¼Œåªé è‡ªèº«å­¦åˆ°çš„â€œå›¾åƒå…ˆéªŒâ€å»é¢„æµ‹ä¸‹ä¸€ä¸ª tokenï¼åƒç´ ã€‚è¾“å‡ºæˆ‘ä»¬è®°ä½œ

   $$
     \text{logits}_{\text{uncond}}.
   $$

2. **æœ‰æ¡ä»¶é¢„æµ‹**

   å†æ¬¡ç”¨åŸå§‹çš„æ¡ä»¶ï¼ˆå¦‚æ–‡æœ¬æè¿°ï¼‰å»é¢„æµ‹ï¼Œå¾—åˆ°

   $$
     \text{logits}_{\text{cond}}.
   $$

3. **çº¿æ€§æ··åˆå¼ºåŒ–**

   å°†ä¸¤è€…æŒ‰ä¸‹å¼æ··åˆï¼š

   $$
     \text{logits}_{\text{guided}}
     = \text{logits}_{\text{uncond}}
       + s\;\bigl(\text{logits}_{\text{cond}} - \text{logits}_{\text{uncond}}\bigr)
   $$

   å…¶ä¸­ $s$ï¼ˆ`cond_scale`ï¼‰æ˜¯ä¸€ä¸ªå¤§äº 1 çš„æ”¾å¤§ç³»æ•°ã€‚è¿™æ ·åšçš„æ„ä¹‰åœ¨äºï¼š

   * $\text{logits}_{\text{cond}} - \text{logits}_{\text{uncond}}$ æ­£å¥½æ•æ‰äº†â€œæ¡ä»¶å¯¹è¾“å‡ºçš„é¢å¤–å½±å“â€ï¼Œ
   
   * æ”¾å¤§è¿™ä¸ªå·®å€¼å°±èƒ½è®©æ¨¡å‹æ›´â€œå¬è¯â€åœ°è·Ÿéšæ¡ä»¶ï¼ˆä¾‹å¦‚æ›´å‡†ç¡®åœ°æŒ‰ç…§æç¤ºæ–‡æœ¬ç”Ÿæˆå›¾åƒï¼‰ï¼Œ
   
   * è€ŒåŸºç¡€çš„â€œæ— æ¡ä»¶â€éƒ¨åˆ†ä¿è¯äº†ç”Ÿæˆçš„å¤šæ ·æ€§ä¸æ ·æœ¬è´¨é‡ã€‚

ä¸ºä»€ä¹ˆå®ƒèƒ½å·¥ä½œï¼Ÿ

* **å•æ¨¡å‹å®ç°**ï¼šä¸éœ€è¦é¢å¤–è®­ç»ƒä¸€ä¸ªå¯¹æ¯”åˆ¤åˆ«å™¨æˆ–è¾…åŠ©ç½‘ç»œï¼Œåªåˆ©ç”¨æ¨¡å‹è‡ªèº«â€œæœ‰æ¡ä»¶/æ— æ¡ä»¶â€ä¸¤ç§æ¨¡å¼ã€‚

* **ç¨³å®šå¹³è¡¡**ï¼š$s=1$ æ—¶é€€åŒ–ä¸ºæ™®é€šæœ‰æ¡ä»¶ç”Ÿæˆï¼›$s>1$ æ—¶å¢å¼ºæ¡ä»¶å½±å“ï¼›å¦‚æœæ¡ä»¶æœ¬èº«æ¨¡ç³Šï¼Œè¿‡å¤§ $s$ ä¼šä¸§å¤±å¤šæ ·æ€§ã€‚

* **å®é™…æ•ˆæœ**ï¼šåœ¨å›¾åƒæˆ–åºåˆ—ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒCFG èƒ½æ˜¾è‘—æå‡æ¡ä»¶ç›¸å…³æ€§ï¼ˆå¦‚æ–‡æœ¬ä¸ç”Ÿæˆå›¾åƒçš„ç´§å¯†å¥‘åˆåº¦ï¼‰ï¼ŒåŒæ—¶ä¿ç•™ä¸€å®šçš„éšæœºæ€§å’Œè‡ªç„¶åº¦ã€‚

è¿™ç§æŠ€æœ¯è¢«å¹¿æ³›åº”ç”¨äºæ‰©æ•£æ¨¡å‹ã€Transformer-based è‡ªå›å½’æ¨¡å‹ï¼ˆå¦‚ DALLÂ·Eï¼‰ç­‰æ¡ä»¶ç”Ÿæˆåœºæ™¯ï¼Œæ˜¯å½“å‰æœ€ç®€å•ã€æœ€é«˜æ•ˆçš„â€œæ— åˆ¤åˆ«å™¨â€å¼•å¯¼æ–¹æ³•ã€‚

å…·ä½“ä»£ç å®ç°è¿‡ç¨‹å¦‚ä¸‹:

```python
    def forward_with_cond_scale(self, *args, cond_scale = 1, cache = None, **kwargs):
        if cond_scale == 1:
            return self(*args, **kwargs)

        prev_cache = cache.copy() if exists(cache) else None
        logits = self(*args, cache = cache, **kwargs)

        # discovery by Katherine Crowson
        # https://twitter.com/RiversHaveWings/status/1478093658716966912
        null_cond_logits = self(*args, null_cond_prob = 1., cache = prev_cache, **kwargs)
        return null_cond_logits + (logits - null_cond_logits) * cond_scale
```

### æ¨ç†è¿‡ç¨‹: å›¾æ–‡è”åˆç”Ÿæˆå›¾åƒ

DALL-E çš„æ¨ç†è¿‡ç¨‹å®é™…æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œä¸ä»…å¯ä»¥ä¼ å…¥æ–‡æœ¬æ¡ä»¶ï¼Œè¿˜å¯ä»¥ä¼ å…¥åˆå§‹å›¾åƒæ¡ä»¶ï¼Œä»è€Œå®ç°å›¾æ–‡è”åˆç”Ÿæˆ (text + image condition) , å…·ä½“ä»£ç å®ç°å¦‚ä¸‹:

```python
@torch.no_grad()  # ä¸è®¡ç®—æ¢¯åº¦ï¼Œç”¨äºæ¨ç†æ¨¡å¼ï¼ŒèŠ‚çœæ˜¾å­˜
@eval_decorator  # å°†æ¨¡å‹åˆ‡æ¢åˆ° eval æ¨¡å¼ï¼ˆå¦‚å…³é—­ dropoutã€norm ç»Ÿè®¡å†»ç»“ç­‰ï¼‰ï¼Œç¡®ä¿ä¸€è‡´æ€§
def generate_images(
    self,
    text,                      # è¾“å…¥çš„æ–‡æœ¬ token åºåˆ—ï¼ˆå·²ç» embed å¥½çš„ token idï¼‰
    *,
    clip = None,               # å¯é€‰ï¼šç”¨äºå¯¹ç”Ÿæˆå›¾åƒè¿›è¡Œ CLIP æ‰“åˆ†çš„æ¨¡å‹
    filter_thres = 0.5,        # Top-k é‡‡æ ·æ—¶çš„é˜ˆå€¼ï¼Œæ§åˆ¶ç”Ÿæˆ token çš„å¤šæ ·æ€§
    temperature = 1.,          # Gumbel softmax çš„æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶é‡‡æ ·éšæœºæ€§
    img = None,                # å¯é€‰ï¼šç”¨äº image priming çš„èµ·å§‹å›¾åƒ
    num_init_img_tokens = None,# ç”¨äº priming çš„èµ·å§‹ image token æ•°é‡
    cond_scale = 1.,           # CFG å¼ºåŒ–ç³»æ•°ï¼ˆ1 è¡¨ç¤ºä¸å¼ºåŒ–ï¼‰
    use_cache = False,         # æ˜¯å¦å¯ç”¨ KV ç¼“å­˜åŠ é€Ÿ
):
    # ä¸€äº›å¸¸ç”¨å˜é‡çš„å¼•ç”¨
    vae, text_seq_len, image_seq_len, num_text_tokens = (
        self.vae, self.text_seq_len, self.image_seq_len, self.num_text_tokens
    )
    total_len = text_seq_len + image_seq_len  # æ•´ä¸ªåºåˆ—çš„æ€»é•¿åº¦

    text = text[:, :text_seq_len]  # é™åˆ¶è¾“å…¥æ–‡æœ¬é•¿åº¦ä¸è¶…è¿‡æœ€å¤§ text_seq_len
    out = text                     # åˆå§‹åŒ–è¾“å‡º token åºåˆ—

    # --------------------------
    # Optional: å›¾åƒ priming
    # --------------------------
    if exists(img):
        image_size = vae.image_size
        assert img.shape[1:] == (3, image_size, image_size), \
            f'input image must have the correct image size {image_size}'

        # ç¼–ç å›¾åƒä¸º VQ token åºåˆ—
        indices = vae.get_codebook_indices(img)

        # é»˜è®¤é‡‡æ ·å‰ 14 Ã— 32 = 448 ä¸ªå›¾åƒ tokenï¼ˆçº¦å  43.75%ï¼‰
        num_img_tokens = default(num_init_img_tokens, int(0.4375 * image_seq_len))
        assert num_img_tokens < image_seq_len, 'priming token æ•°ä¸èƒ½è¶…è¿‡å›¾åƒ token æ€»é•¿åº¦'

        # ä»…ä½¿ç”¨å‰ num_img_tokens ä¸ª image token æ¥è¿›è¡Œæ¡ä»¶ priming
        indices = indices[:, :num_img_tokens]

        # å°†è¿™äº›å›¾åƒ token æ‹¼æ¥åˆ°æ–‡æœ¬åé¢ä½œä¸ºèµ·å§‹åºåˆ—
        out = torch.cat((out, indices), dim = -1)
```
`Image Priming for Conditional Image Generation` ä¹Ÿå¯ä»¥ç†è§£ä¸ºæ˜¯ä¸€ç§ `å›¾åƒå¼•å¯¼ç”Ÿæˆï¼ˆImage Conditioningï¼‰`ï¼Œå°±åƒ `æ–‡æœ¬ prompt` ä¸€æ ·å¼•å¯¼ç”Ÿæˆå†…å®¹ï¼Œåªä¸è¿‡å®ƒæ˜¯ `å›¾åƒ prompt` ã€‚

å¹¶ä¸”æˆ‘ä»¬åªæ‹¼æ¥ä¸€éƒ¨åˆ†ï¼ˆå¦‚å‰ 14Ã—32 ä¸ª token â‰ˆ å·¦ä¸Šè§’åŒºåŸŸï¼‰ï¼šç»™å‡ºä¸€å®šå›¾åƒå¼•å¯¼ï¼Œè®©æ¨¡å‹çŸ¥é“ã€Œé£æ ¼/ç»“æ„/é¢œè‰²ã€ï¼Œä½†ç•™å‡ºç©ºé—´ç»§ç»­ç”Ÿæˆå›¾åƒåç»­å†…å®¹ã€‚

| æ¨¡å¼         | æ¡ä»¶è¾“å…¥                          | æ•ˆæœ              |
| ---------- | ----------------------------- | --------------- |
| **æ–‡æœ¬ç”Ÿæˆå›¾åƒ** | ä»…æ–‡æœ¬ token                     | ä»é›¶ç”Ÿæˆå®Œæ•´å›¾åƒ        |
| **å›¾åƒè¡¥å…¨**   | æ–‡æœ¬ token + éƒ¨åˆ†å›¾åƒ tokenï¼ˆæ¥è‡ªçœŸå®å›¾åƒï¼‰ | åœ¨å·²æœ‰å›¾åƒåŸºç¡€ä¸Šè¡¥å…¨æœªæä¾›åŒºåŸŸ |

```python
    # --------------------------
    # ç”Ÿæˆ token åºåˆ—ï¼ˆä»èµ·å§‹é•¿åº¦åˆ° total_lenï¼‰
    # --------------------------
    prev_cache = None
    cache = {} if use_cache else None  # KV ç¼“å­˜æœºåˆ¶ï¼ˆå¯åŠ é€Ÿ transformer æ¨ç†ï¼‰

    for cur_len in range(out.shape[1], total_len):
        is_image = cur_len >= text_seq_len  # å½“å‰ token å±äºå›¾åƒéƒ¨åˆ†

        # æ¯ä¸€æ­¥æ„é€  text / image token åºåˆ—ï¼ˆæ³¨æ„æœ‰ paddingï¼‰
        text, image = out[:, :text_seq_len], out[:, text_seq_len:]

        # ä½¿ç”¨ CFG æŠ€æœ¯è¿›è¡Œæ¡ä»¶å¼•å¯¼é¢„æµ‹ logits
        logits = self.forward_with_cond_scale(text, image, cond_scale=cond_scale, cache=cache)

        # å–å½“å‰æ—¶é—´æ­¥ï¼ˆåªå…³å¿ƒæœ€åä¸€ä¸ª token çš„ logitsï¼‰
        logits = logits[:, -1, :]

        # top-k é‡‡æ ·ï¼ˆè¿‡æ»¤æ‰æ¦‚ç‡ä½çš„ tokenï¼‰
        filtered_logits = top_k(logits, thres=filter_thres)

        # ä½¿ç”¨ gumbel softmax è¿›è¡Œéšæœºé‡‡æ ·ï¼Œå¾—åˆ°ä¸€ä¸ª token id
        sample = gumbel_sample(filtered_logits, temperature=temperature, dim=-1)

        # å¦‚æœæ˜¯ image tokenï¼Œéœ€è¦å‡å»åç§»ï¼ˆå› ä¸º logit ç©ºé—´ = [text_vocab, image_vocab]ï¼‰
        sample -= (num_text_tokens if is_image else 0)

        # æ‹¼æ¥æ–°ç”Ÿæˆçš„ token
        out = torch.cat((out, sample[:, None]), dim=-1)

    # æ‹†åˆ†è¾“å‡ºåºåˆ—
    text_seq = out[:, :text_seq_len]               # æœ€ç»ˆæ–‡æœ¬ token åºåˆ—
    img_seq = out[:, -image_seq_len:]              # æœ€ç»ˆå›¾åƒ token åºåˆ—ï¼ˆå image_seq_len ä¸ªï¼‰

    # è§£ç å›¾åƒ token ä¸ºå®é™…å›¾ç‰‡
    images = vae.decode(img_seq)

    # è‹¥æä¾›äº† CLIPï¼Œåˆ™ä½¿ç”¨å…¶æ‰“åˆ†
    if exists(clip):
        scores = clip(text_seq, images, return_loss=False)
        return images, scores

    return images
```
#### Top-K é‡‡æ ·

Top-K é‡‡æ ·æ˜¯ä¸€ç§å¸¸ç”¨çš„ç”Ÿæˆæ¨¡å‹é‡‡æ ·æ–¹æ³•ï¼Œç”¨äºä»æ¨¡å‹è¾“å‡ºçš„ logits ä¸­é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ K ä¸ª token ä½œä¸ºä¸‹ä¸€ä¸ª tokenã€‚

```python
def top_k(logits, thres=0.5):
    # è·å–æœ€åä¸€ç»´çš„å¤§å°ï¼Œå³ token çš„æ•°é‡
    num_logits = logits.shape[-1]

    # æ ¹æ®é˜ˆå€¼è®¡ç®— top-k çš„ k å€¼ï¼Œç¡®ä¿è‡³å°‘é€‰ä¸€ä¸ª
    # ä¾‹å¦‚ thres=0.5 è¡¨ç¤ºä¿ç•™ top 50% çš„ logits
    k = max(int((1 - thres) * num_logits), 1)

    # ä» logits ä¸­è·å– top-k çš„å€¼ val åŠå…¶å¯¹åº”çš„ç´¢å¼• ind
    val, ind = torch.topk(logits, k)

    # æ„é€ ä¸€ä¸ªä¸ logits ç›¸åŒå½¢çŠ¶çš„ tensorï¼Œåˆå§‹å€¼ä¸º -infï¼ˆè´Ÿæ— ç©·ï¼‰
    # ç”¨äºå±è”½é top-k çš„ logits
    probs = torch.full_like(logits, float('-inf'))

    # å°† top-k çš„å€¼ scatter åˆ°å¯¹åº”çš„ä½ç½®ï¼ˆå…¶ä½™ä½ç½®ä»ä¸º -infï¼‰
    probs.scatter_(1, ind, val)

    # è¿”å›ç»è¿‡ç­›é€‰åçš„ logitsï¼Œé top-k çš„ä½ç½®ä¸º -inf
    return probs
```
![](DALL-E/13.png)

#### Gumbel Sampling

`Gumbel Samplingï¼ˆGumbel-Max é‡‡æ ·ï¼‰`ï¼Œå®ƒæ˜¯ä¸€ä¸ªå¸¸ç”¨äºç¦»æ•£åˆ†å¸ƒä¸­é‡‡æ ·çš„æŠ€å·§ï¼Œå°¤å…¶é€‚ç”¨äºç”Ÿæˆæ¨¡å‹ä¸­ä» logits ä¸­ä»¥æ¦‚ç‡æ–¹å¼é‡‡æ ·ä¸€ä¸ª tokenï¼Œé¿å…ç›´æ¥ç”¨ softmax â†’ multinomialã€‚

$$
\text{sample} = \arg\max_i \left( \log p_i + G_i \right)
$$

å…¶ä¸­ $G_i \sim \text{Gumbel}(0, 1)$ï¼Œè¿™æ˜¯ä¸€ä¸ªä» Gumbel åˆ†å¸ƒé‡‡æ ·çš„å™ªå£°ã€‚



```python
def gumbel_sample(t, temperature=1., dim=-1):
    # å°† logits t é™¤ä»¥æ¸©åº¦ temperatureï¼ˆæ§åˆ¶éšæœºæ€§ï¼‰ï¼ŒåŠ ä¸Š Gumbel å™ªå£°åå– argmax é‡‡æ ·
    return ((t / temperature) + gumbel_noise(t)).argmax(dim=dim)
```


åœ¨ä»£ç ä¸­ï¼š

* `t` æ˜¯ logitsï¼Œå³æ¨¡å‹è¾“å‡ºçš„æ¯ä¸ª token çš„æ‰“åˆ†ï¼›

* `gumbel_noise(t)` ä¸ºæ¯ä¸ªä½ç½®ç”Ÿæˆ Gumbel(0,1) å™ªå£°ï¼›

* `(t / temperature)` æ˜¯ç”¨æ¸©åº¦æ§åˆ¶ logits çš„â€œå¹³æ»‘ç¨‹åº¦â€ï¼›

* `argmax(dim=dim)` å°±æ˜¯ä»åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ª tokenã€‚

* `temperature` æ§åˆ¶é‡‡æ ·çš„éšæœºç¨‹åº¦ï¼š

  * è¶‹è¿‘ 0 â†’ è¶‹è¿‘è´ªå¿ƒé‡‡æ ·ï¼ˆæœ€å¤§å€¼ï¼‰ï¼›

  * è¶‹è¿‘ âˆ â†’ æ›´åŠ éšæœºï¼Œå¹³æ»‘é‡‡æ ·ã€‚

* `gumbel_noise` çš„åŠ å…¥ä½¿å¾—é‡‡æ ·å˜ä¸ºâ€œæœ‰å™ªå£°çš„ argmaxâ€ï¼Œè€Œä¸æ˜¯ç®€å•åœ°é€‰æœ€å¤§å€¼ã€‚

### â€œè¯­è¨€å»ºæ¨¡èƒ½åŠ›â€çš„å›æº¯æ€§éªŒè¯

`DALLÂ·E` æ˜¯ä¸€ä¸ª `æ–‡æœ¬-å›¾åƒè”åˆå»ºæ¨¡ï¼ˆjoint modelingï¼‰` çš„ Transformerï¼š

1. å®ƒçš„è¾“å…¥æ˜¯ `text_tokens + image_tokens` æ‹¼æ¥è€Œæˆçš„åºåˆ—ï¼›

2. è¾“å‡ºæ˜¯å¯¹æ•´ä¸ªåºåˆ—çš„é¢„æµ‹ï¼ˆè‡ªå›å½’å»ºæ¨¡ï¼‰ï¼›

3. æ¨¡å‹å¤´éƒ¨è¾“å‡º logitsï¼Œæ—¢å¯ç”¨äºé¢„æµ‹æ–‡æœ¬ tokenï¼Œä¹Ÿå¯ç”¨äºé¢„æµ‹å›¾åƒ tokenã€‚

`generate_texts` æ–¹æ³•å°±æ˜¯åœ¨ `å¤ç”¨è¿™ä¸ªæ¨¡å‹çš„ text ç”Ÿæˆèƒ½åŠ›`ï¼Œå¯ä»¥è§†ä½œï¼š

ğŸ”¸ â€œæµ‹è¯• DALLÂ·E æ˜¯å¦çœŸæ­£å­¦ä¼šäº†è¯­è¨€å»ºæ¨¡éƒ¨åˆ†â€ï¼Œ

ğŸ”¸ â€œæ˜¯å¦ç†è§£ prompt çš„è¯­è¨€ç»“æ„â€ã€‚

```python
@torch.no_grad()  # è¡¨ç¤ºè¯¥å‡½æ•°ä¸­ä¸è¿›è¡Œæ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜ï¼Œæé«˜æ¨ç†æ•ˆç‡
@eval_decorator   # å°†æ¨¡å‹è®¾ç½®ä¸º evaluation æ¨¡å¼ï¼Œç¦ç”¨ dropout ç­‰è®­ç»ƒè¡Œä¸º
def generate_texts(
    self,
    tokenizer,               # åˆ†è¯å™¨å¯¹è±¡ï¼Œç”¨äºå°†è¾“å…¥æ–‡æœ¬ç¼–ç ä¸º token åºåˆ—
    text = None,             # è¾“å…¥æ–‡æœ¬ï¼ˆå¯ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
    *,
    filter_thres = 0.5,      # top-k é‡‡æ ·çš„é˜ˆå€¼ï¼Œæ§åˆ¶ä¿ç•™å¤šå°‘ logits å€¼
    temperature = 1.         # Gumbel Softmax çš„æ¸©åº¦ç³»æ•°ï¼Œè°ƒèŠ‚éšæœºæ€§
):
    text_seq_len = self.text_seq_len  # è®¾å®šæ–‡æœ¬åºåˆ—çš„æœ€å¤§é•¿åº¦ï¼ˆå›ºå®šï¼‰

    # å¦‚æœæ²¡æœ‰è¾“å…¥æ–‡æœ¬ï¼Œé»˜è®¤ä» token_id ä¸º 0 çš„ token å¼€å§‹ï¼ˆå¦‚ [BOS]ï¼‰
    if text is None or text == "":
        text_tokens = torch.tensor([[0]]).cuda()
    else:
        # ç¼–ç è¾“å…¥æ–‡æœ¬ä¸º token åºåˆ—ï¼Œå¹¶æ·»åŠ  batch ç»´åº¦
        text_tokens = torch.tensor(tokenizer.tokenizer.encode(text)).cuda().unsqueeze(0)

    # è‡ªå›å½’ç”Ÿæˆï¼Œé€ token é‡‡æ ·ç›´åˆ°è¾¾åˆ°ç›®æ ‡é•¿åº¦
    for _ in range(text_tokens.shape[1], text_seq_len):
        device = text_tokens.device

        # è·å– token çš„åµŒå…¥å‘é‡
        tokens = self.text_emb(text_tokens)

        # æ·»åŠ ä½ç½®ç¼–ç ï¼ˆç›¸å¯¹æˆ–ç»å¯¹ï¼‰ï¼Œä¿æŒ token é¡ºåºæ„ŸçŸ¥
        tokens += self.text_pos_emb(torch.arange(text_tokens.shape[1], device=device))

        seq_len = tokens.shape[1]  # å½“å‰åºåˆ—é•¿åº¦

        # é€å…¥ Transformer æ¨¡å‹è·å–è¾“å‡ºï¼ˆæ¯ä¸ªä½ç½®çš„è¡¨å¾ï¼‰
        output_transf = self.transformer(tokens)

        # å¦‚æœå¼€å¯äº† stable æ¨¡å¼ï¼Œåˆ™å½’ä¸€åŒ–è¾“å‡ºï¼Œé¿å…æç«¯æ•°å€¼
        if self.stable:
            output_transf = self.norm_by_max(output_transf)

        # æ˜ å°„è‡³ logitsï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒï¼‰
        logits = self.to_logits(output_transf)

        # å±è”½éæ³•çš„é¢„æµ‹ä½ç½®ï¼š
        # ç¡®ä¿åœ¨ç”Ÿæˆæ–‡æœ¬çš„é˜¶æ®µï¼Œåªèƒ½é¢„æµ‹æ–‡æœ¬ tokenï¼Œè€Œä¸æ˜¯å›¾åƒ token
        logits_mask = self.logits_mask[:, :seq_len]
        max_neg_value = -torch.finfo(logits.dtype).max
        logits.masked_fill_(logits_mask, max_neg_value)

        # ä»…å–æœ€åä¸€ä¸ªä½ç½®çš„ logitsï¼ˆç”¨äºä¸‹ä¸€ä¸ª token çš„é‡‡æ ·ï¼‰
        logits = logits[:, -1, :]

        # top-k è¿‡æ»¤ï¼šä»…ä¿ç•™æœ€å¯èƒ½çš„ k ä¸ª logitsï¼Œå…¶ä½™è®¾ç½®ä¸º -inf
        filtered_logits = top_k(logits, thres=filter_thres)

        # ä½¿ç”¨ Gumbel Softmax æŠ€æœ¯ä»è¿‡æ»¤åçš„ logits ä¸­é‡‡æ ·ä¸€ä¸ª token
        sample = gumbel_sample(filtered_logits, temperature=temperature, dim=-1)

        # å°†é‡‡æ ·åˆ°çš„æ–° token æ‹¼æ¥åˆ°å·²æœ‰åºåˆ—å
        text_tokens = torch.cat((text_tokens, sample[:, None]), dim=-1)

    # æ„å»º padding token çš„é›†åˆï¼Œç”¨äºåç»­è§£ç æ—¶è·³è¿‡å¡«å…… token
    padding_tokens = set(np.arange(self.text_seq_len) + (self.num_text_tokens - self.text_seq_len))

    # å°† token åºåˆ—è§£ç ä¸ºå¯è¯»æ–‡æœ¬ï¼Œè‡ªåŠ¨å»æ‰ padding token
    texts = [tokenizer.tokenizer.decode(text_token, pad_tokens=padding_tokens) for text_token in text_tokens]

    # è¿”å› token åºåˆ—å’Œè§£ç åçš„æ–‡æœ¬
    return text_tokens, texts
```
### DiscreteVAE ç¦»æ•£åŒ–å˜åˆ†è‡ªç¼–ç å™¨

ä»æœ¬èŠ‚å¼€å§‹ï¼Œæˆ‘ä»¬å°†å¿«é€Ÿè¿‡ä¸€ä¸‹ `DiscreteVAE` ç¦»æ•£åŒ–å˜åˆ†è‡ªç¼–ç å™¨ å’Œ `CLIP` æ¨¡å‹çš„ä»£ç å®ç°ã€‚

> æœ¬èŠ‚å¼€å§‹ä¸ºæ‰©å±•é˜…è¯»å†…å®¹ï¼Œå·²æœ‰å‰ç½®çŸ¥è¯†çš„åŒå­¦ï¼Œå¯ä»¥é€‰æ‹©è·³è¿‡ã€‚

é¦–å…ˆæ¥çœ‹ä¸€ä¸‹ `DiscreteVAE` çš„åˆå§‹åŒ–æ–¹æ³•:

```python
class DiscreteVAE(nn.Module):
    def __init__(
        self,
        image_size = 256,                # è¾“å…¥å›¾åƒå°ºå¯¸ï¼ˆå®½é«˜ï¼‰ï¼Œè¦æ±‚æ˜¯ 2 çš„å¹‚
        num_tokens = 512,                # codebook ä¸­çš„ token æ•°é‡ï¼ˆç¦»æ•£è¡¨ç¤ºç©ºé—´çš„å¤§å°ï¼‰
        codebook_dim = 512,             # codebook ä¸­æ¯ä¸ªå‘é‡çš„ç»´åº¦
        num_layers = 3,                 # ç¼–ç å™¨ / è§£ç å™¨çš„å±‚æ•°ï¼ˆæ¯å±‚æ˜¯ä¸€æ¬¡ä¸‹é‡‡æ ·æˆ–ä¸Šé‡‡æ ·ï¼‰
        num_resnet_blocks = 0,         # æ®‹å·®å—çš„æ•°é‡ï¼ˆç”¨äºæå‡è¡¨è¾¾èƒ½åŠ›ï¼‰
        hidden_dim = 64,               # ç¼–ç å™¨ / è§£ç å™¨ä¸­å·ç§¯é€šé“çš„åŸºç¡€ç»´åº¦
        channels = 3,                  # å›¾åƒé€šé“æ•°ï¼ˆRGB = 3ï¼‰
        smooth_l1_loss = False,        # æ˜¯å¦ä½¿ç”¨ Smooth L1 æŸå¤±ï¼ˆå¦åˆ™ä½¿ç”¨ MSEï¼‰
        temperature = 0.9,             # Gumbel Softmax æ¸©åº¦ï¼Œæ§åˆ¶ç¦»æ•£é‡‡æ ·çš„å¹³æ»‘ç¨‹åº¦
        straight_through = False,     # æ˜¯å¦ä½¿ç”¨ straight-through estimatorï¼ˆç”¨äºåå‘ä¼ æ’­ç¦»æ•£ tokenï¼‰
        reinmax = False,              # æ˜¯å¦ä½¿ç”¨ Reinmaxï¼ˆä¸€ç§ç”¨äºç¦»æ•£å˜é‡çš„é‡‡æ ·æŠ€æœ¯ï¼‰
        kl_div_loss_weight = 0.,      # KL æ•£åº¦æŸå¤±çš„æƒé‡ï¼ˆé€šå¸¸ä¸º 0 æˆ–å¾ˆå°ï¼‰
        normalization = ((*((0.5,) * 3), 0), (*((0.5,) * 3), 1))  # å›¾åƒæ ‡å‡†åŒ–å‚æ•°
    ):
        super().__init__()
        assert log2(image_size).is_integer(), 'image size must be a power of 2'
        assert num_layers >= 1, 'number of layers must be greater than or equal to 1'
        has_resblocks = num_resnet_blocks > 0

        self.channels = channels
        self.image_size = image_size
        self.num_tokens = num_tokens
        self.num_layers = num_layers
        self.temperature = temperature
        self.straight_through = straight_through
        self.reinmax = reinmax

        # codebookï¼štoken_id åˆ°å‘é‡çš„æ˜ å°„ï¼Œå¤§å°ä¸º (num_tokens, codebook_dim)
        self.codebook = nn.Embedding(num_tokens, codebook_dim)

        hdim = hidden_dim

        # æ„é€ ç¼–ç å™¨ä¸è§£ç å™¨çš„é€šé“åˆ—è¡¨ï¼ˆæ¯å±‚çš„é€šé“æ•°ï¼‰
        enc_chans = [hidden_dim] * num_layers
        dec_chans = list(reversed(enc_chans))  # è§£ç å™¨é€šé“åè½¬

        enc_chans = [channels, *enc_chans]  # ç¼–ç å™¨è¾“å…¥é€šé“ä»å›¾åƒå¼€å§‹

        # å¦‚æœæœ‰æ®‹å·®å—ï¼Œè§£ç å™¨ç¬¬ä¸€å±‚è¾“å…¥é€šé“æ¥è‡ª ResBlock è¾“å‡º
        dec_init_chan = codebook_dim if not has_resblocks else dec_chans[0]
        dec_chans = [dec_init_chan, *dec_chans]

        # å½¢å¦‚ [(in1, out1), (in2, out2), ...]
        enc_chans_io, dec_chans_io = map(lambda t: list(zip(t[:-1], t[1:])), (enc_chans, dec_chans))

        enc_layers = []  # ç¼–ç å™¨ç½‘ç»œå±‚åˆ—è¡¨
        dec_layers = []  # è§£ç å™¨ç½‘ç»œå±‚åˆ—è¡¨

        # æ„å»ºç¼–ç å™¨å’Œè§£ç å™¨çš„æ¯ä¸€å±‚ï¼ˆå·ç§¯ / è½¬ç½®å·ç§¯ + ReLUï¼‰
        for (enc_in, enc_out), (dec_in, dec_out) in zip(enc_chans_io, dec_chans_io):
            enc_layers.append(
                nn.Sequential(nn.Conv2d(enc_in, enc_out, kernel_size=4, stride=2, padding=1), nn.ReLU())
            )
            dec_layers.append(
                nn.Sequential(nn.ConvTranspose2d(dec_in, dec_out, kernel_size=4, stride=2, padding=1), nn.ReLU())
            )

        # æ·»åŠ  ResBlockï¼ˆå¦‚æœæœ‰ï¼‰
        for _ in range(num_resnet_blocks):
            dec_layers.insert(0, ResBlock(dec_chans[1]))             # è§£ç å™¨æœ€å‰é¢æ’å…¥ ResBlock
            enc_layers.append(ResBlock(enc_chans[-1]))               # ç¼–ç å™¨æœ«å°¾è¿½åŠ  ResBlock

        # å¦‚æœä½¿ç”¨ ResBlockï¼Œè¿˜éœ€è¦é¢å¤–å°† codebook_dim æ˜ å°„åˆ° decoder é€šé“æ•°
        if num_resnet_blocks > 0:
            dec_layers.insert(0, nn.Conv2d(codebook_dim, dec_chans[1], kernel_size=1))

        # ç¼–ç å™¨æœ€ç»ˆè¾“å‡º token logitsï¼Œç»´åº¦æ˜¯ num_tokensï¼ˆæ³¨æ„ï¼šé softmaxï¼‰
        enc_layers.append(nn.Conv2d(enc_chans[-1], num_tokens, kernel_size=1))

        # è§£ç å™¨æœ€ç»ˆè¾“å‡ºå›¾åƒï¼Œç»´åº¦æ˜¯åŸå§‹å›¾åƒçš„é€šé“æ•°
        dec_layers.append(nn.Conv2d(dec_chans[-1], channels, kernel_size=1))

        # æ‰“åŒ…æˆ nn.Sequential æ¨¡å—
        self.encoder = nn.Sequential(*enc_layers)
        self.decoder = nn.Sequential(*dec_layers)

        # è®¾ç½®é‡å»ºæŸå¤±å‡½æ•°ï¼šMSE æˆ– Smooth L1
        self.loss_fn = F.smooth_l1_loss if smooth_l1_loss else F.mse_loss

        self.kl_div_loss_weight = kl_div_loss_weight  # KLæŸå¤±çš„æƒé‡ï¼ˆå¯ç”¨äº soft quantizationï¼‰

        # å›¾åƒæ ‡å‡†åŒ–ï¼ˆmean, stdï¼‰ï¼Œç”¨äºè¾“å…¥é¢„å¤„ç†
        self.normalization = tuple(map(lambda t: t[:channels], normalization))
```

ä¸‹é¢ç»™å‡º `DiscreteVAE` çš„ `forward` æ–¹æ³•ï¼š

```python
def forward(
    self,
    img,                      # è¾“å…¥å›¾åƒï¼Œå½¢çŠ¶ä¸º (B, C, H, W)
    return_loss = False,     # æ˜¯å¦è¿”å›æŸå¤±ï¼ˆè®­ç»ƒæ—¶è®¾ä¸º Trueï¼‰
    return_recons = False,   # æ˜¯å¦è¿”å›é‡å»ºå›¾åƒï¼ˆå¯ç”¨äºå¯è§†åŒ–å¯¹æ¯”ï¼‰
    return_logits = False,   # æ˜¯å¦è¿”å› token logitsï¼ˆDALLÂ·E è®­ç»ƒæ—¶æå– token ç”¨ï¼‰
    temp = None              # æ¸©åº¦å‚æ•°ï¼Œç”¨äº Gumbel-Softmaxï¼Œæ§åˆ¶é‡‡æ ·å¹³æ»‘ç¨‹åº¦
):
    device = img.device
    num_tokens = self.num_tokens
    image_size = self.image_size
    kl_div_loss_weight = self.kl_div_loss_weight

    # å›¾åƒå°ºå¯¸æ£€æŸ¥
    assert img.shape[-1] == image_size and img.shape[-2] == image_size, f'input must have the correct image size {image_size}'

    # å½’ä¸€åŒ–è¾“å…¥å›¾åƒï¼ˆå’Œè®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    img = self.norm(img)

    # ç¼–ç å™¨è¾“å‡º logitsï¼Œå½¢çŠ¶ä¸º (B, num_tokens, H/2^L, W/2^L)
    logits = self.encoder(img)

    # è‹¥ä»…éœ€è¦ token logitsï¼ˆæ¯”å¦‚è®­ç»ƒ DALLÂ·E æ—¶è·å–ç¦»æ•£ tokenï¼‰
    if return_logits:
        return logits

    # é‡‡æ ·æ¸©åº¦å‚æ•°ï¼šå¦‚æœæ²¡ä¼ å…¥ï¼Œå°±ç”¨é»˜è®¤çš„ self.temperature
    temp = default(temp, self.temperature)

    # Gumbel Softmax é‡‡æ ·ï¼šè¾“å‡º one-hot å‘é‡æˆ– soft one-hotï¼ˆå–å†³äº straight_throughï¼‰
    one_hot = F.gumbel_softmax(logits, tau = temp, dim = 1, hard = self.straight_through)

    # Reinmaxï¼ˆæ”¹è¿›çš„ straight-through Gumbel Softmaxï¼‰é€»è¾‘
    if self.straight_through and self.reinmax:
        # Reinmax æ¥è‡ª https://arxiv.org/abs/2304.08612ï¼Œå¢å¼ºé‡‡æ ·ç²¾åº¦
        # è®ºæ–‡ç®—æ³•2å®ç°

        one_hot = one_hot.detach()  # ä¸åå‘ä¼ æ’­æ¢¯åº¦

        Ï€0 = logits.softmax(dim = 1)  # åŸå§‹ softmax åˆ†å¸ƒ
        Ï€1 = (one_hot + (logits / temp).softmax(dim = 1)) / 2  # å¹³å‡åˆ†å¸ƒ
        Ï€1 = ((log(Ï€1) - logits).detach() + logits).softmax(dim = 1)  # åŠ å…¥æ¢¯åº¦ä¿®æ­£
        Ï€2 = 2 * Ï€1 - 0.5 * Ï€0  # Reinmax åˆ†å¸ƒ
        one_hot = Ï€2 - Ï€2.detach() + one_hot  # å°†æ¢¯åº¦ä¼ é€’ç»™ one_hot

    # å°† one-hot ä¸ codebook è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œè·å–åµŒå…¥å‘é‡å›¾ï¼ˆå›¾åƒ latent è¡¨ç¤ºï¼‰
    # einsum: b (token) h w, token d -> b d h w
    sampled = einsum('b n h w, n d -> b d h w', one_hot, self.codebook.weight)

    # è§£ç å™¨å°† latent è¡¨ç¤ºè¿˜åŸä¸ºå›¾åƒ
    out = self.decoder(sampled)

    # å¦‚æœä¸éœ€è¦è¿”å› lossï¼Œç›´æ¥è¿”å›è§£ç å›¾åƒ
    if not return_loss:
        return out

    # è®¡ç®—é‡å»ºæŸå¤±ï¼ˆMSE æˆ– Smooth L1ï¼‰
    recon_loss = self.loss_fn(img, out)

    # KL æ•£åº¦éƒ¨åˆ†ï¼ˆç”¨äºå°† token åˆ†å¸ƒé€¼è¿‘ uniformï¼‰
    # logits shape: (B, num_tokens, H, W) -> (B, HW, num_tokens)
    logits = rearrange(logits, 'b n h w -> b (h w) n')
    log_qy = F.log_softmax(logits, dim = -1)  # q(y|x)ï¼šé¢„æµ‹åˆ†å¸ƒ
    log_uniform = torch.log(torch.tensor([1. / num_tokens], device = device))  # p(y) ~ U
    kl_div = F.kl_div(log_uniform, log_qy, None, None, 'batchmean', log_target = True)

    # æ€»æŸå¤± = é‡å»ºæŸå¤± + KLæ•£åº¦æŸå¤±ï¼ˆå¯é€‰ï¼‰
    loss = recon_loss + (kl_div * kl_div_loss_weight)

    # å¦‚æœä¸éœ€è¦é‡å»ºå›¾åƒï¼Œç›´æ¥è¿”å› loss
    if not return_recons:
        return loss

    # å¦åˆ™è¿”å›æŸå¤± + è§£ç å›¾åƒ
    return loss, out
```
> å…³äºæœ¬éƒ¨åˆ†ä»£ç ç»†èŠ‚çš„è¯¦ç»†è§£é‡Šï¼Œå¯ä»¥å‚è€ƒä¹‹å‰è¿™ç¯‡æ–‡ç« : [BEiT æ¨¡å‹ä»£ç è§£è¯»](https://binaryoracle.github.io/other_direction/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/BEiT%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB.html)

DALL-E æ¨¡å‹ä½¿ç”¨çš„æ˜¯è®­ç»ƒå¥½çš„ `DiscreteVAE` , å…¶ä¸­æˆ‘ä»¬æœ€å¸¸ä½¿ç”¨ `get_codebook_indices` æ–¹æ³•è·å–è¾“å…¥å›¾åƒå¯¹åº”çš„ç¦»æ•£è§†è§‰ token ç´¢å¼•ã€‚

```python
@torch.no_grad()  # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆæ¨ç†æ¨¡å¼ï¼Œæé«˜æ•ˆç‡ï¼ŒèŠ‚çœæ˜¾å­˜ï¼‰
@eval_decorator    # å°†æ¨¡å‹æš‚æ—¶è®¾ä¸º eval æ¨¡å¼ï¼ˆå…³é—­ Dropoutã€BatchNorm çš„åŠ¨æ•ˆï¼‰
def get_codebook_indices(self, images):
    # ç¼–ç å™¨ + projectionï¼Œå¾—åˆ°æ¯ä¸ªä½ç½®å¯¹åº”çš„ logitsï¼ˆæœª softmaxï¼‰
    # logits å½¢çŠ¶: (B, num_tokens, H', W')ï¼ŒH'=W'=åŸå›¾å°ºå¯¸ / 2^L
    logits = self(images, return_logits = True)

    # å–æœ€å¤§æ¦‚ç‡çš„ token ç´¢å¼•ï¼šåœ¨ dim=1ï¼ˆtoken ç±»åˆ«ç»´ï¼‰ä¸Š argmax
    # å¾—åˆ°å½¢çŠ¶: (B, H', W')ï¼Œå³æ¯ä¸ªå›¾åƒä¸­æ¯ä¸ª patch çš„ token ç´¢å¼•
    codebook_indices = logits.argmax(dim = 1).flatten(1)  
    # flatten(1): å°† (B, H', W') å±•å¹³ä¸º (B, H'*W')ï¼Œæ–¹ä¾¿åç»­å¤„ç†

    return codebook_indices
```

å…¶æ¬¡æˆ‘ä»¬ä¼šè°ƒç”¨ `decode` æ–¹æ³•å®ç°ä»ç¦»æ•£è§†è§‰Tokenç´¢å¼•åˆ°å›¾åƒçš„é‡å»ºè¿‡ç¨‹:

```python
def decode(
    self,
    img_seq  # è¾“å…¥å›¾åƒçš„ç¦»æ•£ token åºåˆ—ï¼Œå½¢çŠ¶ï¼š(B, N)
):
    # é€šè¿‡ codebook æŸ¥è¡¨ï¼ŒæŠŠæ¯ä¸ª token è½¬æ¢ä¸ºå‘é‡ï¼ˆembeddingï¼‰
    # image_embeds å½¢çŠ¶: (B, N, D)
    image_embeds = self.codebook(img_seq)

    # è·å–ç»´åº¦ä¿¡æ¯ï¼šB æ‰¹æ¬¡å¤§å°ï¼ŒN token ä¸ªæ•°ï¼ŒD embedding ç»´åº¦
    b, n, d = image_embeds.shape

    # å‡è®¾å›¾åƒæ˜¯æ­£æ–¹å½¢çš„ï¼ŒN = H' Ã— W'ï¼Œè®¡ç®—è¾¹é•¿
    h = w = int(sqrt(n))

    # é‡æ–°æ’åˆ—ï¼šä» (B, N, D) è½¬æ¢ä¸º (B, D, H', W')ï¼Œç”¨äº ConvTranspose è§£ç 
    image_embeds = rearrange(image_embeds, 'b (h w) d -> b d h w', h = h, w = w)

    # è§£ç è¿˜åŸå›¾åƒï¼šä½¿ç”¨ Decoderï¼ˆè½¬ç½®å·ç§¯ç­‰ï¼‰
    # è¾“å‡ºå›¾åƒå½¢çŠ¶: (B, C, H, W)
    images = self.decoder(image_embeds)

    return images
```

