---
title: Tutorial on Variational Autoencoders 论文
icon: file
category:
  - 生成模型
tag:
  - 生成模型
  - 编辑中
footer: 技术共建，知识共享
date: 2025-07-27
author:
  - BinaryOracle
---

`Tutorial on Variational Autoencoders 论文` 

<!-- more -->

> 论文链接: [Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908)

## 引言

生成建模是机器学习中的一个重要领域，目标是建立对数据点 $X$ 所在的高维空间 $\mathcal{X}$ 上分布 $P(X)$ 的模型。以图像为例，每张图像包含成千上万个像素，这些像素之间存在复杂的依赖关系，比如相邻像素颜色相似且共同构成物体。生成模型的任务就是捕捉这些像素间的依赖。

模型的具体含义取决于我们想用它完成什么。最基础的生成模型能够数值计算 $P(X)$，让看起来真实的图像具有较高概率，而随机噪声的图像概率较低。然而，这样的模型不一定实用，因为知道某个图像不太可能出现，并不能帮助我们生成新的、真实的图像。

实际应用中，人们更关心的是能否基于已有数据库，生成更多类似但不完全相同的新样本。比如：

* 从图像数据库合成新的未见图像；

* 从三维植物模型生成更多植被以填充游戏场景；

* 从手写文本生成更多手写内容。

这些生成工具对设计师等用户非常有用。


我们假设数据来自一个未知的真实分布 $P_{\text{gt}}(X)$，目标是学习一个生成模型 $P$，使得从 $P$ 中采样的样本尽量和真实分布相似。

训练这类模型长期以来面临三大难题：

* 需要对数据结构做强假设；

* 进行严重近似，导致模型性能不佳；

* 依赖计算量大、效率低的推断方法，如马尔可夫链蒙特卡洛（MCMC）。

近年来，借助反向传播训练神经网络这一强大函数逼近器的突破，出现了基于神经网络的生成模型框架。其中变分自编码器（VAE）是一种非常流行的方法，具有如下优点：

* 假设较弱，不强制对数据结构做过多限制；

* 训练速度快，可通过反向传播高效优化；

* 引入近似但误差较小，尤其是在高容量模型下。

这些特点使得 VAE 快速流行，成为研究和应用的热门工具。

> 论文面向对生成模型感兴趣但不熟悉变分贝叶斯方法的读者，主要偏重计算机视觉领域。教程起源于加州大学伯克利分校和卡内基梅隆大学的读书分享。

### 预备知识: 潜变量模型

生成模型训练时，维度间的复杂依赖会增加难度。以生成手写数字图像为例，模型若先随机选择一个数字 $z$（潜变量），再生成对应像素，比直接逐像素生成效果更好。潜变量 $z$ 是指生成过程中的隐藏决策，虽然我们只能看到最终生成的字符，但不知道具体哪个潜变量设置产生了它。

为了让模型能生成接近训练数据的样本，必须确保对数据集中的每个样本 $X$，存在一个或多个潜变量设置 $z$，使得模型能生成与 $X$ 相似的结果。数学上，假设潜变量 $z$ 服从概率密度 $P(z)$，通过一个确定性函数族 $f(z; \theta)$ 生成样本。优化目标是调整参数 $\theta$，使得从 $P(z)$ 采样后生成的样本 $f(z; \theta)$ 高概率地类似训练集中的数据。

用概率分布形式表达即为最大化

$$
P(X) = \int P(X|z; \theta) P(z) \, dz, \tag{1}
$$

其中 $P(X|z; \theta)$ 表示给定潜变量 $z$ 时生成样本 $X$ 的条件概率。这种最大似然方法保证模型倾向于生成训练样本及其相似样本，而非随机噪声。

在变分自编码器中，常用的 $P(X|z; \theta)$ 是均值为 $f(z; \theta)$、协方差为 $\sigma^2 I$ 的高斯分布：

$$
P(X|z; \theta) = \mathcal{N}(X \mid f(z; \theta), \sigma^2 I).
$$

这个设计使得模型输出能“软匹配”训练样本，便于通过梯度下降逐渐调整参数，增加数据的生成概率。如果使用确定映射（即 $X = f(z; \theta)$），优化将难以进行。

输出分布不一定是高斯分布，例如二值数据可用伯努利分布。关键是 $P(X|z)$ 需要可计算且关于参数 $\theta$ 连续。后续为了简洁，文中将省略函数 $f$ 中的参数 $\theta$。

## 变分自编码器

虽然 VAE 含有编码器和解码器结构，看起来像传统的自编码器，但它的数学基础与稀疏自编码器或去噪自编码器并不相同。VAE 的目标是近似最大化训练样本的概率：

$$
P(X) = \int P(X|z; \theta) \, P(z) \, dz
$$

它最大的优势在于可以**直接从$P(X)$中采样**，而不像早期方法那样依赖 MCMC 等复杂的采样技术。

**VAE 需要解决两个核心问题**：

* 如何定义潜变量 $z$，即 $z$ 应该包含哪些信息？

* 如何计算 $P(X)$ 中对 $z$ 的积分？

针对第一个问题，以手写数字为例，一个合理的 $z$ 不仅要包含数字的类别信息，还要包含书写角度、笔画粗细、风格等。而这些属性往往是**相关联的**，例如书写快导致角度大、笔画细。

我们不希望人为规定 $z$ 每个维度的含义或其之间的关系，因此 VAE 采取的策略是：

> **直接假设 $z$ 来自一个简单的分布**，通常是标准正态分布 $\mathcal{N}(0, I)$。

为什么这样可行？因为任意复杂分布都可以通过把简单分布输入到一个**足够复杂的函数**中得到。例如：

$$
g(z) = \frac{z}{10} + \frac{z}{\|z\|}
$$

若 $z \sim \mathcal{N}(0, I)$，则 $g(z)$ 会产生环形分布（如图2所示）。

![](TVAE/1.png)

所以，使用神经网络等强函数逼近器，我们可以将标准正态的 $z$ 映射为**模型所需的潜在因子空间**，再进一步映射为图像 $X$。

在 VAE 中，生成图像的过程被建模为高斯分布：

$$
P(X|z; \theta) = \mathcal{N}(X \mid f(z; \theta), \sigma^2 I)
$$

其中 $f(z; \theta)$ 是多层神经网络。前几层将 $z$ 映射成潜在属性（例如数字类别、风格等），后几层则将这些属性解码为图像。

这意味着：

> **网络会自动学习潜在结构**，只要这样的结构有助于拟合训练数据（即使最大似然更大）。

现在剩下的问题是如何优化上述积分。一个直接的近似方法是采样多个 $z\_i$，然后用 Monte Carlo 平均近似 $P(X)$：

$$
P(X) \approx \frac{1}{n} \sum_{i=1}^{n} P(X|z_i)
$$

但在高维空间中，这种方式效率极低，需要非常多的样本 $z\_i$ 才能得到准确估计。

![](TVAE/2.png)

**图3 中说明了这个问题的本质**：

* 图3(a)：目标图像 $X$，我们希望估计其 $P(X)$。

* 图3(b)：模型生成的图像，看起来不像“2”，质量很差。

* 图3(c)：仅比 $X$ 偏移半个像素，看起来很像原图。

**问题在于**：

* 图3(c) 与 $X$ 的欧式距离为 0.2693

* 图3(b) 与 $X$ 的欧式距离为 0.0387

由于 $P(X|z)$ 是高斯分布，其值由 $|f(z) - X|^2$ 控制。

如果我们希望图3(b) 对 $P(X)$ 贡献很小，就必须让 $\sigma$ 足够小。但这会导致图3(c) 也被“排除”，因为其距离并不小。

> 设随机向量 $\mathbf{x} \in \mathbb{R}^d$，其分布为维度为 $d$ 的多元高斯分布，记作：
> 
> $$
> \mathbf{x} \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})
> $$
>
> 其概率密度函数为：
> 
> $$
> p(\mathbf{x}) = \frac{1}{(2\pi)^{d/2} \, |\boldsymbol{\Sigma}|^{1/2}} \, \exp\left(-\frac{1}{2} (\mathbf{x} - \boldsymbol{\mu})^\top \boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) \right)
> $$

> 在 VAE 里，我们通常假设协方差矩阵是对角的，甚至直接是单位矩阵的倍数：
> 
> $$
> \boldsymbol{\Sigma} = \sigma^2 \cdot \mathbf{I}
> $$
> 
> 此时公式简化为：
> 
> $$
> p(\mathbf{x}) = \frac{1}{(2\pi \sigma^2)^{d/2}} \, \exp\left(-\frac{1}{2\sigma^2} \|\mathbf{x} - \boldsymbol{\mu}\|^2 \right)
> $$
> 
> 其中 $|\mathbf{x} - \boldsymbol{\mu}|^2$ 是欧几里得距离的平方，表示 $X$ 与生成样本的距离。

**现存问题**（如图3所示）：

* 要排除错误样本（图3b），需要 $\sigma$ 非常小

* 但这样也会排除相似的好样本（图3c）

* 采样效率低，需大量 $z$ 才能采到接近目标图像的样本

虽然可以尝试用更好的相似性度量代替欧氏距离，但在复杂视觉任务中，这类度量难以设计，也难以训练。为此，**VAE 选择不改变相似性度量，而是优化采样方式**，以提高效率。这为后续的变分推断方法奠定了基础。

### 构建目标函数

当我们尝试通过采样计算公式 (1) 中的 $P(X)$ 时，有没有捷径可走呢？实际上，对于大多数 $z$ 值，$P(X|z)$ 都会非常接近于 0，因此对 $P(X)$ 的估计几乎没有贡献。

变分自编码器（VAE）的关键思想是：**尝试只采样那些很可能生成 $X$ 的 $z$ 值**，并利用这些 $z$ 来估计 $P(X)$。为此，我们引入一个新的分布函数 $Q(z|X)$，它能够根据输入 $X$ 生成一组可能生成 $X$ 的潜变量 $z$。希望这个 $Q(z|X)$ 下高概率的 $z$ 空间远小于先验分布 $P(z)$ 下高概率的区域。

这使得我们可以更容易地计算：

$$
\mathbb{E}_{z \sim Q}[P(X|z)] = \int Q(z) \cdot P(X|z) \, dz
$$

但问题来了：如果 $z$ 是从一个任意分布 $Q(z)$（不是标准正态分布 $N(0, I)$）中采样的，我们该如何优化 $P(X)$ 呢？

我们先从变分贝叶斯方法的基础出发：**Kullback-Leibler 散度（KL 散度）**，它衡量两个概率分布之间的距离。我们用它来衡量 $Q(z)$ 和后验分布 $P(z|X)$ 之间的差异：

$$
D_{KL}[Q(z) \| P(z|X)] = \mathbb{E}_{z \sim Q} [\log Q(z) - \log P(z|X)] \tag{2}
$$

为了将 $P(X)$ 和 $P(X|z)$ 引入这个式子，我们对 $P(z|X)$ 应用贝叶斯公式，有：

$$
D_{KL}[Q(z) \| P(z|X)] = \mathbb{E}_{z \sim Q} [\log Q(z) - \log P(X|z) - \log P(z)] + \log P(X) \tag{3}
$$

> 注意：$\log P(X)$ 不依赖于 $z$，因此可以移出期望符号。


> 我们从 KL 散度的定义开始：
> 
> $$
> D_{\text{KL}}[Q(z) \| P(z|X)] = \mathbb{E}_{z \sim Q} \left[ \log \frac{Q(z)}{P(z|X)} \right] \tag{2}
> $$
> 
> 接下来使用 **贝叶斯公式** 展开 $P(z|X)$：
> 
> $$
> P(z|X) = \frac{P(X|z) P(z)}{P(X)}
> $$
> 
> 带入上式中：
> 
> $$
> \log \frac{Q(z)}{P(z|X)} = \log \frac{Q(z)}{\frac{P(X|z) P(z)}{P(X)}} = \log \left( \frac{Q(z) P(X)}{P(X|z) P(z)} \right)
> $$
> 
> 对右侧进行对数展开：
> 
> $$
> = \log Q(z) + \log P(X) - \log P(X|z) - \log P(z)
> $$
> 
> 将其带入 KL 散度的期望中：
> 
> $$
> D_{\text{KL}}[Q(z) \| P(z|X)] = \mathbb{E}_{z \sim Q} \left[ \log Q(z) + \log P(X) - \log P(X|z) - \log P(z) \right]
> $$
> 
> 因为 $P(X)$ 与 $z$ 无关，是一个常数，可以移出期望符号：
> 
> $$
> = \mathbb{E}_{z \sim Q} \left[ \log Q(z) - \log P(X|z) - \log P(z) \right] + \log P(X)
> $$
> 
> 最终得到目标公式：
> 
> $$
> D_{\text{KL}}[Q(z) \| P(z|X)] = \mathbb{E}_{z \sim Q} [\log Q(z) - \log P(X|z) - \log P(z)] + \log P(X) \tag{3}
> $$


接着，我们将等式两边都取负号、重新排列，并将期望中的部分转换为另一个 KL 散度，从而得到：

$$
\log P(X) - D_{KL}[Q(z) \| P(z|X)] = \mathbb{E}_{z \sim Q} [\log P(X|z)] - D_{KL}[Q(z) \| P(z)] \tag{4}
$$

其中：

* 左边是我们想要的目标 $\log P(X)$ 减去一个误差项（让 $Q$ 逼近真实后验分布 $P(z|X)$）；

* 右边则是我们可以实际优化的目标。

由于我们关心的是给定样本 $X$ 的 $P(X)$，所以我们自然希望选择一个依赖于 $X$ 的 $Q(z|X)$，并让其尽可能逼近 $P(z|X)$。于是有：

$$
\log P(X) - D_{KL}[Q(z|X) \| P(z|X)] = \mathbb{E}_{z \sim Q(z|X)} [\log P(X|z)] - D_{KL}[Q(z|X) \| P(z)] \tag{5}
$$

这个公式（式 5）正是变分自编码器的核心思想，非常值得深入理解：

* 左边的 $\log P(X)$ 是我们希望最大化的目标；

* 减去的 KL 散度项会鼓励 $Q(z|X)$ 生成那些可以还原 $X$ 的 $z$；

* 如果我们能让 $Q(z|X) \approx P(z|X)$，那么这个误差项趋近于 0，我们就真正最大化了 $\log P(X)$；

* 更重要的是，这样一来我们就绕过了后验分布 $P(z|X)$ 无法精确计算的问题，用 $Q(z|X)$ 代替它。

同时，右边的结构也变得非常像一个**自编码器**：$Q(z|X)$ 像编码器（encoder）将 $X$ 映射到 $z$，而 $P(X|z)$ 像解码器（decoder）将 $z$ 还原为 $X$。

我们会在后续进一步探索这种“看起来像自编码器”的结构。


### 优化目标函数

那么我们该如何对公式（5）右边的目标函数使用随机梯度下降进行优化呢？首先，我们需要更具体地定义 $Q(z|X)$ 的形式。通常的选择是将其设为：

$$
Q(z|X) = \mathcal{N}(z \mid \mu(X; \theta), \Sigma(X; \theta))
$$

其中 $\mu$ 和 $\Sigma$ 是带参数 $\theta$ 的任意可学习的确定性函数（后续公式中将省略 $\theta$ 以简化表示）。在实际中， $\mu$ 和 $\Sigma$ 都由神经网络实现，并且通常会约束 $\Sigma$ 为对角矩阵。

这样的设定具有计算上的优势，因为它可以明确地定义如何计算公式右边的两项。最后一项 $D_{\text{KL}}[Q(z|X) | P(z)]$ 现在就变成了两个多元高斯分布之间的 KL 散度，其可以写成如下闭式表达：

$$
D_{\text{KL}}[\mathcal{N}(\mu_0, \Sigma_0) \| \mathcal{N}(\mu_1, \Sigma_1)] = \frac{1}{2} \left( \text{tr}(\Sigma_1^{-1} \Sigma_0) + (\mu_1 - \mu_0)^T \Sigma_1^{-1} (\mu_1 - \mu_0) - k + \log \left( \frac{\det \Sigma_1}{\det \Sigma_0} \right) \right) \tag{6}
$$

其中 $k$ 表示分布的维度。

在我们的设定中， $P(z) = \mathcal{N}(0, I)$，因此这个公式可以简化为：

$$
D_{\text{KL}}[\mathcal{N}(\mu(X), \Sigma(X)) \| \mathcal{N}(0, I)] = \frac{1}{2} \left( \text{tr}(\Sigma(X)) + \mu(X)^T \mu(X) - k - \log \det \Sigma(X) \right) \tag{7}
$$

---

现在来看公式（5）右边的第一项： $\mathbb{E}_{z \sim Q}[\log P(X|z)]$。我们可以使用采样来估计这个期望，但要获得准确的估计，就需要多次对 $z$ 采样并输入解码器 $f$，这在计算上代价很高。

因此，和随机梯度下降中常用的做法一样，我们通常只对 $z$ 采样一次，并用该 $z$ 下的 $\log P(X|z)$ 作为对 $\mathbb{E}_{z \sim Q}[\log P(X|z)]$ 的近似。

毕竟，我们已经在对从数据集 $D$ 中采样得到的不同 $X$ 执行随机梯度下降。

最终我们要优化的目标是：

$$
\mathbb{E}_{X \sim D} \left[ \log P(X) - D_{\text{KL}}[Q(z|X) \| P(z|X)] \right] = \mathbb{E}_{X \sim D} \left[ \mathbb{E}_{z \sim Q}[\log P(X|z)] - D_{\text{KL}}[Q(z|X) \| P(z)] \right] \tag{8}
$$

若我们对该公式求梯度，由于期望的线性性质，可以将梯度操作符移入期望内。这样我们只需采样一个 $X$ 和一个从 $Q(z|X)$ 得到的 $z$，然后计算以下表达式的梯度：

$$
\log P(X|z) - D_{\text{KL}}[Q(z|X) \| P(z)] \tag{9}
$$

我们可以对多个样本的 $X$ 和 $z$ 计算该函数的梯度并进行平均，最终会收敛到公式（8）的真实梯度。

---

然而，公式（9）存在一个重要问题： $\mathbb{E}_{z \sim Q}[\log P(X|z)]$ 不仅依赖于生成器 $P$ 的参数，还依赖于编码器 $Q$ 的参数，但在公式（9）中这种依赖“消失了”。

为了让 VAE 正常工作，我们必须推动 $Q$ 学会生成让 $P$ 能够成功解码的 $z$ 编码结果。

换种方式理解这个问题：公式（9）描述的神经网络结构类似图4左侧所示的网络。其前向传播没有问题，若对多个 $X$ 和 $z$ 样本取平均，其输出就是期望值。但我们还需要将误差反向传播到一个从 $Q(z|X)$ 中采样的 $z$，而“采样”这一操作本质上是非连续的、不可微的。

![](TVAE/3.png)

虽然反向传播可以应对带噪输入（例如 dropout），但**无法直接穿过一个采样操作的节点反向传播梯度**。

---

解决方案来自 Kingma 等人在 \[1] 中提出的 **“重参数化技巧”（reparameterization trick）**：

我们将采样从网络内部移动到输入层。具体做法是：

* 先从标准正态分布采样 $\varepsilon \sim \mathcal{N}(0, I)$

* 再计算 $z = \mu(X) + \Sigma^{1/2}(X) \cdot \varepsilon$

这样我们就可以将期望写为如下形式：

$$
\mathbb{E}_{X \sim D} \left[ \mathbb{E}_{\varepsilon \sim \mathcal{N}(0, I)} \left[ \log P(X \mid z = \mu(X) + \Sigma^{1/2}(X) \cdot \varepsilon) \right] - D_{\text{KL}}[Q(z|X) \| P(z)] \right] \tag{10}
$$

该结构如图4右侧所示。

注意：现在所有的期望都关于不依赖模型参数的分布，因此我们可以安全地将梯度符号移入期望中而不会影响等式成立。换言之，在固定 $X$ 和 $\varepsilon$ 的情况下，该函数对 $P$ 和 $Q$ 的参数是**连续且可导的**，所以反向传播可以计算出有效梯度用于随机梯度下降。

---

需要指出的一点是：**重参数化技巧仅适用于连续变量的分布**。为了能写成 $z = h(\varepsilon, X)$，其中 $\varepsilon$ 是不学习的随机变量，$h$ 是一个关于 $X$ 的连续函数，才能使其可微。

因此，如果 $Q(z|X)$ 或 $P(z)$ 是**离散分布**，就无法使用该技巧。因为在这种情况下，函数 $h(\varepsilon, X)$ 要么忽略 $X$，要么在某处发生跳跃，即出现不连续性，这会导致无法对模型参数求导。

