import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,a as r,d as n,e as a,o as i}from"./app-Crhdkm24.js";const p={};function s(c,t){return i(),o("div",null,[t[0]||(t[0]=r("p",null,[r("code",null,"Point Transformer V2 论文")],-1)),n(" more "),t[1]||(t[1]=a('<blockquote><p>论文: <a href="https://arxiv.org/abs/2210.05666" target="_blank" rel="noopener noreferrer">Point Transformer V2: Grouped Vector Attention and Partition-based Pooling</a><br> 代码: <a href="https://github.com/Pointcept/PointTransformerV2" target="_blank" rel="noopener noreferrer">https://github.com/Pointcept/PointTransformerV2</a></p></blockquote><h2 id="引言" tabindex="-1"><a class="header-anchor" href="#引言"><span>引言</span></a></h2><p>Point Transformer (PTv1) 首次将自注意力网络引入三维点云理解，并结合 <strong>向量注意力</strong> 与 <strong>U-Net 风格的编码器-解码器框架</strong>，在分类、分割等任务上取得了显著成绩。但其仍存在一些不足：</p><ul><li><p>向量注意力的权重编码依赖 MLP，当模型加深、通道数增加时，参数量急剧膨胀，容易导致严重过拟合并限制模型深度。</p></li><li><p>三维点云的位置信息比二维像素更关键，但已有方法大多借鉴二维的编码方式，未能充分利用三维坐标中的几何特性。</p></li><li><p>点云的不规则分布给池化带来挑战，以往方法依赖采样（如最远点采样、网格采样）与邻域查询（如 kNN、半径查询）的结合，既耗时又缺乏良好的空间对齐。</p></li></ul><hr><p><strong>提出的方法</strong></p><p>作者提出了新的 <strong>Point Transformer V2 (PTv2)</strong>，在多个方面改进了 PTv1：</p><ul><li><p><strong>分组向量注意力（Grouped Vector Attention, GVA）</strong></p><p>将向量注意力划分为多个组，每组共享注意力权重，从而减少参数量，提升效率。<br> GVA 同时包含了 <strong>多头注意力</strong> 与 <strong>向量注意力</strong> 的优势，并且二者都可以看作是 GVA 的特例。</p></li><li><p><strong>改进的位置编码机制</strong></p><p>在关系向量中额外引入 <strong>位置编码乘子</strong>，强化三维点的空间关系，使模型更好地利用点云的几何信息。</p></li><li><p><strong>基于分区的池化策略</strong></p><p>将点云划分为 <strong>互不重叠的分区</strong>，并直接在同一区域内融合点信息，避免了传统方法对采样和邻域查询的依赖，实现了更高效、更精准的空间对齐。</p></li></ul><h2 id="方法" tabindex="-1"><a class="header-anchor" href="#方法"><span>方法</span></a></h2>',9))])}const g=e(p,[["render",s]]),d=JSON.parse('{"path":"/3DVL/PointTransformerV2.html","title":"Point Transformer V2 论文","lang":"zh-CN","frontmatter":{"title":"Point Transformer V2 论文","icon":"file","category":["3D-VL"],"tag":["3D-VL","编辑中"],"footer":"技术共建，知识共享","date":"2025-09-07T00:00:00.000Z","author":["BinaryOracle"],"description":"Point Transformer V2 论文","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Point Transformer V2 论文\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-09-07T00:00:00.000Z\\",\\"dateModified\\":\\"2025-09-15T01:52:53.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"BinaryOracle\\"}]}"],["meta",{"property":"og:url","content":"https://mister-hope.github.io/3DVL/PointTransformerV2.html"}],["meta",{"property":"og:site_name","content":"MetaMind"}],["meta",{"property":"og:title","content":"Point Transformer V2 论文"}],["meta",{"property":"og:description","content":"Point Transformer V2 论文"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-09-15T01:52:53.000Z"}],["meta",{"property":"article:author","content":"BinaryOracle"}],["meta",{"property":"article:tag","content":"编辑中"}],["meta",{"property":"article:tag","content":"3D-VL"}],["meta",{"property":"article:published_time","content":"2025-09-07T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-09-15T01:52:53.000Z"}]]},"git":{"createdTime":1757231753000,"updatedTime":1757901173000,"contributors":[{"name":"BinaryOracle","username":"BinaryOracle","email":"3076679680@qq.com","commits":3,"url":"https://github.com/BinaryOracle"}]},"readingTime":{"minutes":1.68,"words":505},"filePathRelative":"3DVL/PointTransformerV2.md","excerpt":"<p><code>Point Transformer V2 论文</code></p>\\n","autoDesc":true}');export{g as comp,d as data};
