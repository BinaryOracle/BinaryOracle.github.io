import{_ as p}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as l,a as e,e as g,f as a,d as h,N as n,r as m,o as d,b as t}from"./app-BXcrWU1d.js";const c="/assets/1-Bk7HsVZM.png",L="/assets/2-ByEsoDr6.png",k="/assets/3-Bg4k1rcB.png",u={};function B(b,i){const o=m("CodeTabs");return d(),l("div",null,[i[4]||(i[4]=e("p",null,[e("code",null,"Prompt Engineering 知识扫盲")],-1)),g(" more "),i[5]||(i[5]=a('<h2 id="什么是prompt-engineering" tabindex="-1"><a class="header-anchor" href="#什么是prompt-engineering"><span>什么是Prompt Engineering?</span></a></h2><p>Prompt (提示词) 是人类发给各种人工智能模型、用以完成特定任务的指令。</p><p>Prompt Engineering (提示词工程) 是指我们为了让LLM能够更好地完成我们给它的任务，我们对Prompt进行优化、调整的过程。</p><p>可能会有人这么问，LLM已经这么强了，直接丢给它个指令，让他去执行就好了，为什么还需要Prompt Engineering呢？</p><p>确实像OpenAI的GPT4这样的LLM已经非常强了，很多简单的任务，我们直接用自然语言丢给他就去执行就好了。但是，对于一些复杂的问题，Prompt写得好不好，直接影响着大模型给出答案的正确与否。</p><p><strong>本质上，LLM是一个概率模型，它只是在给定的信息的前提下，给出概率最大的结果，它并不保证结果的合理性和正确性</strong>。</p><p>要让LLM给出的结果尽可能地合理、正确，这是我们使用LLM的人的职责。</p><p>这就是我们要去学习Prompt Engineering的原因。</p><h2 id="如何写好prompt" tabindex="-1"><a class="header-anchor" href="#如何写好prompt"><span>如何写好Prompt?</span></a></h2><h3 id="要明确-要具体" tabindex="-1"><a class="header-anchor" href="#要明确-要具体"><span>要明确,要具体</span></a></h3><p>我们发给LLM的批令，越明确、越具体，对于LLM越友好。</p><p>举个例子，我们让LLM对一段文字进行总结：</p>',12)),h(o,{data:[{id:"Prompt 1"},{id:"Prompt 2"}]},{title0:n(({value:s,isActive:r})=>i[0]||(i[0]=[t("Prompt 1")])),title1:n(({value:s,isActive:r})=>i[1]||(i[1]=[t("Prompt 2")])),tab0:n(({value:s,isActive:r})=>i[2]||(i[2]=[e("div",{class:"language-json line-numbers-mode","data-highlighter":"shiki","data-ext":"json",style:{"--shiki-light":"#383A42","--shiki-dark":"#abb2bf","--shiki-light-bg":"#FAFAFA","--shiki-dark-bg":"#282c34"}},[e("pre",{class:"shiki shiki-themes one-light one-dark-pro vp-code"},[e("code",{class:"language-json"},[e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"请给我总结一下这段文字的要点: 要总结的文字")])])]),e("div",{class:"line-numbers","aria-hidden":"true",style:{"counter-reset":"line-number 0"}},[e("div",{class:"line-number"})])],-1)])),tab1:n(({value:s,isActive:r})=>i[3]||(i[3]=[e("div",{class:"language-json line-numbers-mode","data-highlighter":"shiki","data-ext":"json",style:{"--shiki-light":"#383A42","--shiki-dark":"#abb2bf","--shiki-light-bg":"#FAFAFA","--shiki-dark-bg":"#282c34"}},[e("pre",{class:"shiki shiki-themes one-light one-dark-pro vp-code"},[e("code",{class:"language-json"},[e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"Prompt "),e("span",{style:{"--shiki-light":"#986801","--shiki-dark":"#D19A66"}},"2"),e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},": 你的任务是帮我总结给定文字的要点，总结的要点请按下面的格式输出，这里'###'是分隔符：")]),t(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"###")]),t(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"- {{要点1}}")]),t(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"- {{要点2}}")]),t(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"- …")]),t(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"- {{要点n}}")]),t(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"###")]),t(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"，每个要点不要超出"),e("span",{style:{"--shiki-light":"#986801","--shiki-dark":"#D19A66"}},"20"),e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"个字。这是要你总结的文字：")]),t(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"###")]),t(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"要总结的文字")]),t(`
`),e("span",{class:"line"},[e("span",{style:{"--shiki-light":"#383A42","--shiki-dark":"#ABB2BF"}},"###")])])]),e("div",{class:"line-numbers","aria-hidden":"true",style:{"counter-reset":"line-number 0"}},[e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"})])],-1)])),_:1}),i[6]||(i[6]=a('<p>Prompt 2相比Prompt 1，对输出有了更加明确具体的要求，这样LLM输出的内容也会更加贴合我们的需求。另外，我们还用了&#39;###&#39;作为分隔符，进一步帮LLM明确要求。</p><p><strong>我们在给LLM发指令的时候，第一个关键点，就是我们要把给LLM做的任务尽可能细化，把要求尽可能明确、具体地描述出来</strong>。</p><h3 id="给llm更多的时间去思考" tabindex="-1"><a class="header-anchor" href="#给llm更多的时间去思考"><span>给LLM更多的时间去思考</span></a></h3><p>《思考快与慢》这本书里介绍了我们人类大脑的“系统1”和“ 系统2”。</p><p><strong>系统1是快思考系统，反应很快，但可能会出错。</strong></p><p><strong>系统2是慢思考系统，需要更长的反应时间，进行思考、推理，但结果会更加靠谱。</strong></p><p><strong>默认情况下，LLM就像是一个快思考的系统，他利用自己已掌握的知识，快速给出答案，但并不能保证结果的正确性。</strong></p><p><strong>为了让LLM给出的答案更加靠谱，我们需要通过Prompt Engineering 的方式，把LLM的慢思考调动起来。</strong></p><p>这就是“给LLM更多的时间去思考”背后的大致逻辑。</p><p>给LLM更多的时间去思考，一个简单的技巧是在你的Prompt后面，加上这样一句话“Let’s think step by step”。这句话会引导LLM，会去分步骤思考，效果会比不加这句话要好。</p><p>另一个技巧，在Prompt中加入一些例子，让LLM照着例子进行推理、思考。这一块的技巧性很强，我们在接下来的部分，介绍几种具体的技巧。</p><h4 id="思维链技术-chain-of-thought" tabindex="-1"><a class="header-anchor" href="#思维链技术-chain-of-thought"><span>思维链技术：Chain-of-Thought</span></a></h4><p>这是<a href="https://arxiv.org/abs/2201.11903" target="_blank" rel="noopener noreferrer">《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》</a>这篇论文里讲的一个Prompt Engineering的技巧。</p><p><strong>CoT(Chain-of-Thought) 的核心思想是，在Prompt中加入一些示例，来引导LLM展现出更好的推理能力。</strong></p><p>这里的关键是在Prompt中加入的示例，在这些示例中，我们会用自然语言描述一系列的推理过程，并最终引导出示例问题的正确结果。</p><p>这个过程有点像，我们教小孩做应用题，我们先给小孩子分析讲解一些示例。然后再把新的问题让小孩子来解决。小孩子根据从示例中学习到的推理、分析能力，最终解出了新的问题。</p><p>下面我们来看论文中给的CoT的例子：</p><figure><img src="'+c+'" alt="左侧是常规的Prompt，右侧是CoT Prompt" tabindex="0" loading="lazy"><figcaption>左侧是常规的Prompt，右侧是CoT Prompt</figcaption></figure><p>蓝色标记出的部分是提供给LLM的示例。绿色标记出的部分是LLM输出的推理过程。</p><p>在使用CoT这种Prompt Engineering技巧的时候，有几个注意点：</p><ol><li><p>CoT是LLM足够大（参数足够多，通常是在1000亿参数）时才涌现出来的能力。因此，在一些不够大的LLM上，CoT的效果并不明显。</p></li><li><p>通常，在Prompt中加入的示例不是1条，而是多条。具体要考虑解决的问题类型，以及Prompt的长度（因为LLM的Prompt长度通常都是有长度限制的）。</p></li></ol><h4 id="自一致性技术-self-consistency" tabindex="-1"><a class="header-anchor" href="#自一致性技术-self-consistency"><span>自一致性技术：Self-Consistency</span></a></h4><p>这是<a href="https://arxiv.org/abs/2203.11171" target="_blank" rel="noopener noreferrer">《Self-Consistency Improves Chain of Thought Reasoning in Language Models》</a> 这篇论文里讲的另一个Prompt Engineering的技巧。</p><p>Self-Consistency技术是在CoT技术的基础之上，进行的进一步优化，目的是为了让LLM的推理能力能够更进一步提升。</p><p>Self-Consistency的大致原理是这样：</p><ol><li><p>利用CoT Prompting技巧，写好Prompt；</p></li><li><p>不要让LLM只生成最合适的唯一一个结果，而是利用LLM结果的多样性，生成多种不同推理路径所得的结果的集合；</p></li><li><p>从结果集合中投票选择，选出投票最多的结果，做为最终的答案。</p></li></ol><p>这里有像我们人类解决问题的过程，如果我们用多种不同的方法去求解，大多数方法求解出来结果都一样的答案，那很有可能就是我们最终的答案。</p><p>下面我们来看论文中给的Self-Consistency的例子：</p><figure><img src="'+L+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>在上面的例子中，虚线之上是标准的CoT的过程，它得到的结果是错的。虚线之下是Self-Consistency的过程，得到的三个答案中，有1个是错的，有2个是正确的。最终答案是大多数投票的结果，是正确的。</p><h4 id="从易至难技术-least-to-most" tabindex="-1"><a class="header-anchor" href="#从易至难技术-least-to-most"><span>从易至难技术：Least-to-Most</span></a></h4><p>这是<a href="https://arxiv.org/abs/2205.10625" target="_blank" rel="noopener noreferrer">《Least-to-Most Prompting Enables Complex Reasoning in Large Language Models》</a> 这篇论文中介绍的方法。</p><p><strong>CoT的特点是同类型问题的迁移思考，因此，如果给的例子是比较简单的问题，而给的问题却是难度大很多的问题，这时候CoT的效果就不尽如人意。</strong></p><p><strong>LtM(Least-to-Most)主是为了解决CoT这种从易到难的迁移能力不足而诞生的。</strong></p><p><strong>LtM的核心思想是：教LLM把复杂问题，拆解成一系列的简单问题，通过解决这一系列的简单问题，来最终得到复杂问题的结果。</strong></p><p>LtM的过程包含两个阶段：</p><ol><li><p>分解阶段：把复杂问题分解成一系列的简单子问题。这个阶段的Prompt中要包含分解问题的示例，要和分解的问题；</p></li><li><p>解决子问题阶段：这个阶段的Prompt中包含三部分内容：一是完整的LtM的例子；二是已解决的子问题及其答案列表；三是接下来要解答的子问题。</p></li></ol><p>这里也非常像我们人类学习解决复杂问题的过程，我们通过把复杂问题拆解成一个个的简单问题，通过把一个个的简单问题解决掉，最终把复杂问题也解决了。</p><p>下面我们来看看论文中LtM的例子：</p><figure><img src="'+k+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>从上图中，我们可以对LtM Prompting有一个直观的认知，通过引导LLM解决子问题，一步步引导LLM得出复杂问题的结果。</p>',41))])}const A=p(u,[["render",B]]),P=JSON.parse('{"path":"/LLM/%E5%BA%94%E7%94%A8%E5%B1%82/Prompt_Engineering%E7%9F%A5%E8%AF%86%E6%89%AB%E7%9B%B2.html","title":"Prompt Engineering 知识扫盲","lang":"zh-CN","frontmatter":{"title":"Prompt Engineering 知识扫盲","icon":"file","category":["大模型应用层"],"tag":["大模型应用层","已发布"],"footer":"技术共建，知识共享","date":"2025-06-17T00:00:00.000Z","order":2,"author":["BinaryOracle"],"description":"Prompt Engineering 知识扫盲","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Prompt Engineering 知识扫盲\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-06-17T00:00:00.000Z\\",\\"dateModified\\":\\"2025-06-17T15:42:48.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"BinaryOracle\\"}]}"],["meta",{"property":"og:url","content":"https://mister-hope.github.io/LLM/%E5%BA%94%E7%94%A8%E5%B1%82/Prompt_Engineering%E7%9F%A5%E8%AF%86%E6%89%AB%E7%9B%B2.html"}],["meta",{"property":"og:site_name","content":"MetaMind"}],["meta",{"property":"og:title","content":"Prompt Engineering 知识扫盲"}],["meta",{"property":"og:description","content":"Prompt Engineering 知识扫盲"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-06-17T15:42:48.000Z"}],["meta",{"property":"article:author","content":"BinaryOracle"}],["meta",{"property":"article:tag","content":"已发布"}],["meta",{"property":"article:tag","content":"大模型应用层"}],["meta",{"property":"article:published_time","content":"2025-06-17T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-06-17T15:42:48.000Z"}]]},"git":{"createdTime":1750174968000,"updatedTime":1750174968000,"contributors":[{"name":"BinaryOracle","username":"BinaryOracle","email":"3076679680@qq.com","commits":1,"url":"https://github.com/BinaryOracle"}]},"readingTime":{"minutes":6.74,"words":2023},"filePathRelative":"LLM/应用层/Prompt_Engineering知识扫盲.md","excerpt":"<p><code>Prompt Engineering 知识扫盲</code></p>\\n","autoDesc":true}');export{A as comp,P as data};
