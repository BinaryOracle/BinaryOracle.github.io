import{_ as r}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as e,e as o,d,o as n}from"./app-BxFI2vDi.js";const i="/assets/1-C_BcPLyN.png",p={};function c(s,t){return n(),a("div",null,[t[0]||(t[0]=e("p",null,[e("code",null,"庖丁解牛BLIP2")],-1)),o(" more "),t[1]||(t[1]=d('<h1 id="庖丁解牛blip2" tabindex="-1"><a class="header-anchor" href="#庖丁解牛blip2"><span>庖丁解牛BLIP2</span></a></h1><blockquote><p>论文: <a href="https://arxiv.org/abs/2301.12597" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2301.12597</a><br> 代码: <a href="https://github.com/salesforce/LAVIS/tree/main/projects/blip2" target="_blank" rel="noopener noreferrer">https://github.com/salesforce/LAVIS/tree/main/projects/blip2</a></p></blockquote><h2 id="背景" tabindex="-1"><a class="header-anchor" href="#背景"><span>背景</span></a></h2><p>多模态模型在过往发展的过程中，曾有一段时期一直在追求更大的网络架构（image encoder 和 text encoder/decoder）和 数据集，从而导致更大的训练代价。例如CLIP，400M数据，需要数百个GPU训练数十天，如何降低模型训练成本，同时具有很好的性能？</p><p>这就是BLIP-2的起因，回顾下之前的多模态网络设计，三个模块（图像分支、文本分支、融合模块）:</p><figure><img src="'+i+'" alt="多模态网络设计" tabindex="0" loading="lazy"><figcaption>多模态网络设计</figcaption></figure><p>(a) 早期的图文多模态：图像分支依赖目标检测器，模态融合比较弱，如VSE++。</p><p>(b) 重点训练图像和文本特征提取，模态融合比较轻量，如CLIP。</p><p>(c) 图像特征提取和模态融合都很重。</p><p>(d) 侧重模态融合，特征提取网络相对轻量，如ViLT。</p><table><thead><tr><th>模块</th><th>(a)</th><th>(b)</th><th>(c)</th><th>(d)</th><th>理想情况</th></tr></thead><tbody><tr><td>视觉分支</td><td>重</td><td>重</td><td>重</td><td>轻</td><td>重</td></tr><tr><td>文本分支</td><td>轻</td><td>重</td><td>轻</td><td>轻</td><td>重</td></tr><tr><td>融合模块</td><td>轻</td><td>轻</td><td>重</td><td>重</td><td>轻</td></tr><tr><td>性能</td><td>一般</td><td>好</td><td>好</td><td>一般</td><td>好</td></tr><tr><td>训练代价</td><td>中</td><td>非常高</td><td>非常高</td><td>高</td><td>中</td></tr></tbody></table><p>BLIP-2 基于 BLIP 架构，利用已有的ViT 和 LLM（均冻结）+ 一个的轻量Q-Former模块做模态融合，大幅降低训练成本。具有很强的zero-shot image-to-text generation能力，同时因LLM而具有了视觉推理能力。</p>',12))])}const h=r(p,[["render",c]]),g=JSON.parse('{"path":"/MMLLM/%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9BBLIP2.html","title":"庖丁解牛BLIP2","lang":"zh-CN","frontmatter":{"icon":"file","category":["MMLLM"],"tag":["多模态","编辑中"],"footer":"技术共建，知识共享","date":"2025-05-25T00:00:00.000Z","cover":"assets/cover/BLIP2.png","author":["BinaryOracle"],"description":"庖丁解牛BLIP2","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"庖丁解牛BLIP2\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-05-25T00:00:00.000Z\\",\\"dateModified\\":\\"2025-05-31T03:31:54.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"BinaryOracle\\"}]}"],["meta",{"property":"og:url","content":"https://mister-hope.github.io/MMLLM/%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9BBLIP2.html"}],["meta",{"property":"og:site_name","content":"MetaMind"}],["meta",{"property":"og:title","content":"庖丁解牛BLIP2"}],["meta",{"property":"og:description","content":"庖丁解牛BLIP2"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-05-31T03:31:54.000Z"}],["meta",{"property":"article:author","content":"BinaryOracle"}],["meta",{"property":"article:tag","content":"编辑中"}],["meta",{"property":"article:tag","content":"多模态"}],["meta",{"property":"article:published_time","content":"2025-05-25T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-05-31T03:31:54.000Z"}]]},"git":{"createdTime":1748142340000,"updatedTime":1748662314000,"contributors":[{"name":"BinaryOracle","username":"BinaryOracle","email":"3076679680@qq.com","commits":3,"url":"https://github.com/BinaryOracle"},{"name":"大忽悠","username":"","email":"3076679680@qq.com","commits":4}]},"readingTime":{"minutes":1.34,"words":403},"filePathRelative":"MMLLM/庖丁解牛BLIP2.md","excerpt":"<p><code>庖丁解牛BLIP2</code></p>\\n","autoDesc":true}');export{h as comp,g as data};
