import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as l,a as t,d as T,e as r,b as n,o}from"./app-4s_tN-H4.js";const s="/assets/1-_9pbK23p.png",Q="/assets/2-A_wQDF6Q.png",i="/assets/3-C036Nh8v.png",p="/assets/4-SRV479HM.png",g={},m={class:"MathJax",jax:"SVG",style:{position:"relative"}},d={style:{"vertical-align":"0"},xmlns:"http://www.w3.org/2000/svg",width:"7.291ex",height:"1.532ex",role:"img",focusable:"false",viewBox:"0 -677 3222.4 677","aria-hidden":"true"},u={class:"MathJax",jax:"SVG",style:{position:"relative"}},h={style:{"vertical-align":"0"},xmlns:"http://www.w3.org/2000/svg",width:"9.553ex",height:"1.532ex",role:"img",focusable:"false",viewBox:"0 -677 4222.4 677","aria-hidden":"true"},M={class:"MathJax",jax:"SVG",style:{position:"relative"}},V={style:{"vertical-align":"-0.439ex"},xmlns:"http://www.w3.org/2000/svg",width:"8.177ex",height:"2.034ex",role:"img",focusable:"false",viewBox:"0 -705 3614.1 899","aria-hidden":"true"},f={class:"MathJax",jax:"SVG",style:{position:"relative"}},H={style:{"vertical-align":"-0.439ex"},xmlns:"http://www.w3.org/2000/svg",width:"9.308ex",height:"2.034ex",role:"img",focusable:"false",viewBox:"0 -705 4114.1 899","aria-hidden":"true"},c={class:"MathJax",jax:"SVG",style:{position:"relative"}},L={style:{"vertical-align":"-0.186ex"},xmlns:"http://www.w3.org/2000/svg",width:"10.018ex",height:"1.692ex",role:"img",focusable:"false",viewBox:"0 -666 4428 748","aria-hidden":"true"},w={class:"MathJax",jax:"SVG",style:{position:"relative"}},x={style:{"vertical-align":"-0.186ex"},xmlns:"http://www.w3.org/2000/svg",width:"6.082ex",height:"1.692ex",role:"img",focusable:"false",viewBox:"0 -666 2688.4 748","aria-hidden":"true"};function Z(B,a){return o(),l("div",null,[a[25]||(a[25]=t("p",null,[t("code",null,"Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks 论文解读")],-1)),T(" more "),a[26]||(a[26]=r('<blockquote><p>论文链接: <a href="https://arxiv.org/abs/2208.10442" target="_blank" rel="noopener noreferrer">Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks</a><br> 代码链接: <a href="https://github.com/microsoft/unilm/tree/master/beit3" target="_blank" rel="noopener noreferrer">https://github.com/microsoft/unilm/tree/master/beit3</a></p></blockquote><h2 id="引言" tabindex="-1"><a class="header-anchor" href="#引言"><span>引言</span></a></h2><p>近年来，<strong>语言、视觉与多模态预训练</strong>正在出现“大融合”的趋势。研究者发现，只要在<strong>海量数据</strong>上进行大规模预训练，就可以把模型轻松迁移到各种下游任务中。一个理想的方向是：<strong>预训练一个通用基础模型，能够同时处理多种模态</strong>。</p><p>BEiT-3 正是顺应这一趋势提出的，它在 <strong>视觉任务</strong>和 <strong>视觉-语言任务</strong>上都取得了最新的迁移性能；BEiT-3 核心贡献如下:</p><p><strong>1. 统一的骨干架构</strong></p><p>Transformer 的成功已经从 <strong>语言</strong> 扩展到了 <strong>视觉</strong> 和 <strong>多模态</strong>任务，这使得用统一网络结构来处理不同模态成为可能。不过，不同下游任务常常需要不同架构：</p><ul><li><p><strong>双编码器 (dual-encoder)</strong>：用于高效检索（如跨模态检索）。</p></li><li><p><strong>编码器-解码器 (encoder-decoder)</strong>：用于生成任务（如图像描述）。</p></li><li><p><strong>融合编码器 (fusion-encoder)</strong>：用于图文联合表示学习。</p></li></ul><p>问题在于：大多数基础模型需要针对不同任务手动调整网络格式，且不同模态之间的参数往往难以有效共享。</p><p>BEiT-3 引入了 <strong>Multiway Transformer</strong>（多路 Transformer），作为通用建模框架。它既能做模态特定的编码，也能实现跨模态深度融合，<strong>做到“一套架构适配所有下游任务”</strong>。</p><hr><p><strong>2. 统一的预训练任务</strong></p><p>掩码建模（Masked Data Modeling）已在多种模态上取得成功：</p><ul><li><p>文本（Masked Language Modeling, MLM）</p></li><li><p>图像（Masked Image Modeling, MIM）</p></li><li><p>图文对（Masked Multimodal Modeling）</p></li></ul><p>现有视觉-语言基础模型通常需要 <strong>多任务训练</strong>（如图文匹配、对比学习），但这会导致扩展到大规模数据时效率低。</p><p>BEiT-3 的做法是：只保留 <strong>单一任务</strong>——<strong>mask-then-predict（掩码预测）</strong>。</p><ul><li><p>把图像当作外语（Imglish），和文本用相同的方式建模。</p></li><li><p>图文对被看作“平行句子”，用来学习模态间的对齐关系。</p></li></ul><p>这种方法虽然简单，却能学习到很强的可迁移表征，并在视觉与视觉-语言任务中取得了最新结果。</p><hr><p><strong>3. 模型与数据的规模化</strong></p><p>扩大模型规模与数据规模，可以显著提高基础模型的泛化能力。</p><ul><li><p>BEiT-3 将模型扩展到了 <strong>数十亿参数</strong>级别。</p></li><li><p>预训练数据规模也被扩大，但仅使用 <strong>公开数据集</strong>，保证学术可复现性。</p></li></ul><p>即使没有依赖私有数据，BEiT-3 依然超过了许多依赖私有大数据的基础模型。</p><p>此外，将图像当作外语的方式还能直接复用大规模语言模型的训练管线，从而在规模化上进一步受益。</p><hr><p>BEiT-3 使用 Multiway Transformer，在 <strong>图像、文本和图文对</strong>上进行统一的掩码建模。</p><ul><li><p>在训练中，会随机掩码部分文本 token 或图像 patch。</p></li><li><p>学习目标是恢复原始 token（文本 token 或视觉 token）。</p></li></ul><p>这是一个标准的自监督学习任务，使模型在预训练阶段就能获得通用性。 BEiT-3 在多种任务上都取得了最新性能，包括：</p><ul><li><p><strong>视觉任务</strong>：目标检测（COCO）、实例分割（COCO）、语义分割（ADE20K）、图像分类（ImageNet）</p></li><li><p><strong>视觉-语言任务</strong>：视觉推理（NLVR2）、视觉问答（VQAv2）、图像描述（COCO）、跨模态检索（Flickr30K、COCO）</p></li></ul><p>结果显示：</p><ul><li><p>即使只使用公开数据，BEiT-3 依然超越了许多依赖私有数据的强大模型。</p></li><li><p>它不仅在多模态任务上表现优异，在<strong>纯视觉任务</strong>中也能达到甚至超过专用模型的效果。</p></li></ul><h2 id="方法" tabindex="-1"><a class="header-anchor" href="#方法"><span>方法</span></a></h2><figure><img src="'+s+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>如图2所示，BEiT-3 通过在单模态与多模态数据上进行 <strong>掩码数据建模</strong> 来预训练，采用的是一个共享的 <strong>Multiway Transformer</strong> 网络。该模型可以迁移到多种视觉和视觉-语言下游任务中。</p><h3 id="骨干网络-multiway-transformers" tabindex="-1"><a class="header-anchor" href="#骨干网络-multiway-transformers"><span>骨干网络：Multiway Transformers</span></a></h3><p>我们采用 <strong>Multiway Transformer</strong> 作为骨干模型来对不同模态进行编码。</p><p>如图2所示，每一个 Multiway Transformer 块由一个共享的 <strong>自注意力模块</strong> 和一个 <strong>前馈网络池（即模态专家）</strong> 构成，不同模态使用不同的专家。我们会根据输入 token 的模态，将其路由到对应的专家。在实现中：</p><ul><li><p>每一层包含一个 <strong>视觉专家</strong> 和一个 <strong>语言专家</strong>。</p></li><li><p>顶部三层还额外包含 <strong>视觉-语言专家</strong>，用于融合编码（fusion encoder）。</p></li></ul><figure><img src="'+Q+'" alt="见图3 (a)(b)(c) 了解更详细的结构布局" tabindex="0" loading="lazy"><figcaption>见图3 (a)(b)(c) 了解更详细的结构布局</figcaption></figure><p>使用一组模态专家可以鼓励模型更好地捕获模态特定的信息；而共享的自注意力模块则负责学习不同模态之间的对齐，并支持在多模态任务（如视觉-语言任务）中实现深度融合。</p><p>如图3所示，这种统一架构使得 BEiT-3 能够支持多种下游任务。例如：</p><ul><li><p>BEiT-3 可以作为图像骨干网络，用于图像分类、目标检测、实例分割和语义分割等任务。</p></li><li><p>它也可以微调用作 <strong>双编码器</strong>，用于高效的图文检索。</p></li><li><p>还可以作为 <strong>融合模型</strong>，应用于多模态理解与生成任务。</p></li></ul><hr><h3 id="预训练任务-掩码数据建模" tabindex="-1"><a class="header-anchor" href="#预训练任务-掩码数据建模"><span>预训练任务：掩码数据建模</span></a></h3><p>我们通过一个 <strong>统一的掩码数据建模（Masked Data Modeling, MDM）</strong> 目标来预训练 BEiT-3，适用于单模态数据（即图像和文本）以及多模态数据（即图文对）。</p><p>在预训练过程中，我们会随机掩码一部分文本 token 或图像 patch，然后训练模型恢复被掩码的 token。这样一个统一的 mask-then-predict 任务不仅可以学习到表征，还能学到不同模态之间的对齐。</p><ul><li><p><strong>文本数据</strong>：使用 SentencePiece tokenizer 进行分词。</p></li><li><p><strong>图像数据</strong>：使用 BEiT v2 的 tokenizer 获得离散化的视觉 token，作为重建目标。</p></li></ul><p>掩码策略如下：</p><ul><li><p>对单模态文本：随机掩码 15% 的 token。</p></li><li><p>对图文对中的文本：随机掩码 50% 的 token。</p></li><li><p>对图像：使用与 BEiT 相同的 <strong>block-wise 掩码策略</strong>，随机掩码 40% 的图像 patch。</p></li></ul><p>值得注意的是，我们只使用这一种预训练任务，使得训练过程更适合规模化。而之前的视觉-语言模型通常需要多个预训练目标（如图文对比、图文匹配、词-图像 patch/区域对齐等）。</p><p>相比之下，我们的方法能使用更小的 batch size 进行训练。而基于对比学习的模型通常需要非常大的 batch size，这带来了工程上的挑战（如 GPU 内存消耗）。</p><hr><h3 id="模型与预训练规模化" tabindex="-1"><a class="header-anchor" href="#模型与预训练规模化"><span>模型与预训练规模化</span></a></h3><p><strong>骨干网络</strong></p><figure><img src="'+i+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>BEiT-3 是一个 <strong>超大规模基础模型</strong>，其配置遵循 ViT-giant 。如表2所示，该模型包含：</p><ul><li><p>40 层 Multiway Transformer</p></li><li><p>隐藏层大小为 1408</p></li><li><p>中间层大小为 6144</p></li><li><p>16 个注意力头</p></li></ul><p>每一层都包含视觉专家与语言专家，顶层三层还包含视觉-语言专家。自注意力模块在不同模态之间共享。</p><p>参数规模：BEiT-3 总共有 <strong>19 亿参数</strong>：</p><ul><li><p>视觉专家：6.92 亿</p></li><li><p>语言专家：6.92 亿</p></li><li><p>视觉-语言专家：5200 万</p></li><li><p>共享自注意力模块：3.17 亿</p></li></ul><p>当 BEiT-3 用作纯视觉编码器时，只有与视觉相关的参数会被激活，其规模大约与 ViT-giant 相当（约 10 亿参数）。</p><hr><p><strong>预训练数据</strong></p><figure><img src="'+p+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>BEiT-3 在单模态和多模态数据上进行预训练（见表3）。</p><ul><li><p><strong>多模态数据</strong>：约 1500 万图像和 2100 万图文对，来自 5 个公开数据集： Conceptual 12M (CC12M)、Conceptual Captions (CC3M) 、SBU Captions (SBU) 、COCO 和 Visual Genome (VG) 。</p></li><li><p><strong>单模态数据</strong>：来自 ImageNet-21K 的 1400 万图像，以及 160GB 文本语料 ，包括：English Wikipedia、BookCorpus 、OpenWebText3、CC-News 和 Stories 。</p></li></ul><hr><p><strong>预训练设置</strong></p><ul><li><p>总共训练 <strong>100 万步</strong>。</p></li><li><p>每个 batch 包含 6144 个样本（2048 图像 + 2048 文本 + 2048 图文对）。</p></li><li><p>相比对比学习模型 ，所需 batch size 要小得多。</p></li></ul><p>图像处理：</p>',69)),t("ul",null,[t("li",null,[t("p",null,[a[4]||(a[4]=n("patch 大小为 ")),t("mjx-container",m,[(o(),l("svg",d,a[0]||(a[0]=[r('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path></g></g></g>',1)]))),a[1]||(a[1]=t("mjx-assistive-mml",{unselectable:"on",display:"inline"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mn",null,"14"),t("mo",null,"×"),t("mn",null,"14")])],-1))]),a[5]||(a[5]=n("，输入分辨率 ")),t("mjx-container",u,[(o(),l("svg",h,a[2]||(a[2]=[r('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1000,0)"></path></g></g></g>',1)]))),a[3]||(a[3]=t("mjx-assistive-mml",{unselectable:"on",display:"inline"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mn",null,"224"),t("mo",null,"×"),t("mn",null,"224")])],-1))]),a[6]||(a[6]=n("。"))])]),a[7]||(a[7]=t("li",null,[t("p",null,"数据增强与 BEiT 相同，包括随机裁剪、水平翻转、颜色扰动。")],-1))]),a[27]||(a[27]=t("p",null,"文本处理：",-1)),a[28]||(a[28]=t("ul",null,[t("li",null,"使用 64k 词表的 SentencePiece tokenizer。")],-1)),a[29]||(a[29]=t("p",null,"优化配置：",-1)),t("ul",null,[t("li",null,[t("p",null,[a[14]||(a[14]=n("优化器：AdamW ，超参数 ")),t("mjx-container",M,[(o(),l("svg",V,a[8]||(a[8]=[r('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mn" transform="translate(599,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1280.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(2336.1,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(778,0)"></path></g></g></g>',1)]))),a[9]||(a[9]=t("mjx-assistive-mml",{unselectable:"on",display:"inline"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msub",null,[t("mi",null,"β"),t("mn",null,"1")]),t("mo",null,"="),t("mn",null,"0.9")])],-1))]),a[15]||(a[15]=n("，")),t("mjx-container",f,[(o(),l("svg",H,a[10]||(a[10]=[r('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mn" transform="translate(599,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1280.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(2336.1,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(778,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1278,0)"></path></g></g></g>',1)]))),a[11]||(a[11]=t("mjx-assistive-mml",{unselectable:"on",display:"inline"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msub",null,[t("mi",null,"β"),t("mn",null,"2")]),t("mo",null,"="),t("mn",null,"0.98")])],-1))]),a[16]||(a[16]=n("，")),t("mjx-container",c,[(o(),l("svg",L,a[12]||(a[12]=[r('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D716" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path></g><g data-mml-node="mo" transform="translate(683.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1739.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(2239.6,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(2927.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(3928,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path></g></g></g>',1)]))),a[13]||(a[13]=t("mjx-assistive-mml",{unselectable:"on",display:"inline"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"ϵ"),t("mo",null,"="),t("mn",null,"1"),t("mi",null,"e"),t("mo",null,"−"),t("mn",null,"6")])],-1))]),a[17]||(a[17]=n("。"))])]),t("li",null,[t("p",null,[a[20]||(a[20]=n("学习率：cosine decay 调度器，峰值 ")),t("mjx-container",w,[(o(),l("svg",x,a[18]||(a[18]=[r('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(1188.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(2188.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g></g>',1)]))),a[19]||(a[19]=t("mjx-assistive-mml",{unselectable:"on",display:"inline"},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mn",null,"1"),t("mi",null,"e"),t("mo",null,"−"),t("mn",null,"3")])],-1))]),a[21]||(a[21]=n("，线性 warmup 10000 步。"))])]),a[22]||(a[22]=t("li",null,[t("p",null,"权重衰减：0.05。")],-1)),a[23]||(a[23]=t("li",null,[t("p",null,"随机深度 (stochastic depth) ：0.1。")],-1)),a[24]||(a[24]=t("li",null,[t("p",null,"初始化：采用 BEiT 初始化算法稳定 Transformer 训练。")],-1))]),a[30]||(a[30]=r('<h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><p><strong>BEIT-3</strong>: 一个通用的多模态基础模型，在广泛的视觉和视觉-语言基准测试上都取得了 <strong>最新的最优性能</strong>。</p><p>BEIT-3 的核心思想是：<strong>将图像视作一种外语</strong>，从而可以在图像、文本以及图文对上以统一方式进行 <strong>掩码“语言”建模</strong>。</p><p>我们还展示了 <strong>Multiway Transformers</strong> 能够有效建模不同的视觉与视觉-语言任务，使其成为通用建模的一个有趣选择。BEIT-3 方法简单且高效，是 <strong>多模态基础模型规模化发展的有前景方向</strong>。</p><p>更进一步：</p><ul><li><p>预训练 <strong>多语言版本的 BEIT-3</strong>，并加入更多模态（例如音频），以促进跨语言和跨模态迁移，推进大规模预训练在任务、语言和模态间的 <strong>大融合</strong>。</p></li><li><p>结合 BEIT-3 与 <strong>MetaLM</strong> 的优势，探索为多模态基础模型赋予 <strong>上下文学习能力（in-context learning）</strong>。</p></li></ul><blockquote><p>官方没有开源预训练阶段代码，所以本文就不再对代码进行讲解了。</p></blockquote>',7))])}const k=e(g,[["render",Z]]),E=JSON.parse('{"path":"/MMLLM/BEIT3.html","title":"BEIT3 论文","lang":"zh-CN","frontmatter":{"title":"BEIT3 论文","icon":"file","category":["多模态"],"tag":["多模态","已发布"],"footer":"技术共建，知识共享","date":"2025-08-22T00:00:00.000Z","author":["BinaryOracle"],"description":"Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks 论文解读","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"BEIT3 论文\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-08-22T00:00:00.000Z\\",\\"dateModified\\":\\"2025-08-28T03:09:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"BinaryOracle\\"}]}"],["meta",{"property":"og:url","content":"https://mister-hope.github.io/MMLLM/BEIT3.html"}],["meta",{"property":"og:site_name","content":"MetaMind"}],["meta",{"property":"og:title","content":"BEIT3 论文"}],["meta",{"property":"og:description","content":"Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks 论文解读"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-28T03:09:58.000Z"}],["meta",{"property":"article:author","content":"BinaryOracle"}],["meta",{"property":"article:tag","content":"已发布"}],["meta",{"property":"article:tag","content":"多模态"}],["meta",{"property":"article:published_time","content":"2025-08-22T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-28T03:09:58.000Z"}]]},"git":{"createdTime":1755826642000,"updatedTime":1756350598000,"contributors":[{"name":"BinaryOracle","username":"BinaryOracle","email":"3076679680@qq.com","commits":5,"url":"https://github.com/BinaryOracle"}]},"readingTime":{"minutes":8.35,"words":2505},"filePathRelative":"MMLLM/BEIT3.md","excerpt":"<p><code>Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks 论文解读</code></p>\\n","autoDesc":true}');export{k as comp,E as data};
