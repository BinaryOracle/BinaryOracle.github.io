import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,a,d as r,e as i,o as n}from"./app-Dz5zJGT1.js";const p="/assets/1-D1pbm_VH.png",l="/assets/4-b4D0c1aJ.png",s="/assets/2-Ch_jbl-N.png",c="/assets/2-DhTi-rFx.png",d={};function f(h,e){return n(),o("div",null,[e[0]||(e[0]=a("p",null,[a("code",null,"3D Affordance Grounding 方向复盘")],-1)),r(" more "),e[1]||(e[1]=i('<h2 id="点云-文本" tabindex="-1"><a class="header-anchor" href="#点云-文本"><span>点云 + 文本</span></a></h2><h3 id="affogato-arxiv-2025-06" tabindex="-1"><a class="header-anchor" href="#affogato-arxiv-2025-06"><span><a href="https://arxiv.org/abs/2506.12009" target="_blank" rel="noopener noreferrer">Affogato (Arxiv 2025.06)</a></span></a></h3><p>特点:</p><ol><li><p>AFFOrdance Grounding All aT Once</p></li><li><p>a large-scale dataset for 3D and 2D affordance grounding</p></li><li><p>minimalistic architecture</p></li></ol><figure><img src="'+p+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>损失函数:</p><ol><li><p>Focal Loss to handle class imbalance</p></li><li><p>Dice Loss to improve region-level alignment.</p></li></ol><p>现状:</p><ol><li><p>wait for code release</p></li><li><p>dataset available</p></li></ol><h3 id="seqafford-cvpr-2025" tabindex="-1"><a class="header-anchor" href="#seqafford-cvpr-2025"><span><a href="https://arxiv.org/abs/2412.01550" target="_blank" rel="noopener noreferrer">SeqAfford (CVPR 2025)</a></span></a></h3><p>特点:</p><figure><img src="'+l+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>损失函数:</p><p>现状:</p><ol><li><p>code available</p></li><li><p>dataset available</p></li></ol><h2 id="点云-图像" tabindex="-1"><a class="header-anchor" href="#点云-图像"><span>点云 + 图像</span></a></h2><h2 id="点云-文本-图像" tabindex="-1"><a class="header-anchor" href="#点云-文本-图像"><span>点云 + 文本 + 图像</span></a></h2><h3 id="great-cvpr-2025" tabindex="-1"><a class="header-anchor" href="#great-cvpr-2025"><span><a href="https://arxiv.org/abs/2411.19626" target="_blank" rel="noopener noreferrer">GREAT (CVPR 2025)</a></span></a></h3><p>特点:</p><ol><li><p>grounding 3D object affordance in an Open-Vocabulary fashion</p></li><li><p>Multi-Head Affordance Chain-of-Thought</p></li></ol><blockquote><p>Data preparation stage:</p><ol><li><p>Use prompts to generate descriptions of the object interaction area, the morphology(形态学) of the interaction area, the interaction behavior, and other common interaction behaviors of the object.</p></li><li><p>Geometric structure knowledge = Answers to Prompt 1 + Prompt 2 = Interaction parts + Inference of geometric properties of these parts</p></li><li><p>Interaction knowledge = Answers to Prompt 3 + Prompt 4 = Current interaction + Analogous(类似的)/supplementary(补充) interaction methods</p></li></ol></blockquote><ol start="3"><li>PIADv2 dataset</li></ol><blockquote><p>24 affordance , 43 object categories, 15K interaction images , 38K 3D objects with annotations.</p></blockquote><figure><img src="'+s+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>损失函数:</p><ol><li><p>Focal Loss to handle class imbalance</p></li><li><p>Dice Loss to improve region-level alignment.</p></li></ol><p>现状:</p><ol><li><p>code available</p></li><li><p>dataset available</p></li></ol><h2 id="_3d-gaussian-splatting-3dgs" tabindex="-1"><a class="header-anchor" href="#_3d-gaussian-splatting-3dgs"><span>3D Gaussian Splatting (3DGS)</span></a></h2><h3 id="geal-cvpr-2025" tabindex="-1"><a class="header-anchor" href="#geal-cvpr-2025"><span><a href="https://arxiv.org/abs/2412.09511" target="_blank" rel="noopener noreferrer">GEAL (CVPR 2025)</a></span></a></h3><p>特点:</p><ol><li><p>&quot;Knowledge Distillation&quot; from 2D to 3D: Transfer the semantic capabilities of pre-trained 2D models to the 3D affordance prediction model through Gaussian splat mapping, cross-modal consistency alignment, and multi-scale fusion.</p></li><li><p>Noisy Dataset: Construct a new benchmark with multiple types of noise/damage to evaluate the generalization and robustness of the model under real/harsh conditions.</p></li></ol><figure><img src="'+c+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>损失函数:</p><ol><li><p>BCE</p></li><li><p>Dice Loss</p></li><li><p>Consistency Loss（MSE 损失）</p></li></ol><p>现状:</p><ol><li><p>wait for code release</p></li><li><p>wait for dataset release</p></li></ol><h3 id="_3daffordsplat-arxiv-2025-04" tabindex="-1"><a class="header-anchor" href="#_3daffordsplat-arxiv-2025-04"><span><a href="https://arxiv.org/abs/2504.11218" target="_blank" rel="noopener noreferrer">3DAffordSplat (Arxiv 2025.04)</a></span></a></h3><h3 id="iaao-cvpr-2025" tabindex="-1"><a class="header-anchor" href="#iaao-cvpr-2025"><span><a href="https://arxiv.org/abs/2504.06827" target="_blank" rel="noopener noreferrer">IAAO (CVPR 2025)</a></span></a></h3><h2 id="idea" tabindex="-1"><a class="header-anchor" href="#idea"><span>idea</span></a></h2><p>Momentum Encoder 生成伪标签应对噪声问题，实现更加稳健的学习 ？(参考: MoCo , ALBEF , DINO)</p>',41))])}const u=t(d,[["render",f]]),b=JSON.parse('{"path":"/3DVL/3D_affordance_grounding.html","title":"3D Affordance Grounding 方向复盘","lang":"zh-CN","frontmatter":{"title":"3D Affordance Grounding 方向复盘","icon":"file","category":["3D-VL"],"tag":["3D-VL","编辑中"],"footer":"技术共建，知识共享","date":"2025-09-15T00:00:00.000Z","author":["BinaryOracle"],"description":"3D Affordance Grounding 方向复盘","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"3D Affordance Grounding 方向复盘\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-09-15T00:00:00.000Z\\",\\"dateModified\\":\\"2025-09-15T07:26:37.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"BinaryOracle\\"}]}"],["meta",{"property":"og:url","content":"https://mister-hope.github.io/3DVL/3D_affordance_grounding.html"}],["meta",{"property":"og:site_name","content":"MetaMind"}],["meta",{"property":"og:title","content":"3D Affordance Grounding 方向复盘"}],["meta",{"property":"og:description","content":"3D Affordance Grounding 方向复盘"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-09-15T07:26:37.000Z"}],["meta",{"property":"article:author","content":"BinaryOracle"}],["meta",{"property":"article:tag","content":"编辑中"}],["meta",{"property":"article:tag","content":"3D-VL"}],["meta",{"property":"article:published_time","content":"2025-09-15T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-09-15T07:26:37.000Z"}]]},"git":{"createdTime":1757901173000,"updatedTime":1757921197000,"contributors":[{"name":"BinaryOracle","username":"BinaryOracle","email":"3076679680@qq.com","commits":3,"url":"https://github.com/BinaryOracle"}]},"readingTime":{"minutes":1.4,"words":421},"filePathRelative":"3DVL/3D_affordance_grounding.md","excerpt":"<p><code>3D Affordance Grounding 方向复盘</code></p>\\n","autoDesc":true}');export{u as comp,b as data};
