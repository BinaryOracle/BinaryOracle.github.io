import{_ as r}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,a as T,d as o,e as a,b as t,o as l}from"./app-4s_tN-H4.js";const s="/assets/1-B4ckMDuH.png",e="/assets/2-DzRsN2Rr.png",m="/assets/3-DRNvmt2c.png",p="/assets/4-BMYYQyBr.png",i={},d={class:"MathJax",jax:"SVG",display:"true",style:{position:"relative"}},g={style:{"vertical-align":"-2.819ex"},xmlns:"http://www.w3.org/2000/svg",width:"26.73ex",height:"6.354ex",role:"img",focusable:"false",viewBox:"0 -1562.5 11814.7 2808.5","aria-hidden":"true"},h={class:"MathJax",jax:"SVG",style:{position:"relative"}},u={style:{"vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"15.371ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 6794 1000","aria-hidden":"true"},H={class:"MathJax",jax:"SVG",style:{position:"relative"}},L={style:{"vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"20.63ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 9118.7 1000","aria-hidden":"true"},c={class:"MathJax",jax:"SVG",style:{position:"relative"}},f={style:{"vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"6.201ex",height:"2.758ex",role:"img",focusable:"false",viewBox:"0 -969 2741 1219","aria-hidden":"true"},M={class:"MathJax",jax:"SVG",style:{position:"relative"}},x={style:{"vertical-align":"0"},xmlns:"http://www.w3.org/2000/svg",width:"2.009ex",height:"1.545ex",role:"img",focusable:"false",viewBox:"0 -683 888 683","aria-hidden":"true"};function Z(D,Q){return l(),n("div",null,[Q[23]||(Q[23]=T("p",null,[T("code",null,"GPT-2 论文")],-1)),o(" more "),Q[24]||(Q[24]=a('<blockquote><p>论文链接: <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener noreferrer">Language Models are Unsupervised Multitask Learners</a></p></blockquote><h2 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h2><p>这篇论文《Language Models are Unsupervised Multitask Learners》由OpenAI团队提出，介绍了GPT-2模型，展示了大规模语言模型在无监督多任务学习中的潜力。GPT-2通过训练一个包含45百万网页链接的WebText数据集，<strong>能够在零样本（zero-shot）设置下完成多种自然语言处理任务</strong>，如问答、翻译、摘要和阅读理解等，<strong>无需任务特定的监督训练</strong>。研究发现，<strong>模型容量对任务性能至关重要，更大的模型在多个基准测试中达到了最先进水平</strong>。论文还探讨了模型泛化与记忆的关系，并指出GPT-2在生成连贯文本方面的能力，为构建通用语言处理系统提供了新思路。</p><h2 id="简介" tabindex="-1"><a class="header-anchor" href="#简介"><span>简介</span></a></h2><ol><li><strong>当前机器学习系统的局限性</strong></li></ol><p>当前的机器学习系统虽然在特定任务上表现出色，但依赖于大量标注数据和监督学习，导致其泛化能力有限。这些系统往往对数据分布或任务定义的微小变化非常敏感，表现为“狭窄的专家”而非通用的多任务处理者。作者指出，这种局限性部分源于单任务、单领域的数据集训练模式，限制了模型在多样化场景中的应用能力。</p><hr><ol start="2"><li><strong>多任务学习的挑战与机遇</strong></li></ol><p>多任务学习（Multitask Learning）被视为提升模型通用性的潜在途径，但其在自然语言处理（NLP）领域的进展仍处于早期阶段。现有研究通常仅联合训练少量任务（如10-17个任务），而机器学习系统通常需要数百至数千个任务示例才能实现良好的泛化。作者认为，单纯依赖人工标注和设计任务目标难以满足多任务学习的规模化需求，因此需要探索更高效的学习范式。</p><hr><ol start="3"><li><strong>预训练与迁移学习的趋势</strong></li></ol><p>近年来，预训练结合监督微调的方法在NLP任务中表现突出。从早期的词向量（如Word2Vec）到上下文感知的循环神经网络（如ELMo），再到基于自注意力机制的Transformer架构（如BERT、GPT），模型的迁移能力逐渐增强。然而，这些方法仍依赖监督数据。作者提出，语言模型本身可能通过无监督学习捕捉任务相关的知识，从而减少对显式监督的依赖。</p><hr><ol start="4"><li><strong>论文的核心假设与目标</strong></li></ol><p>本文的核心假设是：<strong>足够大的语言模型在多样化文本训练下，能够通过预测任务的自然语言描述（如问答、翻译的文本示例）间接学习任务，而无需参数调整或架构修改</strong>。作者通过实验验证这一假设，证明GPT-2在零样本设置下能完成多种任务，部分任务性能接近或超越监督基线模型。这一发现为构建通用语言系统提供了新方向，同时揭示了模型容量与任务性能之间的紧密关联。</p><hr><ol start="5"><li><strong>研究意义</strong></li></ol><p>论文强调，无监督任务学习是预训练技术成功的关键因素之一。尽管零样本性能尚不完美，但结果表明语言模型在无监督条件下已具备初步的多任务处理能力，为未来探索更通用的AI系统奠定了基础。</p><h2 id="方法" tabindex="-1"><a class="header-anchor" href="#方法"><span>方法</span></a></h2><p><strong>1. 语言建模的核心框架</strong></p><p>论文的核心方法是基于<strong>语言建模（Language Modeling, LM）</strong>，即通过无监督学习估计文本序列的概率分布。给定一个符号序列 ((s_1, s_2, ..., s_n))，语言模型通过链式法则计算联合概率：</p>',21)),T("mjx-container",d,[(l(),n("svg",g,Q[0]||(Q[0]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mo" transform="translate(503,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(892,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1464,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2130.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munderover" transform="translate(3186.6,0)"><g data-mml-node="mo"><path data-c="220F" d="M220 812Q220 813 218 819T214 829T208 840T199 853T185 866T166 878T140 887T107 893T66 896H56V950H1221V896H1211Q1080 896 1058 812V-311Q1076 -396 1211 -396H1221V-450H725V-396H735Q864 -396 888 -314Q889 -312 889 -311V896H388V292L389 -311Q405 -396 542 -396H552V-450H56V-396H66Q195 -396 219 -314Q220 -312 220 -311V812Z"></path></g><g data-mml-node="TeXAtom" transform="translate(65.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(426.9,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mi" transform="translate(4631.2,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mo" transform="translate(5134.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(5523.2,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(6319.2,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(6597.2,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(7502.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(7947.4,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(8392.1,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(8836.7,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(9281.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(9726.1,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(502,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(11425.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g>',1)]))),Q[1]||(Q[1]=T("mjx-assistive-mml",{unselectable:"on",display:"block"},[T("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[T("mi",null,"p"),T("mo",{stretchy:"false"},"("),T("mi",null,"x"),T("mo",{stretchy:"false"},")"),T("mo",null,"="),T("munderover",null,[T("mo",{"data-mjx-texclass":"OP"},"∏"),T("mrow",{"data-mjx-texclass":"ORD"},[T("mi",null,"i"),T("mo",null,"="),T("mn",null,"1")]),T("mrow",{"data-mjx-texclass":"ORD"},[T("mi",null,"n")])]),T("mi",null,"p"),T("mo",{stretchy:"false"},"("),T("msub",null,[T("mi",null,"s"),T("mi",null,"i")]),T("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),T("msub",null,[T("mi",null,"s"),T("mn",null,"1")]),T("mo",null,","),T("mo",null,"."),T("mo",null,"."),T("mo",null,"."),T("mo",null,","),T("msub",null,[T("mi",null,"s"),T("mrow",{"data-mjx-texclass":"ORD"},[T("mi",null,"i"),T("mo",null,"−"),T("mn",null,"1")])]),T("mo",{stretchy:"false"},")")])],-1))]),Q[25]||(Q[25]=T("p",null,[t("这一框架允许模型不仅生成文本，还能计算任意条件概率，例如预测缺失的单词或句子。近年来，"),T("strong",null,"Transformer"),t(" 架构（Vaswani et al., 2017）的引入显著提升了语言模型的表达能力，使其能够建模长距离依赖关系。")],-1)),Q[26]||(Q[26]=T("hr",null,null,-1)),Q[27]||(Q[27]=T("p",null,[T("strong",null,"2. 多任务学习的概率视角")],-1)),T("p",null,[Q[6]||(Q[6]=t("传统监督学习通常建模 ")),T("mjx-container",h,[(l(),n("svg",u,Q[2]||(Q[2]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mo" transform="translate(503,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(892,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1377,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1949,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(2310,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2813,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3385,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(3746,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(4024,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4369,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4969,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(5472,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6044,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(6405,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g>',1)]))),Q[3]||(Q[3]=T("mjx-assistive-mml",{unselectable:"on",display:"inline"},[T("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[T("mi",null,"p"),T("mo",{stretchy:"false"},"("),T("mi",null,"o"),T("mi",null,"u"),T("mi",null,"t"),T("mi",null,"p"),T("mi",null,"u"),T("mi",null,"t"),T("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),T("mi",null,"i"),T("mi",null,"n"),T("mi",null,"p"),T("mi",null,"u"),T("mi",null,"t"),T("mo",{stretchy:"false"},")")])],-1))]),Q[7]||(Q[7]=t("，而通用系统需要能够根据任务描述动态调整行为，即建模 ")),T("mjx-container",H,[(l(),n("svg",L,Q[4]||(Q[4]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mo" transform="translate(503,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(892,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1377,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1949,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(2310,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(2813,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3385,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(3746,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(4024,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4369,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(4969,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(5472,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6044,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(6405,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(6849.7,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(7210.7,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(7739.7,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(8208.7,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(8729.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g>',1)]))),Q[5]||(Q[5]=T("mjx-assistive-mml",{unselectable:"on",display:"inline"},[T("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[T("mi",null,"p"),T("mo",{stretchy:"false"},"("),T("mi",null,"o"),T("mi",null,"u"),T("mi",null,"t"),T("mi",null,"p"),T("mi",null,"u"),T("mi",null,"t"),T("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),T("mi",null,"i"),T("mi",null,"n"),T("mi",null,"p"),T("mi",null,"u"),T("mi",null,"t"),T("mo",null,","),T("mi",null,"t"),T("mi",null,"a"),T("mi",null,"s"),T("mi",null,"k"),T("mo",{stretchy:"false"},")")])],-1))]),Q[8]||(Q[8]=t("。作者指出，McCann et al. (2018) 的")),Q[9]||(Q[9]=T("strong",null,"MQAN（Multi-task Question Answering Network）",-1)),Q[10]||(Q[10]=t(" 已经证明，任务可以通过自然语言描述（如“translate to French, English text, French text”）来指定。本文进一步假设，")),Q[11]||(Q[11]=T("strong",null,"语言模型本身可以通过观察任务的自然语言演示（如问答对、翻译示例）来隐式学习任务，而无需显式监督",-1)),Q[12]||(Q[12]=t("。"))]),Q[28]||(Q[28]=a("<hr><p><strong>3. 训练数据集：WebText</strong></p><p>为了训练一个能够泛化到多种任务的语言模型，论文构建了一个新的数据集 <strong>WebText</strong>，其关键特点是：</p><ul><li><p><strong>数据来源</strong>：从 Reddit 上爬取高赞（≥3 karma）的外链网页，确保内容经过人工筛选，质量高于 Common Crawl 等原始网络数据。</p></li><li><p><strong>规模与处理</strong>：初步版本包含约800万篇文档（40GB文本），去重并移除了 Wikipedia 数据以避免测试集污染。</p></li><li><p><strong>多样性目标</strong>：涵盖广泛的主题和写作风格，以增加模型接触不同任务（如翻译、摘要）自然演示的机会。</p></li></ul><hr><p><strong>4. 输入表示：改进的字节对编码（BPE）</strong></p><p>传统语言模型通常依赖单词或字符级输入，但存在词汇表限制或效率问题。本文采用<strong>字节级 BPE（Byte Pair Encoding）</strong>，其优势包括：</p><ul><li><p><strong>词汇表灵活性</strong>：基础词汇仅需256个字节，可表示任意 Unicode 字符串，避免传统 BPE 对 Unicode 编码的冗余扩展（如130,000+基词）。</p></li><li><p><strong>改进的合并策略</strong>：防止跨字符类别的合并（如“dog”与“dog!”被分开），减少词汇碎片化，同时允许空格合并以提高压缩效率。</p></li><li><p><strong>兼容性</strong>：支持对任何文本（无论预处理方式）直接计算概率，便于跨数据集评估。</p></li></ul><hr><p><strong>5. 模型架构：GPT-2 的改进</strong></p><p>GPT-2 基于 <strong>Transformer</strong> 架构，延续了 GPT-1（Radford et al., 2018）的设计，但进行了以下优化：</p>",11)),T("ul",null,[Q[21]||(Q[21]=T("li",null,[T("p",null,[T("strong",null,"层归一化调整"),t("：移至每个子模块的输入（类似预激活残差网络），并在最终自注意力块后增加额外层归一化。")])],-1)),T("li",null,[T("p",null,[Q[17]||(Q[17]=T("strong",null,"初始化优化",-1)),Q[18]||(Q[18]=t("：残差层权重按 ")),T("mjx-container",c,[(l(),n("svg",f,Q[13]||(Q[13]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(500,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="msqrt" transform="translate(1000,0)"><g transform="translate(853,0)"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g><g data-mml-node="mo" transform="translate(0,109)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path></g><rect width="888" height="60" x="853" y="849"></rect></g></g></g>',1)]))),Q[14]||(Q[14]=T("mjx-assistive-mml",{unselectable:"on",display:"inline"},[T("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[T("mn",null,"1"),T("mrow",{"data-mjx-texclass":"ORD"},[T("mo",null,"/")]),T("msqrt",null,[T("mi",null,"N")])])],-1))]),Q[19]||(Q[19]=t(" 缩放（")),T("mjx-container",M,[(l(),n("svg",x,Q[15]||(Q[15]=[T("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[T("g",{"data-mml-node":"math"},[T("g",{"data-mml-node":"mi"},[T("path",{"data-c":"1D441",d:"M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"})])])],-1)]))),Q[16]||(Q[16]=T("mjx-assistive-mml",{unselectable:"on",display:"inline"},[T("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[T("mi",null,"N")])],-1))]),Q[20]||(Q[20]=t(" 为残差层数），缓解深层网络的梯度问题。"))])]),Q[22]||(Q[22]=T("li",null,[T("p",null,[T("strong",null,"扩展配置"),t("：词汇表增至50,257，上下文窗口从512扩展到1024 tokens，批大小提升至512。")])],-1))]),Q[29]||(Q[29]=a('<hr><p><strong>6. 实验设置与模型规模</strong></p><p>论文训练了 <strong>4种不同规模的模型</strong>（参数从117M到1.5B），以研究模型容量对性能的影响：</p><ul><li><p>最小模型（117M）与原始 GPT 相当，中等模型（345M）匹配 BERT-Large，最大模型 <strong>GPT-2（1.5B）</strong> 参数量远超 GPT-1。</p></li><li><p>所有模型在 WebText 上仍表现欠拟合（held-out perplexity 持续下降），表明进一步扩大数据或模型可能提升性能。</p></li></ul><hr><p><strong>7. 任务执行的零样本机制</strong></p><p>GPT-2 的零样本能力依赖于<strong>任务提示（Task Prompting）</strong>，即通过自然语言描述或示例引导模型生成目标输出。例如：</p><ul><li><p><strong>翻译任务</strong>：输入“english sentence = french sentence”示例后，模型在“english sentence =”提示下生成翻译。</p></li><li><p><strong>摘要任务</strong>：在文章末尾添加“TL;DR:”触发摘要生成。</p></li><li><p><strong>问答任务</strong>：输入文档+对话历史+“A:”引导答案生成。</p></li></ul><p><mark><strong>这种方法无需微调，完全依赖语言模型对任务上下文的理解能力</strong>。</mark></p><hr><p><strong>总结</strong></p><ol><li><p><strong>无监督多任务学习的可行性证明</strong>：语言模型通过预测多样化文本中的任务演示（如翻译对、问答），隐式学习任务逻辑。</p></li><li><p><strong>数据与架构创新</strong>：WebText 的高质量数据、字节级 BPE 的通用性，以及 GPT-2 的规模化改进，共同支撑了零样本泛化能力。</p></li><li><p><strong>任务提示的关键作用</strong>：自然语言指令可作为隐式任务描述，激活模型的相关能力。</p></li></ol><p>这些设计使 GPT-2 成为首个在零样本设置下接近监督模型性能的大规模语言模型，为后续研究（如 GPT-3 的少样本学习）奠定了基础。</p><h2 id="实验" tabindex="-1"><a class="header-anchor" href="#实验"><span>实验</span></a></h2><p><strong>1. 实验设计与模型配置</strong></p><p>论文系统评估了不同规模的GPT-2模型（117M、345M、762M和1.5B参数）在多个NLP任务上的零样本（zero-shot）性能。所有模型均采用相同的架构，但层数、隐藏层维度和参数量不同（见表2）。实验的关键发现是：<strong>模型容量与任务性能呈对数线性关系</strong>，更大的模型在几乎所有任务上都显著优于小模型。作者特别指出，即使是最大的1.5B模型，在WebText验证集上仍未完全收敛（underfitting），表明进一步扩大模型和数据规模可能带来额外提升。</p><figure><img src="'+s+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>2. 语言建模任务评估</strong></p><p>GPT-2在8个标准语言建模数据集上进行了测试，包括Penn Treebank（PTB）、WikiText-2、LAMBADA等。结果显示：</p><ul><li><p><strong>跨领域泛化能力</strong>：GPT-2在7/8的数据集上刷新了零样本SOTA，特别是在小数据集（如PTB）和长程依赖任务（如LAMBADA）上提升显著。</p></li><li><p><strong>预处理的影响</strong>：由于GPT-2使用字节级BPE，可以避免传统tokenization的损失。通过可逆去token化（invertible detokenizers）处理，GPT-2的困惑度（perplexity）进一步降低了2.5-5点。</p></li><li><p><strong>例外情况</strong>：在One Billion Word Benchmark（1BW）上表现较差，作者归因于该数据集的句子级打乱破坏了长程依赖。</p></li></ul><hr><p><strong>3. 具体任务表现分析</strong></p><p><strong>3.1 Children&#39;s Book Test（CBT）</strong></p><p>CBT测试模型对不同词类（命名实体、名词等）的预测能力。GPT-2在验证集（避免与WebText重叠）上达到：</p><ul><li><p>常见名词准确率93.3%（原SOTA 85.7%）</p></li><li><p>命名实体准确率89.1%（原SOTA 82.3%）</p></li></ul><p>分析表明，<strong>模型容量增加直接缩小了与人类表现的差距</strong>（图2）。</p><figure><img src="'+e+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>3.2 LAMBADA</strong></p><p>该任务要求预测句子的最后一个词，需要至少50个token的上下文理解。GPT-2将：</p><ul><li><p>困惑度从99.8降至8.6</p></li><li><p>准确率从19%提升至52.66%</p></li></ul><p>通过添加停用词过滤器（避免生成非结尾词），准确率进一步提升至63.24%，超过此前需依赖上下文词约束的SOTA方法。</p><hr><p><strong>3.3 Winograd Schema Challenge</strong></p><p>测试常识推理能力（共273个样例）。GPT-2以70.7%的准确率超越前SOTA（Trinh &amp; Le, 2018）7个百分点。作者指出，尽管数据集小，但结果与人类表现（约95%）的差距已显著缩小。</p><hr><p><strong>3.4 阅读理解（CoQA）</strong></p><p>在对话式问答数据集上，GPT-2仅通过文档+历史对话+“A:”提示生成答案，达到55 F1：</p><ul><li><p>匹配或超过3/4监督基线的性能</p></li><li><p>但远低于人类（89 F1）和BERT SOTA</p></li></ul><p>错误分析显示，模型倾向于使用简单的检索启发式（如用文档中的人名回答&quot;who&quot;问题）。</p><hr><p><strong>3.5 摘要生成（CNN/Daily Mail）</strong></p><p>通过“TL;DR:”提示+Top-k采样（k=2）生成摘要：</p><ul><li><p>ROUGE分数仅略高于随机选句基线</p></li><li><p>但定性分析显示生成内容类似摘要, 移除提示后性能下降6.4点，证明自然语言指令可激活任务特定行为。</p></li></ul><hr><p><strong>3.6 翻译（WMT-14）</strong></p><p>尽管WebText几乎无平行语料，GPT-2通过示例提示：</p><ul><li><p>英→法：5 BLEU（低于词对齐基线）</p></li><li><p>法→英：11.5 BLEU（超过部分无监督方法）</p></li></ul><p>作者推测英语语言模型的强大概率补偿了翻译知识的不足。</p><hr><p><strong>3.7 问答（Natural Questions）</strong></p><p>在事实型问答测试中：</p><ul><li><p>精确匹配准确率4.1%（远低于监督系统30-50%）</p></li><li><p>但对高置信度预测（top 1%），准确率达63.1%</p></li></ul><p>表明模型容量是限制因素（最小模型仅1.0%准确率）。</p><hr><p><strong>4. 记忆与泛化分析</strong></p><p><strong>4.1 数据重叠检测</strong></p><p>使用Bloom过滤器统计测试集与WebText的8-gram重叠率：</p><ul><li><p>平均重叠率3.2%（与常规训练-测试重叠率5.9%相比更低）</p></li><li><p>极端案例：WikiText-103测试集1.6%重叠（因文章复用段落）</p></li><li><p>对性能影响：LAMBADA去除重叠样本后，困惑度仅从8.6→8.7</p></li></ul><p><strong>4.2 训练集与测试集性能对比</strong></p><p>图4显示，WebText训练集和测试集的困惑度同步下降，表明：</p><ul><li><p>即使1.5B模型仍欠拟合</p></li><li><p>性能提升非源于记忆，而是真实泛化能力</p></li></ul><figure><img src="'+m+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>4.3 生成样本分析</strong></p><p>表13展示GPT-2在非分布数据（如“独角兽新闻”）上的生成能力：</p><ul><li><p>能生成连贯但虚构的内容</p></li><li><p>证实模型并非简单记忆，而是组合学到的知识</p></li></ul><figure><img src="'+p+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><hr><p><strong>5. 实验结论</strong></p><ol><li><p><strong>规模定律</strong>：模型容量与零样本性能强相关，1.5B参数模型在多数任务上逼近或超越监督基线。</p></li><li><p><strong>任务通用性</strong>：单一语言模型可处理翻译、问答、摘要等多样化任务，仅需自然语言提示。</p></li><li><p><strong>数据质量</strong>：WebText的多样性和规模是关键，但数据重叠对结果影响有限。</p></li><li><p><strong>局限性</strong>：摘要、翻译等任务表现仍远逊于专业系统，显示无监督学习的当前边界。</p></li></ol><p>这些实验为后续研究（如GPT-3的少样本学习）提供了重要基准，证明无监督预训练在多任务迁移中的巨大潜力。</p><h2 id="讨论" tabindex="-1"><a class="header-anchor" href="#讨论"><span>讨论</span></a></h2><p>无监督任务学习作为预训练技术成功的关键因素。研究表明，<mark><strong>当语言模型在足够多样化的文本数据上训练时，能够通过预测任务的自然语言演示（如翻译对、问答示例）隐式学习任务逻辑，而无需显式监督</strong></mark>。这一发现为理解当前预训练模型的有效性提供了新视角，并表明在<strong>极限情况下，语言模型可能直接学会执行任务</strong>。</p><p>作者同时指出GPT-2的局限性：虽然在阅读理解等任务上接近监督基线，但在摘要、翻译等任务上的表现仍远未达到实用水平。这种性能差异揭示了当前方法的边界，<strong>表明模型容量和训练数据规模仍需进一步扩大</strong>。特别值得注意的是，<strong>GPT-2的完全抽象式输出（如问答时生成而非抽取答案）与传统指针网络方法形成鲜明对比，这为未来探索更灵活的文本生成方式提供了启示</strong>。</p><p>未来研究方向，包括探索GPT-2的微调潜力（如在GLUE等基准上的表现），以及研究双向表示（如BERT）与单向语言模型的互补性。这些发现为后续GPT-3等更大规模模型的开发奠定了基础，推动学界重新思考语言模型在多任务学习中的角色。</p><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><p>本文通过GPT-2模型证明了大规模语言模型在无监督多任务学习中的强大潜力。<strong>当模型在足够大且多样化的文本数据（WebText）上训练时，仅通过语言建模目标就能在零样本设置下完成多种NLP任务，并在7/8的语言建模基准上达到SOTA水平</strong>。这一发现表明，<strong>高容量模型通过最大化文本序列的似然估计，可以自发地学习执行任务，而无需明确的监督信号</strong>。</p><p>研究结果对构建通用语言系统具有重要意义：<strong>首先，它验证了单一模型架构通过规模扩展即可实现多任务处理的可能性；其次，展示了自然语言本身作为任务描述符的有效性。尽管当前零样本性能仍有限，但这一方向为减少对人工标注数据的依赖提供了新思路。</strong></p><p>最后，论文指出这仅是通向更通用AI系统的初步探索。作者开放了模型代码和小型预训练模型，鼓励后续研究继续探索更大规模语言模型的行为边界，以及如何更好地利用其隐含学习到的多任务能力。这项工作为后续GPT系列模型的发展奠定了理论基础和方法框架。</p>',80))])}const P=r(i,[["render",Z]]),y=JSON.parse('{"path":"/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/GPT-2%E8%AE%BA%E6%96%87.html","title":"GPT-2 论文","lang":"zh-CN","frontmatter":{"title":"GPT-2 论文","icon":"file","category":["NLP"],"tag":["预训练语言模型","已发布"],"footer":"技术共建，知识共享","date":"2025-06-25T00:00:00.000Z","order":2,"author":["BinaryOracle"],"description":"GPT-2 论文","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"GPT-2 论文\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-06-25T00:00:00.000Z\\",\\"dateModified\\":\\"2025-06-26T05:48:54.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"BinaryOracle\\"}]}"],["meta",{"property":"og:url","content":"https://mister-hope.github.io/LLM/%E6%A8%A1%E5%9E%8B%E5%B1%82/GPT-2%E8%AE%BA%E6%96%87.html"}],["meta",{"property":"og:site_name","content":"MetaMind"}],["meta",{"property":"og:title","content":"GPT-2 论文"}],["meta",{"property":"og:description","content":"GPT-2 论文"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-06-26T05:48:54.000Z"}],["meta",{"property":"article:author","content":"BinaryOracle"}],["meta",{"property":"article:tag","content":"已发布"}],["meta",{"property":"article:tag","content":"预训练语言模型"}],["meta",{"property":"article:published_time","content":"2025-06-25T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-06-26T05:48:54.000Z"}]]},"git":{"createdTime":1750914390000,"updatedTime":1750916934000,"contributors":[{"name":"BinaryOracle","username":"BinaryOracle","email":"3076679680@qq.com","commits":3,"url":"https://github.com/BinaryOracle"}]},"readingTime":{"minutes":14.24,"words":4272},"filePathRelative":"LLM/模型层/GPT-2论文.md","excerpt":"<p><code>GPT-2 论文</code></p>\\n","autoDesc":true}');export{P as comp,y as data};
