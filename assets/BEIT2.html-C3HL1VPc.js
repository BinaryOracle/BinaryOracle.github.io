import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as r,a as t,e as a,f as i,o as n}from"./app-DS4Vnp6_.js";const p="/assets/1-C82pM5q7.png",l={};function c(s,e){return n(),r("div",null,[e[0]||(e[0]=t("p",null,[t("code",null,"BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers 论文解读")],-1)),a(" more "),e[1]||(e[1]=i('<blockquote><p>论文链接: <a href="https://arxiv.org/abs/2208.06366" target="_blank" rel="noopener noreferrer">BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers</a><br> 代码链接: <a href="https://github.com/microsoft/unilm/tree/master/beit2" target="_blank" rel="noopener noreferrer">https://github.com/microsoft/unilm/tree/master/beit2</a></p></blockquote><h2 id="引言" tabindex="-1"><a class="header-anchor" href="#引言"><span>引言</span></a></h2><p>掩码图像建模（MIM）通过恢复被掩码的图像块，能够在自监督学习中捕捉丰富的上下文信息，但大多数方法仅在低层像素上操作。</p><p>现有重建目标可以分为三类：</p><ul><li><p>低层图像元素（如原始像素）</p></li><li><p>手工特征（如 HOG 特征）</p></li><li><p>视觉 token</p></li></ul><p>这些方法大多忽略了高层语义信息，而语言模型中的掩码词都是高层语义，这启发了 MIM 可以借助语义感知监督进行改进。</p><figure><img src="'+p+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>BEIT V2</strong> 提出 <strong>向量量化知识蒸馏（VQ-KD）</strong>，将连续的语义空间离散化为紧凑的视觉 token。VQ-KD 训练过程：</p><ol><li><p>编码器将输入图像转为离散 token，基于可学习码本（codebook）。</p></li><li><p>解码器根据教师模型编码的语义特征重建图像特征。</p></li></ol><p>训练完成后，VQ-KD 的编码器被用作 BEIT V2 的语义视觉分词器，离散 token 作为监督信号进行 MIM 预训练。引入 <strong>图像块聚合策略</strong>，让 [CLS] token 聚合全局信息，解决传统 MIM 过度关注局部块重建而忽略全局表示的问题。</p>',10))])}const g=o(l,[["render",c]]),u=JSON.parse('{"path":"/MMLLM/BEIT2.html","title":"BEIT2 论文","lang":"zh-CN","frontmatter":{"title":"BEIT2 论文","icon":"file","category":["多模态"],"tag":["多模态","编辑中"],"footer":"技术共建，知识共享","date":"2025-08-17T00:00:00.000Z","author":["BinaryOracle"],"description":"BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers 论文解读","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"BEIT2 论文\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-08-17T00:00:00.000Z\\",\\"dateModified\\":\\"2025-08-22T01:37:22.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"BinaryOracle\\"}]}"],["meta",{"property":"og:url","content":"https://mister-hope.github.io/MMLLM/BEIT2.html"}],["meta",{"property":"og:site_name","content":"MetaMind"}],["meta",{"property":"og:title","content":"BEIT2 论文"}],["meta",{"property":"og:description","content":"BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers 论文解读"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-22T01:37:22.000Z"}],["meta",{"property":"article:author","content":"BinaryOracle"}],["meta",{"property":"article:tag","content":"编辑中"}],["meta",{"property":"article:tag","content":"多模态"}],["meta",{"property":"article:published_time","content":"2025-08-17T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-22T01:37:22.000Z"}]]},"git":{"createdTime":1755436780000,"updatedTime":1755826642000,"contributors":[{"name":"BinaryOracle","username":"BinaryOracle","email":"3076679680@qq.com","commits":3,"url":"https://github.com/BinaryOracle"}]},"readingTime":{"minutes":1.25,"words":374},"filePathRelative":"MMLLM/BEIT2.md","excerpt":"<p><code>BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers 论文解读</code></p>\\n","autoDesc":true}');export{g as comp,u as data};
