<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"ViLT 论文","image":[""],"datePublished":"2025-06-15T00:00:00.000Z","dateModified":"2025-07-15T03:27:26.000Z","author":[{"@type":"Person","name":"BinaryOracle"}]}</script><meta property="og:url" content="https://mister-hope.github.io/MMLLM/ViLT.html"><meta property="og:site_name" content="MetaMind"><meta property="og:title" content="ViLT 论文"><meta property="og:description" content="ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision 论文简析"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-07-15T03:27:26.000Z"><meta property="article:author" content="BinaryOracle"><meta property="article:tag" content="已发布"><meta property="article:tag" content="多模态"><meta property="article:published_time" content="2025-06-15T00:00:00.000Z"><meta property="article:modified_time" content="2025-07-15T03:27:26.000Z"><title>ViLT 论文 | MetaMind</title><meta name="description" content="ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision 论文简析">
    <link rel="preload" href="/assets/style-B9ka0LB5.css" as="style"><link rel="stylesheet" href="/assets/style-B9ka0LB5.css">
    <link rel="modulepreload" href="/assets/app-hy09JEJM.js"><link rel="modulepreload" href="/assets/ViLT.html-BQkWHXzp.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-CHLxZHa9.js" as="script"><link rel="prefetch" href="/assets/intro.html-Dznxr0ZI.js" as="script"><link rel="prefetch" href="/assets/3D_affordance_grounding.html-B7N_jhE2.js" as="script"><link rel="prefetch" href="/assets/GEAL.html-DtqGBcO0.js" as="script"><link rel="prefetch" href="/assets/GREAT.html-B-sIyDeX.js" as="script"><link rel="prefetch" href="/assets/Grounding_3D_Object_Affordance.html-C2jXTu7J.js" as="script"><link rel="prefetch" href="/assets/IAGNet.html-CgNXXcqE.js" as="script"><link rel="prefetch" href="/assets/LASO.html-BBNOM82L.js" as="script"><link rel="prefetch" href="/assets/PointTransformer.html-DN2Ft1Xf.js" as="script"><link rel="prefetch" href="/assets/PointTransformerV2.html-7kucdDDb.js" as="script"><link rel="prefetch" href="/assets/index.html-XGBhLPgm.js" as="script"><link rel="prefetch" href="/assets/SeqAfford.html-DTfTDrol.js" as="script"><link rel="prefetch" href="/assets/SpatialLM.html-CzYU1y6q.js" as="script"><link rel="prefetch" href="/assets/简析PointNet__.html-B6oydXkn.js" as="script"><link rel="prefetch" href="/assets/简析PointNet.html-BDEDUwOi.js" as="script"><link rel="prefetch" href="/assets/index.html-hKYDAKjs.js" as="script"><link rel="prefetch" href="/assets/ BLIP.html-C-xnVwP4.js" as="script"><link rel="prefetch" href="/assets/ALBEF.html-CtOZcjXM.js" as="script"><link rel="prefetch" href="/assets/BEIT2.html-ChLN1_9T.js" as="script"><link rel="prefetch" href="/assets/BEIT3.html-BWfF4_-W.js" as="script"><link rel="prefetch" href="/assets/BEiT.html-k7p27ez2.js" as="script"><link rel="prefetch" href="/assets/BEiT模型代码解读.html-Bm4rcOcT.js" as="script"><link rel="prefetch" href="/assets/CoCa.html-BolZQ6xQ.js" as="script"><link rel="prefetch" href="/assets/DINO.html-B59G8eYZ.js" as="script"><link rel="prefetch" href="/assets/InternVL-1.0.html-B5auDmUD.js" as="script"><link rel="prefetch" href="/assets/InternVl-1.5.html-D0dBAobe.js" as="script"><link rel="prefetch" href="/assets/LLaVA_1.0.html-BoQpu8kr.js" as="script"><link rel="prefetch" href="/assets/MoCo.html-CSoyy3JK.js" as="script"><link rel="prefetch" href="/assets/index.html-BgkRMv-M.js" as="script"><link rel="prefetch" href="/assets/Unified-IO.html-uqsYa88T.js" as="script"><link rel="prefetch" href="/assets/VLMo.html-y5tC4OnO.js" as="script"><link rel="prefetch" href="/assets/VLMo代码解读.html-B4NdVi51.js" as="script"><link rel="prefetch" href="/assets/多模态常用改编Bert实现.html-Bf7U73wj.js" as="script"><link rel="prefetch" href="/assets/多模态模型CLIP原理与图片分类，文字搜索图像实战演练.html-BXvrMGDH.js" as="script"><link rel="prefetch" href="/assets/庖丁解牛BLIP2.html-ChWz07vS.js" as="script"><link rel="prefetch" href="/assets/庖丁解牛VIT.html-6U3dwGG8.js" as="script"><link rel="prefetch" href="/assets/index.html-DEI76k_o.js" as="script"><link rel="prefetch" href="/assets/API记录之Numpy篇.html-xrYemma4.js" as="script"><link rel="prefetch" href="/assets/API记录之Python篇.html-DBb_nGca.js" as="script"><link rel="prefetch" href="/assets/API记录之Pytorch篇.html-Gzb4ndaV.js" as="script"><link rel="prefetch" href="/assets/API记录之杂类篇.html-bc0oc4lT.js" as="script"><link rel="prefetch" href="/assets/API记录之框架篇.html-DC3mG49l.js" as="script"><link rel="prefetch" href="/assets/API记录之训练细节篇.html-KFigmzYS.js" as="script"><link rel="prefetch" href="/assets/Attention运算过程中维度变换的理解.html-DzkXLQep.js" as="script"><link rel="prefetch" href="/assets/Pytorch张量存储与访问原理.html-PTqKCeMY.js" as="script"><link rel="prefetch" href="/assets/index.html-Cob9i95l.js" as="script"><link rel="prefetch" href="/assets/conda虚拟环境管理.html-BUBK4COd.js" as="script"><link rel="prefetch" href="/assets/常用评估指标.html-BuQ4bCjt.js" as="script"><link rel="prefetch" href="/assets/数学知识点.html-Drw6uQN0.js" as="script"><link rel="prefetch" href="/assets/注意力图可视化.html-BUeBEEPH.js" as="script"><link rel="prefetch" href="/assets/语义分割中常用的损失函数.html-9HVBHI4D.js" as="script"><link rel="prefetch" href="/assets/通俗易懂解读BPE分词算法实现.html-QJMpdkUJ.js" as="script"><link rel="prefetch" href="/assets/index.html-CMMEYtMq.js" as="script"><link rel="prefetch" href="/assets/Fine_Tuning知识扫盲.html-CPDuLp7l.js" as="script"><link rel="prefetch" href="/assets/LoRA微调系列.html-U0sYjBgJ.js" as="script"><link rel="prefetch" href="/assets/Prompt_Engineering知识扫盲.html-CuY9jkse.js" as="script"><link rel="prefetch" href="/assets/index.html-BlRdSUlX.js" as="script"><link rel="prefetch" href="/assets/GPT-1论文.html-AW27l9XL.js" as="script"><link rel="prefetch" href="/assets/GPT-2论文.html-Chuez71Q.js" as="script"><link rel="prefetch" href="/assets/GPT-3论文.html-ByXON3g2.js" as="script"><link rel="prefetch" href="/assets/InstructGPT论文.html-BpthS-aG.js" as="script"><link rel="prefetch" href="/assets/KV-Cache.html-y8xD5leq.js" as="script"><link rel="prefetch" href="/assets/LLaMA-1论文.html-BfLadJdl.js" as="script"><link rel="prefetch" href="/assets/LLaMA-2论文.html-BptxJBqa.js" as="script"><link rel="prefetch" href="/assets/index.html-C1aL5Ea5.js" as="script"><link rel="prefetch" href="/assets/RoBERTa论文.html-CGuhB2FG.js" as="script"><link rel="prefetch" href="/assets/从零实现Bert.html-B6FlMtZa.js" as="script"><link rel="prefetch" href="/assets/位置编码.html-BFvAS4iG.js" as="script"><link rel="prefetch" href="/assets/图解BERT.html-Bz6TK4Sp.js" as="script"><link rel="prefetch" href="/assets/图解Transformer.html-VRSDS9cX.js" as="script"><link rel="prefetch" href="/assets/1.自动微分.html-BnSuV3ua.js" as="script"><link rel="prefetch" href="/assets/2.用自然的代码表达.html-DTTyd3h1.js" as="script"><link rel="prefetch" href="/assets/3.高阶导数.html-DS9IB6pM.js" as="script"><link rel="prefetch" href="/assets/4.神经网络.html-Dc_A6wMA.js" as="script"><link rel="prefetch" href="/assets/index.html-Cuzc_yg8.js" as="script"><link rel="prefetch" href="/assets/1.前置知识.html-CA1aBAHN.js" as="script"><link rel="prefetch" href="/assets/2.大模型API.html-BW9C9cRM.js" as="script"><link rel="prefetch" href="/assets/index.html-B7FuUvwt.js" as="script"><link rel="prefetch" href="/assets/index.html-DbO4INg0.js" as="script"><link rel="prefetch" href="/assets/LNM—LC.html-BepkQ0pi.js" as="script"><link rel="prefetch" href="/assets/NCR.html-BrlJSgPp.js" as="script"><link rel="prefetch" href="/assets/index.html-H561Kgv8.js" as="script"><link rel="prefetch" href="/assets/论文速览.html-ClbFMZ2h.js" as="script"><link rel="prefetch" href="/assets/index.html-BHGHxtsf.js" as="script"><link rel="prefetch" href="/assets/index.html-B2SLOlM1.js" as="script"><link rel="prefetch" href="/assets/index.html-WZEUmXYg.js" as="script"><link rel="prefetch" href="/assets/基础概念.html-CLiXYEo0.js" as="script"><link rel="prefetch" href="/assets/基础模型.html-DwspzxVn.js" as="script"><link rel="prefetch" href="/assets/组合分析.html-BRyp4obY.js" as="script"><link rel="prefetch" href="/assets/DALL-E论文.html-BaGD4WiG.js" as="script"><link rel="prefetch" href="/assets/DALL·E模型代码解读.html-ouFhV4Yz.js" as="script"><link rel="prefetch" href="/assets/GAN学习笔记.html-CRR7OyVS.js" as="script"><link rel="prefetch" href="/assets/PixelCNN.html-CmI113e7.js" as="script"><link rel="prefetch" href="/assets/Pytorch实现VAE和CVAE.html-BfIjq6En.js" as="script"><link rel="prefetch" href="/assets/index.html-CxwkO5J0.js" as="script"><link rel="prefetch" href="/assets/Tutorial_VAE.html-Yuyqr-Mw.js" as="script"><link rel="prefetch" href="/assets/VQ-VAE.html-DWcLO8IR.js" as="script"><link rel="prefetch" href="/assets/WGAN.html-Bkx80oBb.js" as="script"><link rel="prefetch" href="/assets/404.html-DaT5c3ft.js" as="script"><link rel="prefetch" href="/assets/index.html-DEl45FzE.js" as="script"><link rel="prefetch" href="/assets/index.html-JxbbBKtq.js" as="script"><link rel="prefetch" href="/assets/index.html-B68uYyHR.js" as="script"><link rel="prefetch" href="/assets/index.html-Dk2FyLWM.js" as="script"><link rel="prefetch" href="/assets/index.html-CmbfPJPb.js" as="script"><link rel="prefetch" href="/assets/index.html-CyJOo-TH.js" as="script"><link rel="prefetch" href="/assets/index.html-_SX_rJn4.js" as="script"><link rel="prefetch" href="/assets/index.html-CnZwV6Dc.js" as="script"><link rel="prefetch" href="/assets/index.html-CDWSx4Nh.js" as="script"><link rel="prefetch" href="/assets/index.html-BfDQJt9L.js" as="script"><link rel="prefetch" href="/assets/index.html-iAaj-DcS.js" as="script"><link rel="prefetch" href="/assets/index.html-qZQO4AKM.js" as="script"><link rel="prefetch" href="/assets/index.html-CRNA0dSk.js" as="script"><link rel="prefetch" href="/assets/index.html-ChwOiDBs.js" as="script"><link rel="prefetch" href="/assets/index.html-DHBgFajR.js" as="script"><link rel="prefetch" href="/assets/index.html-B97r08LN.js" as="script"><link rel="prefetch" href="/assets/index.html-Cxam9Zzc.js" as="script"><link rel="prefetch" href="/assets/index.html-wiGGb_Ct.js" as="script"><link rel="prefetch" href="/assets/index.html-D5OtiGhU.js" as="script"><link rel="prefetch" href="/assets/index.html-Ct9-11gq.js" as="script"><link rel="prefetch" href="/assets/index.html-B04Pl3LW.js" as="script"><link rel="prefetch" href="/assets/index.html-DS5sozZK.js" as="script"><link rel="prefetch" href="/assets/index.html-Dq91Uyjh.js" as="script"><link rel="prefetch" href="/assets/index.html-kWp5xCpI.js" as="script"><link rel="prefetch" href="/assets/index.html-BLqHUXgH.js" as="script"><link rel="prefetch" href="/assets/index.html-Dce3pCBJ.js" as="script"><link rel="prefetch" href="/assets/index.html-DOCgu0Wx.js" as="script"><link rel="prefetch" href="/assets/index.html-kfldCuHd.js" as="script"><link rel="prefetch" href="/assets/index.html-B2_mfPwN.js" as="script"><link rel="prefetch" href="/assets/index.html-FEw2Lw7D.js" as="script"><link rel="prefetch" href="/assets/index.html-DtHdRDPQ.js" as="script"><link rel="prefetch" href="/assets/index.html-oaMXoH4w.js" as="script"><link rel="prefetch" href="/assets/index.html-6eK5Hhb3.js" as="script"><link rel="prefetch" href="/assets/index.html-DES9SKPt.js" as="script"><link rel="prefetch" href="/assets/index.html-DsnQHZnF.js" as="script"><link rel="prefetch" href="/assets/index.html-D6PKESe-.js" as="script"><link rel="prefetch" href="/assets/index.html-BGLV2Gf6.js" as="script"><link rel="prefetch" href="/assets/index.html-ByKtOjLZ.js" as="script"><link rel="prefetch" href="/assets/index.html-CMLEDVcP.js" as="script"><link rel="prefetch" href="/assets/index.html-CJsqMcxI.js" as="script"><link rel="prefetch" href="/assets/index.html-bpFT8d5V.js" as="script"><link rel="prefetch" href="/assets/index-BzBQJFYZ.js" as="script"><link rel="prefetch" href="/assets/flowchart-BKGBxuOE.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-DmBdXm53.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/SearchResult-BnhDbSgd.js" as="script"><link rel="prefetch" href="/assets/waline-meta-l0sNRNKZ.js" as="script"><link rel="prefetch" href="/assets/component-zJKDe-5x.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><img class="vp-nav-logo" src="/assets/images/head.png" alt><!----><span class="vp-site-name hide-in-pad">MetaMind</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="主页"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:house" sizing="height" height="1em"></iconify-icon><!--]-->主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/LLM/" aria-label="大语言模型"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:book" sizing="height" height="1em"></iconify-icon><!--]-->大语言模型<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/MMLLM/" aria-label="多模态"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:laptop-code" sizing="height" height="1em"></iconify-icon><!--]-->多模态<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/3DVL/" aria-label="3D-Vision Language"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:eye" sizing="height" height="1em"></iconify-icon><!--]-->3D-Vision Language<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/other_direction/" aria-label="其他方向"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:computer" sizing="height" height="1em"></iconify-icon><!--]-->其他方向<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/open_projects/" aria-label="开源项目"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:star" sizing="height" height="1em"></iconify-icon><!--]-->开源项目<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/other/" aria-label="杂谈"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:sun" sizing="height" height="1em"></iconify-icon><!--]-->杂谈<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!----><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><button type="button" class="slimsearch-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="slimsearch-placeholder">搜索</div><div class="slimsearch-key-hints"><kbd class="slimsearch-key">Ctrl</kbd><kbd class="slimsearch-key">K</kbd></div></button><!--]--><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="主页"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:house" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->主页<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:book" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">大语言模型</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:laptop-code" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">多模态</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/ALBEF.html" aria-label="ALBEF 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->ALBEF 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/BEiT%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB.html" aria-label="BEiT 模型代码解读"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->BEiT 模型代码解读<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/BEiT.html" aria-label="BEiT 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->BEiT 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/BEIT2.html" aria-label="BEIT2 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->BEIT2 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/BEIT3.html" aria-label="BEIT3 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->BEIT3 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/%20BLIP.html" aria-label="BLIP 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->BLIP 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/CoCa.html" aria-label="CoCa 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->CoCa 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/DINO.html" aria-label="DINO 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->DINO 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/LLaVA_1.0.html" aria-label="LLaVA 1.0(Large Language and Vision Assistant)"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->LLaVA 1.0(Large Language and Vision Assistant)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/MoCo.html" aria-label="MoCo 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->MoCo 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/Unified-IO.html" aria-label="Unified-IO 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Unified-IO 论文<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/MMLLM/ViLT.html" aria-label="ViLT 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->ViLT 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/VLMo%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB.html" aria-label="VLMo 模型代码解读"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->VLMo 模型代码解读<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/VLMo.html" aria-label="VLMo 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->VLMo 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/InternVL-1.0.html" aria-label="书生·万象多模态大模型（InternVL 1.0）"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->书生·万象多模态大模型（InternVL 1.0）<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/InternVl-1.5.html" aria-label="书生·万象多模态大模型（InternVL 1.5）"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->书生·万象多模态大模型（InternVL 1.5）<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%B8%B8%E7%94%A8%E6%94%B9%E7%BC%96Bert%E5%AE%9E%E7%8E%B0.html" aria-label="多模态常用改编Bert代码实现"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->多模态常用改编Bert代码实现<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9BBLIP2.html" aria-label="庖丁解牛BLIP2"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->庖丁解牛BLIP2<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8BCLIP%E5%8E%9F%E7%90%86%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%EF%BC%8C%E6%96%87%E5%AD%97%E6%90%9C%E7%B4%A2%E5%9B%BE%E5%83%8F%E5%AE%9E%E6%88%98%E6%BC%94%E7%BB%83.html" aria-label="庖丁解牛CLIP"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->庖丁解牛CLIP<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9BVIT.html" aria-label="庖丁解牛VIT"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->庖丁解牛VIT<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:eye" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">3D-Vision Language</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:computer" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">其他方向</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:star" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">开源项目</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:sun" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">杂谈</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="关于我们"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:circle-info" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->关于我们<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="height" height="1em"></iconify-icon>ViLT 论文</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">BinaryOracle</span></span><span property="author" content="BinaryOracle"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/6/15</span><meta property="datePublished" content="2025-06-15T00:00:00.000Z"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color3 clickable" role="navigation">多模态</span><!--]--><meta property="articleSection" content="多模态"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color3 clickable" role="navigation">多模态</span><span class="page-tag-item color4 clickable" role="navigation">已发布</span><!--]--><meta property="keywords" content="多模态,已发布"></span><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 6 分钟</span><meta property="timeRequired" content="PT6M"></span><span class="page-word-info" aria-label="字数🔠" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon word-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="word icon" name="word"><path d="M518.217 432.64V73.143A73.143 73.143 0 01603.43 1.097a512 512 0 01419.474 419.474 73.143 73.143 0 01-72.046 85.212H591.36a73.143 73.143 0 01-73.143-73.143z"></path><path d="M493.714 566.857h340.297a73.143 73.143 0 0173.143 85.577A457.143 457.143 0 11371.566 117.76a73.143 73.143 0 0185.577 73.143v339.383a36.571 36.571 0 0036.571 36.571z"></path></svg><span>约 1913 字</span><meta property="wordCount" content="1913"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><p><code>ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision 论文简析</code></p><!-- more --><blockquote><p>论文链接: <a href="https://arxiv.org/abs/2102.03334" target="_blank" rel="noopener noreferrer">ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</a><br> 代码链接: <a href="https://github.com/dandelin/vilt" target="_blank" rel="noopener noreferrer">https://github.com/dandelin/vilt</a></p></blockquote><h2 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction"><span>Introduction</span></a></h2><figure><img src="/assets/1-DAyBdf-c.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>视觉-语言预训练（VLP）领域中，传统的视觉特征提取主要有两种典型实现方案：</p><ul><li><p><strong>Region Feature（区域特征）</strong>：通常使用预训练的目标检测器（如基于 Visual Genome 数据集训练的检测模型）来定位图像中的物体区域，并提取每个区域的特征。这种方法能够捕获较为精细的对象信息，是许多早期VLP模型的标准做法，但计算复杂且处理速度较慢。</p></li><li><p><strong>Grid Feature（网格特征）</strong>：用卷积神经网络（如 ResNet）对整张图像进行处理，将图像划分为固定大小的网格，通过卷积提取每个网格的视觉特征。这种方式避免了目标检测的步骤，提取速度相对更快，但仍依赖卷积架构，计算资源消耗仍然较大。</p></li></ul><p>ViLT模型提出了一种极简化的视觉嵌入方案，摒弃了传统的目标检测和卷积视觉嵌入器，采用<strong>无卷积的浅层线性投影</strong>直接将图像块（patch）嵌入，并与文本token一同输入transformer处理。这样，ViLT不仅极大降低了模型参数和计算负担，实现了比基于区域特征的模型快数十倍、比基于网格特征的模型快至少四倍的推理速度，还在多项视觉-语言任务中取得了竞争力甚至更优的性能。</p><p>此外，ViLT首次引入了全词掩码和图像增强技术于视觉-语言预训练，进一步推动了模型的下游表现，展示了其轻量化设计在效率与性能上的优势。</p><p><strong>Contribution</strong>:</p><ol><li><p>第一个基于patch projection的多模态预训练模型，其是首个使用patch projection来做visual embedding的方法。</p></li><li><p>证明了可以将BERT的方法和Vison Transformer结合起来用于多模态transformer。</p></li><li><p>体现了全词掩码在预训练时以及图像增强在微调时的重要性。</p></li></ol><h2 id="motivation" tabindex="-1"><a class="header-anchor" href="#motivation"><span>Motivation</span></a></h2><p>目前参数量最小的多模态Transformer方法。ViLT使用预训练的ViT来初始化交互的transformer，这样就可以直接利用交互层来处理视觉特征，不需要额外增加一个视觉encoder（如Faster-RCNN）。</p><h2 id="method" tabindex="-1"><a class="header-anchor" href="#method"><span>Method</span></a></h2><p>现有的视觉语言模型的三种结构类别：</p><ol><li><p>VE = Vision Embedding</p></li><li><p>TE = Text Embedding</p></li><li><p>MI = Modality Interaction</p></li></ol><figure><img src="/assets/2-7pwtNRf7.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>上图是4种不同类型的VLP模型示意图。其中每个矩形的高表示相对计算量大小，VE、TE和MI分别是visual embedding、text embedding和modality interaction的简写。</p><p>作者提出这4种类型的主要依据有两点：</p><ol><li><p>在参数或者计算上，两种模态是否保持平衡。</p></li><li><p>在网络深层中，两种模态是否相互作用。</p></li></ol><p>VSE、VSE++和SCAN属于(a)类型。对图像和文本独立使用encoder，图像的更重，文本的更轻，使用简单的点积或者浅层attention层来表示两种模态特征的相似性。</p><p>CLIP属于(b)类型。每个模态单独使用重的transformer encoder，使用池化后的图像特征点积计算特征相似性。</p><p>ViLBERT、UNTER和Pixel-BERT属于(c)类型。这些方法使用深层transformer进行交互作用，但是由于VE仍然使用重的卷积网络进行特征抽取，导致计算量依然很大。</p><p><strong>作者提出的ViLT属于(d)类型。ViLT是首个将VE设计的如TE一样轻量的方法，该方法的主要计算量都集中在模态交互上</strong>。</p><h2 id="modality-interaction-schema" tabindex="-1"><a class="header-anchor" href="#modality-interaction-schema"><span>Modality Interaction Schema</span></a></h2><p>模态交互部分可以分成两种方式：一种是<strong>single-stream</strong>(如BERT和UNITER)，另一种是<strong>dual-stream</strong>(如ViLBERT和LXMERT)。其中<strong>single-stream</strong>是对图像和文本concate然后进行交互操作，而<strong>dual-stream</strong>是不对图像和文本concate然后进行交互操作。<strong>ViLT延用single-stream的交互方式</strong>，因为<strong>dual-stream会引入额外的计算量</strong>。</p><p>现有的VLP模型的<strong>text embedding</strong>基本上都使用类BERT结构(图1)，但是<strong>visual embedding</strong>存在着差异。在大多数情况下，<strong>visual embedding是现有VLP模型的瓶颈</strong>。<strong>visual embedding的方法总共有三大类</strong>，其中<strong>region feature</strong>方法通常采用Faster R-CNN二阶段检测器提取region的特征，<strong>grid feature</strong>方法直接使用CNN提取grid的特征，<strong>patch projection</strong>方法将输入图片切片投影提取特征。<strong>ViLT是首个使用patch projection来做visual embedding的方法</strong>。</p><h2 id="model-structure" tabindex="-1"><a class="header-anchor" href="#model-structure"><span>Model Structure</span></a></h2><figure><img src="/assets/3-BHQ09kRf.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>作者提出的ViLT可以认为是目前最简单的多模态Transformer方法。ViLT使用预训练的ViT来初始化交互的transformer，这样就可以直接利用交互层来处理视觉特征，不需要额外增加一个视觉encoder。</strong></p><p>文本特征输入部分，将文本看成一个词序列，通过<strong>word embedding matrix</strong>转化成<strong>word embedding</strong>，然后和<strong>position embedding</strong>进行相加，最后和<strong>modal-type embedding</strong>进行concate。</p><p>图像特征输入部分，将图像切块看成一个图像块序列，通过<strong>linear projection</strong>转化成<strong>visual embedding</strong>，然后和<strong>postion embedding</strong>进行相加，最后和<strong>modal-type embedding</strong>进行concate。</p><p>其中<strong>word embedding</strong>和<strong>visual embedding</strong>通过可学习的<strong>modal-type embedding</strong>标志位来区分，其中0标志位表示<strong>word embedding</strong>部分，1标志位表示<strong>visual embedding</strong>部分。</p><p><strong>wrod embedding</strong>和<strong>visual embedding</strong>分别都嵌入了一个额外的可学习 <code>[class] embedding</code>，方便和下游任务对接。</p><h3 id="pretraining-objectives" tabindex="-1"><a class="header-anchor" href="#pretraining-objectives"><span>Pretraining Objectives</span></a></h3><p><strong>ViLT预训练的优化目标有两个：一个是image text matching(ITM)，另一个是masked language modeling(MLM)。</strong></p><p><strong>ImageText Matching</strong>：随机以0.5的概率将文本对应的图片替换成不同的图片，然后对文本标志位对应输出使用一个线性的<strong>ITM head</strong>将输出feature映射成一个二值logits，用来判断图像文本是否匹配。另外ViLT还设计了一个<code>word patch alignment (WPA)</code>来计算textual subset和visual subset的对齐分数。</p><p><strong>Masked Language Modeling</strong>：MLM的目标是通过文本的上下文信息去预测masked的文本tokens。随机以0.15的概率mask掉tokens，然后文本输出接两层<strong>MLP</strong>预测mask掉的tokens。</p><p><strong>Whole Word Masking</strong>：另外ViLT还使用了<strong>whole word masking</strong>技巧。<strong>whole word masking</strong>是将连续的子词tokens进行mask的技巧，避免了只通过单词上下文进行预测。比如将“giraffe”词tokenized成3个部分[“gi”, “##raf”, “##fe”]，可以mask成[“gi”, “[MASK]”, “##fe”]，模型会通过mask的上下文信息[“gi”，“##fe”]来预测mask的“##raf”，就会导致不利用图像信息。</p><h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="#conclusion"><span>Conclusion</span></a></h2><p>本文提出的方法在效率上大大提升且表现出相似的性能，相比于region feature的方法速度快了60倍，相比于grid feature的方法快了4倍，而且下游任务表现出相似甚至更好的性能。</p><p>缺点：</p><p>1、性能不够高，在一些数据集上的表现比不过C类方法，有可能因为对于现有的任务来说，因为数据集的bias，或者这个任务需要更多的视觉信息，因此需要更多得视觉部分，最后的效果才能好。</p><p>2、虽然推理时间快，但是训练速度很慢。只是结构上简化了多模态学习，但一般人还是玩不起。</p></div><!----><!----><!----></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-07-15T03:27:26.000Z" data-allow-mismatch>2025/7/15 03:27</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 3076679680@qq.com">BinaryOracle</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/MMLLM/Unified-IO.html" aria-label="Unified-IO 论文"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="height" height="1em"></iconify-icon>Unified-IO 论文</div></a><a class="route-link auto-link next" href="/MMLLM/VLMo%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB.html" aria-label="VLMo 模型代码解读"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">VLMo 模型代码解读<iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="height" height="1em"></iconify-icon></div></a></nav><div id="comment" class="waline-wrapper vp-comment" vp-comment darkmode="false" style="display:block;"><!----></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">技术共建，知识共享</div><div class="vp-copyright">Copyright © 2025 BinaryOracle </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-hy09JEJM.js" defer></script>
  </body>
</html>
