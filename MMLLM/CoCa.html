<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"CoCa 论文","image":[""],"datePublished":"2025-08-28T00:00:00.000Z","dateModified":"2025-08-29T03:01:25.000Z","author":[{"@type":"Person","name":"BinaryOracle"}]}</script><meta property="og:url" content="https://mister-hope.github.io/MMLLM/CoCa.html"><meta property="og:site_name" content="MetaMind"><meta property="og:title" content="CoCa 论文"><meta property="og:description" content="CoCa: Contrastive Captioners are Image-Text Foundation Models 论文简析"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-08-29T03:01:25.000Z"><meta property="article:author" content="BinaryOracle"><meta property="article:tag" content="编辑中"><meta property="article:tag" content="多模态"><meta property="article:published_time" content="2025-08-28T00:00:00.000Z"><meta property="article:modified_time" content="2025-08-29T03:01:25.000Z"><title>CoCa 论文 | MetaMind</title><meta name="description" content="CoCa: Contrastive Captioners are Image-Text Foundation Models 论文简析">
    <link rel="preload" href="/assets/style-B9ka0LB5.css" as="style"><link rel="stylesheet" href="/assets/style-B9ka0LB5.css">
    <link rel="modulepreload" href="/assets/app-CSzwrp2_.js"><link rel="modulepreload" href="/assets/CoCa.html-FqN32bcM.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-C4-0rx9V.js" as="script"><link rel="prefetch" href="/assets/intro.html-CRrw5Aao.js" as="script"><link rel="prefetch" href="/assets/GREAT.html-O4ekEU7_.js" as="script"><link rel="prefetch" href="/assets/Grounding_3D_Object_Affordance.html-jJt-1DQ6.js" as="script"><link rel="prefetch" href="/assets/IAGNet.html-DXMYZ6uq.js" as="script"><link rel="prefetch" href="/assets/LASO.html-BtWTRZ4X.js" as="script"><link rel="prefetch" href="/assets/index.html-CMkiSIyU.js" as="script"><link rel="prefetch" href="/assets/简析PointNet__.html-Br51XBDD.js" as="script"><link rel="prefetch" href="/assets/简析PointNet.html-B1Ke50cP.js" as="script"><link rel="prefetch" href="/assets/index.html-md7YxVdz.js" as="script"><link rel="prefetch" href="/assets/ BLIP.html-zITxIap8.js" as="script"><link rel="prefetch" href="/assets/ALBEF.html-D50tTwMb.js" as="script"><link rel="prefetch" href="/assets/BEIT2.html-HJoUb3-K.js" as="script"><link rel="prefetch" href="/assets/BEIT3.html-ZsdZf3l8.js" as="script"><link rel="prefetch" href="/assets/BEiT.html-BpDItqyC.js" as="script"><link rel="prefetch" href="/assets/BEiT模型代码解读.html-ChpE3ACH.js" as="script"><link rel="prefetch" href="/assets/DINO.html-CRwZnkDD.js" as="script"><link rel="prefetch" href="/assets/InternVL-1.0.html-TmLL8mWa.js" as="script"><link rel="prefetch" href="/assets/InternVl-1.5.html-nZJ3K38O.js" as="script"><link rel="prefetch" href="/assets/LLaVA_1.0.html-Dw3l49v9.js" as="script"><link rel="prefetch" href="/assets/MoCo.html-BqQvk9C6.js" as="script"><link rel="prefetch" href="/assets/index.html-isdNMNwJ.js" as="script"><link rel="prefetch" href="/assets/Unified-IO.html-EjbURGz0.js" as="script"><link rel="prefetch" href="/assets/VLMo.html-9t0ERjHe.js" as="script"><link rel="prefetch" href="/assets/VLMo代码解读.html-IFjahaYa.js" as="script"><link rel="prefetch" href="/assets/ViLT.html-D2FKt7vh.js" as="script"><link rel="prefetch" href="/assets/多模态常用改编Bert实现.html-CFJsQS8S.js" as="script"><link rel="prefetch" href="/assets/多模态模型CLIP原理与图片分类，文字搜索图像实战演练.html-OJ75Y7N_.js" as="script"><link rel="prefetch" href="/assets/庖丁解牛BLIP2.html-CVzeUZcq.js" as="script"><link rel="prefetch" href="/assets/庖丁解牛VIT.html-D821lBp5.js" as="script"><link rel="prefetch" href="/assets/index.html-DJhJZxYp.js" as="script"><link rel="prefetch" href="/assets/API记录之Numpy篇.html-C2mzjR_0.js" as="script"><link rel="prefetch" href="/assets/API记录之Python篇.html-BfY5BvJ9.js" as="script"><link rel="prefetch" href="/assets/API记录之Pytorch篇.html-CmfX-5SI.js" as="script"><link rel="prefetch" href="/assets/API记录之杂类篇.html-CgI5rO_C.js" as="script"><link rel="prefetch" href="/assets/API记录之框架篇.html-BI4Nws4w.js" as="script"><link rel="prefetch" href="/assets/Attention运算过程中维度变换的理解.html-DI1Qlgr2.js" as="script"><link rel="prefetch" href="/assets/Pytorch张量存储与访问原理.html-Dvgg6WPh.js" as="script"><link rel="prefetch" href="/assets/index.html-DUqeMx1J.js" as="script"><link rel="prefetch" href="/assets/conda虚拟环境管理.html-jPejMNyH.js" as="script"><link rel="prefetch" href="/assets/常用评估指标.html-K793UZXD.js" as="script"><link rel="prefetch" href="/assets/数学知识点.html-CovIUFik.js" as="script"><link rel="prefetch" href="/assets/注意力图可视化.html-BSuBIBu2.js" as="script"><link rel="prefetch" href="/assets/语义分割中常用的损失函数.html-D0HFIuM5.js" as="script"><link rel="prefetch" href="/assets/通俗易懂解读BPE分词算法实现.html-B8jsaOCa.js" as="script"><link rel="prefetch" href="/assets/index.html-CIMBTwP7.js" as="script"><link rel="prefetch" href="/assets/Fine_Tuning知识扫盲.html-VX2j8LeX.js" as="script"><link rel="prefetch" href="/assets/LoRA微调系列.html-43uMvySE.js" as="script"><link rel="prefetch" href="/assets/Prompt_Engineering知识扫盲.html-cVBbs5p-.js" as="script"><link rel="prefetch" href="/assets/index.html-COYWbzg2.js" as="script"><link rel="prefetch" href="/assets/GPT-1论文.html-D5httzKn.js" as="script"><link rel="prefetch" href="/assets/GPT-2论文.html-CJ0epDx0.js" as="script"><link rel="prefetch" href="/assets/GPT-3论文.html-DwVUk3zg.js" as="script"><link rel="prefetch" href="/assets/InstructGPT论文.html-DJgQcBGO.js" as="script"><link rel="prefetch" href="/assets/KV-Cache.html-mAP9ugQh.js" as="script"><link rel="prefetch" href="/assets/LLaMA-1论文.html-5WG_mKNn.js" as="script"><link rel="prefetch" href="/assets/LLaMA-2论文.html-BugV5QNl.js" as="script"><link rel="prefetch" href="/assets/index.html-DWYsup3q.js" as="script"><link rel="prefetch" href="/assets/RoBERTa论文.html-CtKhKW3s.js" as="script"><link rel="prefetch" href="/assets/从零实现Bert.html-D83oPQ4n.js" as="script"><link rel="prefetch" href="/assets/位置编码.html-Fa_4evND.js" as="script"><link rel="prefetch" href="/assets/图解BERT.html-Ci3j9icV.js" as="script"><link rel="prefetch" href="/assets/图解Transformer.html-CC5nPSsI.js" as="script"><link rel="prefetch" href="/assets/1.自动微分.html-DYjvIPb4.js" as="script"><link rel="prefetch" href="/assets/2.用自然的代码表达.html-BEQG7SIb.js" as="script"><link rel="prefetch" href="/assets/3.高阶导数.html-C4sNv-9V.js" as="script"><link rel="prefetch" href="/assets/4.神经网络.html-DlUrgDUJ.js" as="script"><link rel="prefetch" href="/assets/index.html-9mVMqpCU.js" as="script"><link rel="prefetch" href="/assets/1.前置知识.html-B3ndwAb8.js" as="script"><link rel="prefetch" href="/assets/2.大模型API.html-Cgek__5O.js" as="script"><link rel="prefetch" href="/assets/index.html-76d9AqNE.js" as="script"><link rel="prefetch" href="/assets/index.html-D6eZTYig.js" as="script"><link rel="prefetch" href="/assets/index.html-hoJIUSE9.js" as="script"><link rel="prefetch" href="/assets/index.html-BGtcUGyV.js" as="script"><link rel="prefetch" href="/assets/index.html-0G6quzaz.js" as="script"><link rel="prefetch" href="/assets/基础概念.html-2-cyiqzP.js" as="script"><link rel="prefetch" href="/assets/基础模型.html-z734VS64.js" as="script"><link rel="prefetch" href="/assets/组合分析.html-j_QzZBjE.js" as="script"><link rel="prefetch" href="/assets/DALL-E论文.html-CXbBqmR1.js" as="script"><link rel="prefetch" href="/assets/DALL·E模型代码解读.html-DDR0EnL1.js" as="script"><link rel="prefetch" href="/assets/GAN学习笔记.html-Ppx7UWi0.js" as="script"><link rel="prefetch" href="/assets/PixelCNN.html-CQD-ewIz.js" as="script"><link rel="prefetch" href="/assets/Pytorch实现VAE和CVAE.html-BrF-ens5.js" as="script"><link rel="prefetch" href="/assets/index.html-CLWiM_GL.js" as="script"><link rel="prefetch" href="/assets/Tutorial_VAE.html-DwzMnGqe.js" as="script"><link rel="prefetch" href="/assets/VQ-VAE.html-D6HLozKQ.js" as="script"><link rel="prefetch" href="/assets/WGAN.html-P_KXLjc6.js" as="script"><link rel="prefetch" href="/assets/404.html-UeCY5EUK.js" as="script"><link rel="prefetch" href="/assets/index.html-D8U5qZZI.js" as="script"><link rel="prefetch" href="/assets/index.html-DOCrpMmh.js" as="script"><link rel="prefetch" href="/assets/index.html-CC8C5TzV.js" as="script"><link rel="prefetch" href="/assets/index.html-DnmS7ULJ.js" as="script"><link rel="prefetch" href="/assets/index.html-BEsNF1nR.js" as="script"><link rel="prefetch" href="/assets/index.html-E2jQJDDP.js" as="script"><link rel="prefetch" href="/assets/index.html-BRAJCD0y.js" as="script"><link rel="prefetch" href="/assets/index.html-CqrqLCuq.js" as="script"><link rel="prefetch" href="/assets/index.html-AdJhSSsK.js" as="script"><link rel="prefetch" href="/assets/index.html-D0f-zB-_.js" as="script"><link rel="prefetch" href="/assets/index.html-B_u84WxU.js" as="script"><link rel="prefetch" href="/assets/index.html-DrkECBLO.js" as="script"><link rel="prefetch" href="/assets/index.html-DvNWzZdz.js" as="script"><link rel="prefetch" href="/assets/index.html-Bn4B1rR-.js" as="script"><link rel="prefetch" href="/assets/index.html-CbWYfZBY.js" as="script"><link rel="prefetch" href="/assets/index.html-Akp1MyRi.js" as="script"><link rel="prefetch" href="/assets/index.html-DMo7dMwZ.js" as="script"><link rel="prefetch" href="/assets/index.html-t5H4vx9W.js" as="script"><link rel="prefetch" href="/assets/index.html-CTX95-as.js" as="script"><link rel="prefetch" href="/assets/index.html-CkHvIeqX.js" as="script"><link rel="prefetch" href="/assets/index.html-CoYupLkX.js" as="script"><link rel="prefetch" href="/assets/index.html-DsX1Fl9H.js" as="script"><link rel="prefetch" href="/assets/index.html-BCXhhito.js" as="script"><link rel="prefetch" href="/assets/index.html-CVVWlg1B.js" as="script"><link rel="prefetch" href="/assets/index.html-Cct165AG.js" as="script"><link rel="prefetch" href="/assets/index.html-CT9WVyZr.js" as="script"><link rel="prefetch" href="/assets/index.html-BbwVs5G-.js" as="script"><link rel="prefetch" href="/assets/index.html-CKmFB6hg.js" as="script"><link rel="prefetch" href="/assets/index.html-N_hEdjrT.js" as="script"><link rel="prefetch" href="/assets/index.html-iSsBfmI7.js" as="script"><link rel="prefetch" href="/assets/index.html-B5OXrCyQ.js" as="script"><link rel="prefetch" href="/assets/index.html-DUCswwX0.js" as="script"><link rel="prefetch" href="/assets/index.html-DK_NDbQA.js" as="script"><link rel="prefetch" href="/assets/index.html-DX6JUvKU.js" as="script"><link rel="prefetch" href="/assets/index.html-PsQOiCKS.js" as="script"><link rel="prefetch" href="/assets/index.html-C6lJ8xXu.js" as="script"><link rel="prefetch" href="/assets/index.html-BqtPaS2u.js" as="script"><link rel="prefetch" href="/assets/index.html-D7-qTRGK.js" as="script"><link rel="prefetch" href="/assets/index.html-CItLAUm3.js" as="script"><link rel="prefetch" href="/assets/index-BzBQJFYZ.js" as="script"><link rel="prefetch" href="/assets/flowchart-BKGBxuOE.js" as="script"><link rel="prefetch" href="/assets/mermaid.esm.min-qgpMJ8dE.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/SearchResult-PmUfc8Jg.js" as="script"><link rel="prefetch" href="/assets/waline-meta-l0sNRNKZ.js" as="script"><link rel="prefetch" href="/assets/component-9yiY4bDO.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><img class="vp-nav-logo" src="/assets/images/head.png" alt><!----><span class="vp-site-name hide-in-pad">MetaMind</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="主页"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:house" sizing="height" height="1em"></iconify-icon><!--]-->主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/LLM/" aria-label="大语言模型"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:book" sizing="height" height="1em"></iconify-icon><!--]-->大语言模型<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/MMLLM/" aria-label="多模态"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:laptop-code" sizing="height" height="1em"></iconify-icon><!--]-->多模态<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/3DVL/" aria-label="3D-Vision Language"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:eye" sizing="height" height="1em"></iconify-icon><!--]-->3D-Vision Language<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/other_direction/" aria-label="其他方向"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:computer" sizing="height" height="1em"></iconify-icon><!--]-->其他方向<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/open_projects/" aria-label="开源项目"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:star" sizing="height" height="1em"></iconify-icon><!--]-->开源项目<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/other/" aria-label="杂谈"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:sun" sizing="height" height="1em"></iconify-icon><!--]-->杂谈<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!----><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><button type="button" class="slimsearch-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="slimsearch-placeholder">搜索</div><div class="slimsearch-key-hints"><kbd class="slimsearch-key">Ctrl</kbd><kbd class="slimsearch-key">K</kbd></div></button><!--]--><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="主页"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:house" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->主页<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:book" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">大语言模型</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:laptop-code" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">多模态</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/ALBEF.html" aria-label="ALBEF 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->ALBEF 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/BEiT%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB.html" aria-label="BEiT 模型代码解读"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->BEiT 模型代码解读<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/BEiT.html" aria-label="BEiT 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->BEiT 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/BEIT2.html" aria-label="BEIT2 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->BEIT2 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/BEIT3.html" aria-label="BEIT3 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->BEIT3 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/%20BLIP.html" aria-label="BLIP 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->BLIP 论文<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/MMLLM/CoCa.html" aria-label="CoCa 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->CoCa 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/DINO.html" aria-label="DINO 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->DINO 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/LLaVA_1.0.html" aria-label="LLaVA 1.0(Large Language and Vision Assistant)"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->LLaVA 1.0(Large Language and Vision Assistant)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/MoCo.html" aria-label="MoCo 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->MoCo 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/Unified-IO.html" aria-label="Unified-IO 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->Unified-IO 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/ViLT.html" aria-label="ViLT 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->ViLT 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/VLMo%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB.html" aria-label="VLMo 模型代码解读"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->VLMo 模型代码解读<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/VLMo.html" aria-label="VLMo 论文"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->VLMo 论文<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/InternVL-1.0.html" aria-label="书生·万象多模态大模型（InternVL 1.0）"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->书生·万象多模态大模型（InternVL 1.0）<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/InternVl-1.5.html" aria-label="书生·万象多模态大模型（InternVL 1.5）"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->书生·万象多模态大模型（InternVL 1.5）<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%B8%B8%E7%94%A8%E6%94%B9%E7%BC%96Bert%E5%AE%9E%E7%8E%B0.html" aria-label="多模态常用改编Bert代码实现"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->多模态常用改编Bert代码实现<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9BBLIP2.html" aria-label="庖丁解牛BLIP2"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->庖丁解牛BLIP2<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8BCLIP%E5%8E%9F%E7%90%86%E4%B8%8E%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%EF%BC%8C%E6%96%87%E5%AD%97%E6%90%9C%E7%B4%A2%E5%9B%BE%E5%83%8F%E5%AE%9E%E6%88%98%E6%BC%94%E7%BB%83.html" aria-label="庖丁解牛CLIP"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->庖丁解牛CLIP<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/MMLLM/%E5%BA%96%E4%B8%81%E8%A7%A3%E7%89%9BVIT.html" aria-label="庖丁解牛VIT"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->庖丁解牛VIT<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:eye" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">3D-Vision Language</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:computer" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">其他方向</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:star" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">开源项目</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:sun" sizing="both" width="1em" height="1em"></iconify-icon><span class="vp-sidebar-title">杂谈</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="关于我们"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:circle-info" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->关于我们<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="height" height="1em"></iconify-icon>CoCa 论文</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">BinaryOracle</span></span><span property="author" content="BinaryOracle"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/8/28</span><meta property="datePublished" content="2025-08-28T00:00:00.000Z"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color3 clickable" role="navigation">多模态</span><!--]--><meta property="articleSection" content="多模态"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color3 clickable" role="navigation">多模态</span><span class="page-tag-item color4 clickable" role="navigation">编辑中</span><!--]--><meta property="keywords" content="多模态,编辑中"></span><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 10 分钟</span><meta property="timeRequired" content="PT10M"></span><span class="page-word-info" aria-label="字数🔠" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon word-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="word icon" name="word"><path d="M518.217 432.64V73.143A73.143 73.143 0 01603.43 1.097a512 512 0 01419.474 419.474 73.143 73.143 0 01-72.046 85.212H591.36a73.143 73.143 0 01-73.143-73.143z"></path><path d="M493.714 566.857h340.297a73.143 73.143 0 0173.143 85.577A457.143 457.143 0 11371.566 117.76a73.143 73.143 0 0185.577 73.143v339.383a36.571 36.571 0 0036.571 36.571z"></path></svg><span>约 2950 字</span><meta property="wordCount" content="2950"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><p><code>CoCa: Contrastive Captioners are Image-Text Foundation Models 论文简析</code></p><!-- more --><blockquote><p>论文链接: <a href="https://arxiv.org/abs/2205.01917" target="_blank" rel="noopener noreferrer">CoCa: Contrastive Captioners are Image-Text Foundation Models</a><br> 代码链接: <a href="https://github.com/lucidrains/CoCa-pytorch" target="_blank" rel="noopener noreferrer">https://github.com/lucidrains/CoCa-pytorch</a></p></blockquote><h2 id="引言" tabindex="-1"><a class="header-anchor" href="#引言"><span>引言</span></a></h2><p>近年来，计算机视觉领域对<strong>大规模预训练基础模型</strong>的探索越来越重要，因为这些模型能够快速迁移到各种下游任务上。本论文提出了一种极简设计的 <strong>Contrastive Captioner (CoCa)</strong> 模型，它是一种<strong>图文编码-解码结构的基础模型</strong>，在训练时同时使用<strong>对比损失</strong>和<strong>生成式的描述损失</strong>。这样一来，它既能继承 CLIP 这类<strong>对比方法</strong>的能力，又能结合 SimVLM 这类<strong>生成方法</strong>的优点。</p><p>与传统的 encoder-decoder 架构（解码器所有层都对编码器输出做 cross-attention）不同，CoCa 的解码器被一分为二：</p><ul><li><p>前半部分为<strong>单模态解码器（unimodal decoder）</strong>，没有 cross-attention，只学习纯文本的表示；</p></li><li><p>后半部分为<strong>多模态解码器（multimodal decoder）</strong>，通过 cross-attention 融合图像和文本，得到跨模态的联合表示。</p></li></ul><p>在训练目标上，CoCa 同时引入：</p><ul><li><p><strong>对比损失</strong>：用于图像编码器输出与文本单模态表示之间的对齐；</p></li><li><p><strong>描述损失（captioning loss）</strong>：作用在多模态解码器的输出上，要求其自回归地预测文本 token。</p></li></ul><p>这种<strong>共享计算图</strong>的方式，让两个目标可以在计算上高效结合，几乎没有额外开销。训练时，所有的标签（包括人工标注和网络噪声数据）都被统一当作文本，从而自然地融合了不同来源的监督信号。</p><blockquote><p>共享计算图: 一次forward完成两个损失目标值的计算。</p></blockquote><hr><p>深度学习的发展，已经在语言领域涌现出 <strong>BERT、T5、GPT-3</strong> 等基础模型，它们通过大规模预训练展示出<strong>零样本、多任务、迁移学习</strong>的能力。相比专用模型，基础模型能在 amortized（摊销）成本上覆盖更多下游任务，推动规模化智能的发展。</p><p>在视觉和视觉-语言任务中，已有三条研究路径：</p><p><strong>(1) 单编码器（Single-encoder）</strong></p><ul><li><p>代表性工作在 ImageNet 等图像分类数据集上用交叉熵损失预训练。</p></li><li><p>优点：提供通用的视觉特征，可迁移到图像和视频理解任务。</p></li><li><p>缺点：仅依赖图像标注（类别标签），无法利用自然语言知识，因此在涉及图文结合的任务（如 VQA）上受限。</p></li></ul><p><strong>(2) 双编码器（Dual-encoder，对比学习）</strong></p><ul><li><p>通过图像编码器和文本编码器分别编码图像与文本，再用对比损失在共享的潜在空间对齐。</p></li><li><p>优点：不仅能服务视觉任务，还能进行跨模态任务（如图文检索、零样本分类）。</p></li><li><p>缺点：缺乏图文融合的联合表示，因此无法直接应用于复杂的多模态理解任务（如 VQA）。</p></li></ul><p><strong>(3) 编码-解码（Encoder-decoder，生成式预训练）</strong></p><ul><li><p>采用图像输入到编码器，解码器侧使用语言建模损失（LM loss 或 PrefixLM）进行训练。</p></li><li><p>优点：能学到跨模态的联合表示，在多模态理解任务上表现突出。</p></li><li><p>缺点：不能同时得到和图像对齐的纯文本表示，因此在跨模态对齐与检索方面不足。</p></li></ul><hr><figure><img src="/assets/1-COBUoAK5.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>CoCa <strong>融合并统一了以上三类范式</strong>，提出了一种改进的 encoder-decoder 架构：</p><ul><li><p>将解码器拆分为 <strong>单模态部分</strong>（仅学习文本特征）和 <strong>多模态部分</strong>（跨模态融合）。</p></li><li><p>在单模态文本表示与图像表示之间施加<strong>对比目标</strong>，同时在多模态解码器输出上施加<strong>生成目标</strong>。</p></li><li><p>在训练数据上，把所有标注（类别标签、自然描述、网络噪声文本）都视作文本，从而无缝整合了不同监督。</p></li></ul><p>这样一来，CoCa 的训练目标兼顾了：</p><ul><li><p><strong>对比学习的优势</strong>（学习全局语义表征，适合检索和零样本分类）；</p></li><li><p><strong>生成学习的优势</strong>（对细粒度的区域特征建模，适合描述和理解任务）。</p></li></ul><hr><p>CoCa 在多种任务上展现了强大的零样本和迁移能力：</p><ul><li><p><strong>ImageNet 分类</strong>：</p><ul><li><p>零样本准确率 <strong>86.3%</strong></p></li><li><p>冻结编码器 + 学分类头：<strong>90.6%</strong></p></li><li><p>全模型微调：<strong>91.0%（SOTA）</strong></p></li></ul></li><li><p><strong>视频理解</strong>：</p><ul><li><p>Kinetics400/600/700：88.0% / 88.5% / 81.1%</p></li><li><p>Moments-in-Time：47.4%</p></li></ul></li><li><p><strong>跨模态检索</strong>：</p><ul><li>MSCOCO、Flickr30k：显著优于现有方法</li></ul></li><li><p><strong>多模态理解</strong>：</p><ul><li><p>VQA：82.3%</p></li><li><p>SNLI-VE、NLVR2：同样有优异表现</p></li></ul></li><li><p><strong>图像描述生成</strong>：</p><ul><li>NoCaps：CIDEr 得分 <strong>120.6</strong></li></ul></li></ul><p>这些结果表明：<strong>一个统一的 CoCa 模型，能在无需大量任务特定微调的前提下，超越多个专用模型的性能</strong>。</p><h2 id="相关工作" tabindex="-1"><a class="header-anchor" href="#相关工作"><span>相关工作</span></a></h2><p><strong>视觉预训练</strong></p><p>早期的视觉模型大多依赖于在大规模标注数据（如 ImageNet、Instagram、JFT）上对卷积网络或 Transformer 进行预训练，从而解决分类、定位、分割、视频识别、跟踪等视觉识别任务。<br> 近年来，自监督视觉预训练逐渐兴起：</p><ul><li><p><strong>BEiT</strong> 借鉴 BERT 思路，提出了基于掩码图像建模的任务，并用量化后的视觉 token id 作为预测目标。</p></li><li><p><strong>MAE 和 SimMIM</strong> 移除了图像 tokenizer，直接使用轻量级解码器或投影层回归像素值。</p></li></ul><p>但这些方法的局限在于：它们只学习视觉模态模型，无法应用到需要图像与文本 <strong>联合推理</strong> 的任务。</p><hr><p><strong>视觉-语言预训练（VLP）</strong></p><p>VLP 的目标是让模型能够在融合框架中联合建模视觉和语言。</p><ul><li><p>早期方法（LXMERT、UNITER、VinVL）依赖目标检测器（如 Faster R-CNN）提取图像特征。</p></li><li><p>后续方法（ViLT、VLMo）则直接将视觉和语言 Transformer 统一起来，从零开始训练一个多模态 Transformer。</p></li></ul><hr><p><strong>图文基础模型</strong></p><p>最近的研究进一步提出了 <strong>图文基础模型</strong>，它们统一了视觉预训练和视觉-语言预训练：</p><ul><li><p><strong>CLIP 和 ALIGN</strong>：利用噪声图文对数据，通过对比学习目标训练双编码器，学习到跨模态对齐能力，并能实现零样本图像分类。</p></li><li><p><strong>Florence</strong>：在 CLIP/ALIGN 的思路上提出统一的对比目标，并训练能适配于更广泛基准的基础模型。</p></li><li><p><strong>LiT 和 BASIC</strong>：先在大规模图像标注数据上用交叉熵训练，再在噪声图文对数据集上用对比损失微调，从而提升零样本图像分类性能。</p></li><li><p><strong>生成式方法（如 [16, 17, 34]）</strong>：采用编码器-解码器架构并引入生成式损失，在视觉-语言基准任务上表现优异，同时视觉编码器在图像分类上依然具备竞争力。</p></li></ul><hr><p><strong>与现有方法的对比</strong></p><p>本研究提出的 <strong>CoCa</strong>，专注于从零开始，在单一预训练阶段完成图文统一，从而避免多阶段训练（如 ALBEF 那样的先单模态、再多模态流程）。已有一些方法尝试过类似思路（如 ALBEF），但它们存在复杂的训练需求：</p><ul><li><p><strong>计算开销</strong>：CoCa 在一批图文对上只需一次前向与反向传播，而 ALBEF 需要两次（一次使用被扰动输入，一次使用未扰动输入）。</p></li><li><p><strong>训练方式</strong>：CoCa 直接在两个目标函数下从零开始训练，而 ALBEF 依赖预训练的视觉和文本编码器，并需要额外的训练机制（如动量模块）。</p></li><li><p><strong>生成式优势</strong>：CoCa 的解码器架构结合生成式损失，更自然地支持图像描述任务，同时还能直接实现零样本学习。</p></li></ul><h2 id="方法" tabindex="-1"><a class="header-anchor" href="#方法"><span>方法</span></a></h2><h2 id="代码实现" tabindex="-1"><a class="header-anchor" href="#代码实现"><span>代码实现</span></a></h2><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.nn.functional </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> F</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.distributed </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> dist</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> einops </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> rearrange, repeat, einsum</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># -------------------------</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 一些辅助模块 (假设已定义)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - CrossAttention: 跨注意力层</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - LayerNorm: 层归一化</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - Residual: 残差连接包装</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - ParallelTransformerBlock: Transformer 基础块 (自注意力 + FFN)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - EmbedToLatents: 将表征映射到潜在空间 (用于对比学习)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># - default, exists, all_gather: 常用工具函数</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># -------------------------</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">class</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;"> CoCa</span><span style="--shiki-light:#C18401;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">nn</span><span style="--shiki-light:#C18401;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">Module</span><span style="--shiki-light:#C18401;--shiki-dark:#ABB2BF;">)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> __init__</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E5C07B;--shiki-dark-font-style:italic;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        *</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        dim</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                       # 模型隐空间维度</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        num_tokens</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                # 词表大小</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        unimodal_depth</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            # 文本单模态解码层数</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        multimodal_depth</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">          # 图文多模态解码层数</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        dim_latents</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> =</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 对比学习时潜在空间维度</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        image_dim</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> =</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">          # 图像编码器输出维度</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        num_img_queries</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">256</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">       # 图像查询向量数量（额外 +1 作为 CLS token）</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        dim_head</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">64</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">               # 注意力头的维度</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        heads</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">8</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                   # 注意力头数</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        ff_mult</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                 # 前馈层扩展倍数</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        img_encoder</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">          # 图像编码器 (例如 ViT)</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        caption_loss_weight</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # caption 任务损失权重</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        contrastive_loss_weight</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 对比学习损失权重</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        pad_id</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                   # padding token ID</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    ):</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        super</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">__init__</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.dim </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> dim</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.pad_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pad_id</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.caption_loss_weight </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> caption_loss_weight</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.contrastive_loss_weight </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> contrastive_loss_weight</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # ----------- 文本 embedding -----------</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.token_emb </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Embedding</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(num_tokens, dim)        </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># token embedding</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.text_cls_token </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Parameter</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">randn</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dim))  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 文本 CLS token，用于对比学习</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # ----------- 图像编码器 -----------</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.img_encoder </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> img_encoder</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # ----------- 图像注意力池化 -----------</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # img_queries: 查询向量 (包含 num_img_queries 个 + 1 个 CLS)</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.img_queries </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Parameter</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">randn</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(num_img_queries </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, dim))</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.img_attn_pool </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> CrossAttention</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">            dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">dim,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">            context_dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image_dim,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">            dim_head</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">dim_head,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">            heads</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">heads,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">            norm_context</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.img_attn_pool_norm </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> LayerNorm</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dim)</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.text_cls_norm </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> LayerNorm</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dim)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # ----------- 映射到潜在空间 (contrastive learning 用) -----------</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        dim_latents </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> default</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dim_latents, dim)</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.img_to_latents </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> EmbedToLatents</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dim, dim_latents)</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.text_to_latents </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> EmbedToLatents</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dim, dim_latents)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # ----------- 对比学习温度参数 -----------</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.temperature </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Parameter</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.]))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # ----------- 单模态解码层 (仅处理文本) -----------</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.unimodal_layers </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ModuleList</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([])</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ind </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> range</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(unimodal_depth):</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">            self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.unimodal_layers.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">                Residual</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">                    ParallelTransformerBlock</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">                        dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">dim, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dim_head</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">dim_head, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">heads</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">heads, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">ff_mult</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">ff_mult</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                    )</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                ),</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # ----------- 多模态解码层 (融合图文) -----------</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.multimodal_layers </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ModuleList</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([])</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ind </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> range</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(multimodal_depth):</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">            self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.multimodal_layers.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ModuleList</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">                Residual</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ParallelTransformerBlock</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">dim, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dim_head</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">dim_head, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">heads</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">heads, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">ff_mult</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">ff_mult)),   </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 自注意力</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">                Residual</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">CrossAttention</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">dim, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dim_head</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">dim_head, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">heads</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">heads, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">parallel_ff</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">ff_mult</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">ff_mult))  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 跨模态注意力</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            ]))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # ----------- 输出到 logits -----------</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.to_logits </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Sequential</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">            LayerNorm</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dim),</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Linear</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dim, num_tokens, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">bias</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 输出词表 logits</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 权重共享: 输出层的权重和 embedding 权重共享</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.to_logits[</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].weight </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.token_emb.weight</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        nn.init.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">normal_</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.token_emb.weight, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">std</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.02</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # ----------- 分布式训练判断 -----------</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.is_distributed </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> dist.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">is_initialized</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">() </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">and</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> dist.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">get_world_size</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">() </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # -------------------------</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 文本嵌入</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # -------------------------</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> embed_text</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E5C07B;--shiki-dark-font-style:italic;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> text</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        batch, device </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> text.shape[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], text.device</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        seq </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> text.shape[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        text_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">token_emb</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 在末尾拼接 text CLS token</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        text_cls_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> repeat</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.text_cls_token, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;d -&gt; b 1 d&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">b</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">batch)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        text_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">cat</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">((text_tokens, text_cls_tokens), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 构造注意力 mask (避免 CLS token attends 到 padding)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        cls_mask </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> rearrange</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">!=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.pad_id, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;b j -&gt; b 1 j&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        attn_mask </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> F.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">pad</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(cls_mask, (</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, seq, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">value</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 经过单模态层 (仅文本自注意力)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> attn_ff </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.unimodal_layers:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            text_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> attn_ff</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text_tokens, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">attn_mask</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">attn_mask)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 分离 token 表示和 CLS 表示</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        text_tokens, text_cls_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> text_tokens[:, :</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], text_tokens[:, </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        text_embeds </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">text_cls_norm</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text_cls_tokens)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> text_embeds, text_tokens</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # -------------------------</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 图像嵌入</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # -------------------------</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> embed_image</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E5C07B;--shiki-dark-font-style:italic;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> images</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> image_tokens</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 如果输入的是图像，先通过 img_encoder 得到图像 token</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        assert</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> not</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">exists</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(images) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">and</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> exists</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(image_tokens))</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        if</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> exists</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(images):</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">            assert</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> exists</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.img_encoder), </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;必须传入 img_encoder 才能处理原始图像&#39;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            image_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">img_encoder</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(images)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # attention pool 图像 token</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        img_queries </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> repeat</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.img_queries, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;n d -&gt; b n d&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">b</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image_tokens.shape[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">])</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        img_queries </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">img_attn_pool</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(img_queries, image_tokens)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        img_queries </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">img_attn_pool_norm</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(img_queries)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 返回 CLS (全局 embedding) + 其余 token (用于 cross attention)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> img_queries[:, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], img_queries[:, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # -------------------------</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 前向传播</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # -------------------------</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> forward</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E5C07B;--shiki-dark-font-style:italic;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        text</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        images</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        image_tokens</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        labels</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">None</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        return_loss</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">        return_embeddings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    ):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        batch, device </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> text.shape[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], text.device</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 如果需要计算 caption loss 且未提供标签，自动构造 labels</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> return_loss </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">and</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> not</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> exists</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(labels):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            text, labels </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> text[:, :</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], text[:, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 获取文本嵌入 (CLS + token)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        text_embeds, text_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">embed_text</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 获取图像嵌入 (CLS + token)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        image_embeds, image_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">embed_image</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">images</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">images, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">image_tokens</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image_tokens)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 如果只需要 embedding，则直接返回</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> return_embeddings:</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">            return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> text_embeds, image_embeds</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 经过多模态层 (自注意力 + 跨模态注意力)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> attn_ff, cross_attn </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.multimodal_layers:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            text_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> attn_ff</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text_tokens)                    </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 文本自注意力</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            text_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> cross_attn</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text_tokens, image_tokens)   </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 文本 attends 图像</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 输出预测 logits</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        logits </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to_logits</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text_tokens)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 如果不需要 loss，直接返回 logits</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        if</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> not</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> return_loss:</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">            return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> logits</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # ----------- Caption Loss (交叉熵损失) -----------</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        ce </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> F.cross_entropy</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        logits </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> rearrange</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(logits, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;b n c -&gt; b c n&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># [batch, vocab, seq]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        caption_loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> ce</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(logits, labels, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">ignore_index</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.pad_id)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        caption_loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> caption_loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">*</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.caption_loss_weight</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # ----------- Contrastive Loss (对比学习) -----------</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        text_latents </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">text_to_latents</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text_embeds)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        image_latents </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">img_to_latents</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(image_embeds)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 分布式训练下做 all_gather</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        if</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.is_distributed:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            latents </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">stack</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">((text_latents, image_latents), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            latents </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> all_gather</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(latents)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">            text_latents, image_latents </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> latents.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">unbind</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 相似度计算</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        sim </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> einsum</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;i d, j d -&gt; i j&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, text_latents, image_latents)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        sim </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sim </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">*</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.temperature.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">exp</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        contrastive_labels </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">arange</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(batch, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">device</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">device)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 对称 InfoNCE 损失</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        contrastive_loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ce</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(sim, contrastive_labels) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> ce</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(sim.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">t</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(), contrastive_labels)) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">*</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0.5</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        contrastive_loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> contrastive_loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">*</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.contrastive_loss_weight</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 返回总损失 (caption + contrastive)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> caption_loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> contrastive_losss</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!----><!----><!----></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-08-29T03:01:25.000Z" data-allow-mismatch>2025/8/29 03:01</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 3076679680@qq.com">BinaryOracle</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/MMLLM/%20BLIP.html" aria-label="BLIP 论文"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="height" height="1em"></iconify-icon>BLIP 论文</div></a><a class="route-link auto-link next" href="/MMLLM/DINO.html" aria-label="DINO 论文"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">DINO 论文<iconify-icon class="vp-icon" icon="fa6-solid:file" sizing="height" height="1em"></iconify-icon></div></a></nav><div id="comment" class="waline-wrapper vp-comment" vp-comment darkmode="false" style="display:block;"><!----></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">技术共建，知识共享</div><div class="vp-copyright">Copyright © 2025 BinaryOracle </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-CSzwrp2_.js" defer></script>
  </body>
</html>
